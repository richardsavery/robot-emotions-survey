PDF Link,Document Title,Interactive vs Reactive,History,Mapping Strategy,Emotional Model,N,Emotion Critical ,Purpose,Project Stage,What Robot,Abstract,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,ISSN,ISBNs,DOI,Funding Information,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6005226,A behavior combination generating method for reflecting emotional probabilities using simulated annealing algorithm,Probability table - user generated,N,User Emotion to emotion output,Custom Discrete,4,Core,General Interaction,Prototype,MF Head,"This paper presents a behavior generating method for reflecting emotional probabilities. The proposed method consists of two processes: an emotion-behavior probability generating process and a unit behavior combination generating process. 1) In the emotion-behavior probability generating process, the emotional probabilities of behaviors are determined on the basis of user preferences in terms of the priorities of emotions. 2) In the unit behavior combination generating process, optimal behaviors are found by the simulated annealing algorithm. A final behavior is a set of selected parts of expressions. It is possible to not only reveal an abundance of expressions without one-to-one mapping relations between emotions and behaviors but also apply these expressions in the case of various robots. We have verified the diversity of emotional expression by applying the proposed method to two different robot systems, which are a cyber robot simulator and a real robot system.",H. S. Ahn; J. Y. Choi; D. Lee; W. H. Shon,"Department of Applied Robot Technology, Korea Institute of Industrial Technology, Ansan 426-791, Korea; School of Electrical Engineering and Computer Science, ASRI, PIL, Seoul National University, Korea; Department of Applied Robot Technology, Korea Institute of Industrial Technology (KITECH), Ansan 426-791, Korea; Department of Applied Robot Technology, Korea Institute of Industrial Technology (KITECH), Ansan 426-791, Korea",2011 RO-MAN,,2011,,,192,197,,,,,,Robots;Mouth;Simulated annealing;Eyebrows;Indexes;Collision avoidance;Electronic mail,intelligent robots;probability;psychology;simulated annealing,behavior generating method;emotional probability reflection;emotion-behavior probability generating process;unit behavior combination generating process;user preferences;simulated annealing algorithm;emotional expression;cyber robot simulator;real robot system,,8,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5711644,A Biologically Inspired Architecture for an Autonomous and Social Robot,Rule-based BIology Model,Y,Non-emotion stimuli to internal process,Custom Discrete,2,Core,Performance,Implemented and Evaluated,Maggie,"Lately, lots of effort has been put into the construction of robots able to live among humans. This fact has favored the development of personal or social robots, which are expected to behave in a natural way. This implies that these robots could meet certain requirements, for example, to be able to decide their own actions (autonomy), to be able to make deliberative plans (reasoning), or to be able to have an emotional behavior in order to facilitate human-robot interaction. In this paper, the authors present a bioinspired control architecture for an autonomous and social robot, which tries to accomplish some of these features. In order to develop this new architecture, authors have used as a base a prior hybrid control architecture (AD) that is also biologically inspired. Nevertheless, in the later, the task to be accomplished at each moment is determined by a fix sequence processed by the Main Sequencer. Therefore, the main sequencer of the architecture coordinates the previously programmed sequence of skills that must be executed. In the new architecture, the main sequencer is substituted by a decision making system based on drives, motivations, emotions, and self-learning, which decides the proper action at every moment according to robot's state. Consequently, the robot improves its autonomy since the added decision making system will determine the goal and consequently the skills to be executed. A basic version of this new architecture has been implemented on a real robotic platform. Some experiments are shown at the end of the paper.",M. Malfaz; √Å. Castro-Gonzalez; R. Barber; M. A. Salichs,"RoboticsLab at the Carlos III University of Madrid, Legan√©s, Madrid, Spain; RoboticsLab at the Carlos III University of Madrid, Legan√©s, Madrid, Spain; RoboticsLab at the Carlos III University of Madrid, Legan√©s, Madrid, Spain; RoboticsLab at the Carlos III University of Madrid, Legan√©s, Madrid, Spain",IEEE Transactions on Autonomous Mental Development,,2011,3,3,232,246,,,,,Autonomy;cognitive robotics;control architectures;decision making systems;emotions;motivations,Decision making;Computer architecture;Robot kinematics;Robot sensing systems;Biology,decision making;human-robot interaction;intelligent robots;robot programming;unsupervised learning,social robots;emotional behavior;human-robot interaction;bioinspired control architecture;autonomous robot;a prior hybrid control architecture;fix sequence;programmed sequence;decision making system;self-learning,,32,83,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1014401,A computational emotion model based on the prosodic component of speech sounds,Rule-based Computational Model,Y,User Emotion to emotion output,Eckman ,5,Core,General interaction,Model,NA,"Proposes a computational emotion formation model and attempt to apply the model to speech communication. As speech communication plays an essential part of our daily life, the utilization of speech sound is expected to make human-robot communication smooth. The proposed model forms the state of emotion based on the prosodic components because the emotional aspects of human speech sounds are found in the prosodic change. The model is based on an agent network architecture. Also the model is taken account of the motor command generation according to the state of emotion. The validity of the model is examined by the computer simulation. From the results of the simulation, it is shown that the formation of emotion in the model is adequate for speech sounds, and the motor command generation is also adequate.",Y. Wakamatsu; T. Kondo; K. Ito,"Dept. of Computational Intelligence & Syst. Sci., Tokyo Inst. of Technol., Kanagawa, Japan; Dept. of Computational Intelligence & Syst. Sci., Tokyo Inst. of Technol., Kanagawa, Japan; Dept. of Computational Intelligence & Syst. Sci., Tokyo Inst. of Technol., Kanagawa, Japan",Proceedings 2002 IEEE International Conference on Robotics and Automation (Cat. No.02CH37292),,2002,4,,4155,4160 vol.4,,,,,,Computational modeling;Speech;Robots;Humans;Computer simulation;Emotion recognition;Indium tin oxide;Computational intelligence;Acoustical engineering;Oral communication,speech-based user interfaces;robots;multi-agent systems,computational emotion model;prosodic component;speech sounds;human-robot communication;agent network architecture,,,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4415213,A Design of the Mental Model of a Cognitive Robot,Fuzzy Rule Base,N,User Emotion to emotion output,Custom Discrete,5,Core,General Interaction,Model,Digital,"For the development of for mental model of intelligent robot, in this paper we deal with a cognitive modeling system based on the cognitive process of human being, using psychoanalysis and two kinds of emotion theories, artificial intelligence, neural network and fuzzy Petri net. Based on the psychoanalysis of Freud, we graph the psychiatric structure named 'mind sketch' by KNBN(Kohonen Network based on Belief Network). Within the mind sketch, 'emotion' is used as the base for making relative data. It is based on the emotion theory of Plutchick and the cognitive emotion theory of Ortony et al. To combine these emotional theories, a fuzzy Petri net algorithm has been proposed. And a cognitive modeling system has been developed.",K. Park; D. Kwon; M. Park,"Human-Robot Interaction Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Dept. of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Korea. e-mail: parkks@robot.kaist.ac.kr; Human-Robot Interaction Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Dept. of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Korea. e-mail: kwonds@robot.kaist.ac.kr; Member, IEEE, Dept. of Electronic Engineering, Yonsei University, Seoul, Korea. e-mail: mignon@yonsei.ac.kr",RO-MAN 2007 - The 16th IEEE International Symposium on Robot and Human Interactive Communication,,2007,,,905,911,,,,,,Cognitive science;Cognitive robotics;Intelligent robots;Psychology;Cognition;Cybernetics;Evolution (biology);Human robot interaction;Artificial intelligence;Artificial neural networks,belief networks;cognition;fuzzy set theory;Petri nets;psychology;robots;self-organising feature maps,cognitive robot modeling system;mental model design;intelligent robot;Freud psychoanalysis;cognitive emotion theory;artificial intelligence;neural network;fuzzy Petri net;Kohonen network;belief network,,3,12,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8172369,A framework for a robot's emotions engine,Rule-based BIology Model,N,Human and external to emotion output and internal process,Circumplex,x,Core,General Interaction,Model,Digital,"An Emotions Engine is a modelling and a simplification of the Brain circuitry that generate emotions. It should produce a variety of responses including rapid reactionlike emotions as well as slower moods. We introduce such an engine and then propose a framework for its translated equivalent for a robot. We then define key issues that need addressing and provide guidelines via the framework, for its implementation onto an actual robot's Emotions Engine.",B. Salem,"School of Engineering, University of Liverpool, L69 3GH, UK",2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),,2017,,,635,640,,,,,,Engines;Robot sensing systems;Brain modeling;Mood;Cognition,brain;emotion recognition;medical robotics,brain circuitry;robot emotions engine,,,31,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=687472,A fuzzy emotional agent for decision-making in a mobile robot,Fuzzy Rule Base,N,Non-emotion stimuli to internal process,Custom Discrete,3,Component ,General Interaction,Prototype,Custom Unnamed,"We investigate the use of emotional agents in the decision-making process of a mobile robot. We propose a fuzzy logic model that captures the inherent uncertainty of emotions. The model is used to generate decisions based on both internal and external states and incorporates the use of sensory information to extract environmental conditions. In this way, the agent will react to a changing environment and can take an action according to a mixture of emotions generated by multiple states. As a first step towards addressing the complexity, the model deals with three negative emotions-fear, pain and anger-chosen because of their innate structure. In this paper, we discuss our fuzzy logic model and describe the implementation of an emotional agent on a small mobile robot in which sensory information is used to generate emotions.",M. Seif El-Nasr; M. Skubic,"Dept. of Comput. Sci., Texas A&M Univ., College Station, TX, USA; NA",1998 IEEE International Conference on Fuzzy Systems Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98CH36228),,1998,1,,135,140 vol.1,,,,,,Decision making;Mobile robots;Intelligent robots;Humans;Machine intelligence;Intelligent agent;Pain;Artificial intelligence;Computer science;Intelligent sensors,mobile robots;software agents;fuzzy logic;uncertainty handling,fuzzy emotional agent;decision-making;mobile robot;fuzzy logic model;uncertainty handling;sensory information;fear;pain;anger,,24,29,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5665342,A fuzzy intimacy space model to develop human-robot affective relationship,Fuzzy Neural Network,N,User Emotion to emotion output,Discrete Custom,8,Core,General Interaction,Prototype,KaMERo,"This paper presents a novel method to establish human-robot affective relationship for long-term interaction. At first, in order for a robot to estimate human intimacy, a fuzzy space model to formally represent human intimacy is proposed. Proxemic, tactile and oculesic behavioral features which are dominantly used for intimacy exchange in human-human communication are analyzed for developing a 3 dimensional intimacy space between a human and a robot. Fuzzy Min- Max neural network is utilized to develop a general intimacy space from the training data obtained during human intimacy expressions. In second, criteria for designing a robot intimacy are provided according to the types of social robots. Our affective relationship model is being developed to make a robot differently respond to different users with a variety of emotions and therefore increase the believability of a robot.",Y. Kim; D. Kwon,"Department of Mechanical Engineering, KAIST, Korea; Department of Mechanical Engineering, KAIST, Korea",2010 World Automation Congress,,2010,,,1,6,,,,,Intimacy space;Fuzzy neural network;Emotional interaction;Affective relationship,,behavioural sciences;fuzzy neural nets;human-robot interaction;minimax techniques;social sciences,fuzzy intimacy space model;human robot affective relationship;human intimacy;fuzzy min max neural network;social robot,,2,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4058527,A Hybrid Robot Navigation Approach Based on Partial Planning and Emotion-Based Behavior Coordination,Rule-based Computational Model,N,Non-emotion stimuli to internal process,Custom Discrete,3,Component,Performance,Implemented and Evaluated,Digital,"A hybrid navigation approach for mobile robots is presented in this paper, which integrates partial motion planning with emotion-based behavior coordination. According to the local sensing information and assigned goal, the partial motion planning determines a local target point for the mobile robot, and the trajectory composed of the local targets is near optimal in the sense of a given cost function. Behavior coordination based on emotional mechanism is proposed in the navigation control of mobile robots. The emotion system can properly reflect environment states, and then effectively synthesize rational and complex behaviors. The proposed hybrid approach is competent for the mobile robot to navigate autonomously and effectively in unknown environments. Simulation results demonstrate that the robot motion trajectory using the proposed hybrid navigation approach is more reasonable than the one using a pure behavior-based control or emotion-based behavior coordination alone",H. Zhang; S. Liu; S. X. Yang,"School of Automation, Hangzhou Dianzi University, Xiasha, Hangzhou 310018, China. nbzhd@hotmail.com; School of Automation, Hangzhou Dianzi University, Xiasha, Hangzhou 310018, China. liushirong@hziee.edu.cn; School of Engineering, University of Guelph, Guelph, Ontario N1G 2W1, Canada. syang@uoguelph.ca",2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2006,,,1183,1188,,,,,Motion planning;emotion-based behavior;behavior coordination;autonomous navigation,Robot kinematics;Navigation;Mobile robots;Motion planning;Robot sensing systems;Trajectory;Cost function;Robot control;Control system synthesis;Robot motion,cooperative systems;intelligent robots;mobile robots;motion control;multi-robot systems;path planning,emotion-based behavior coordination;hybrid robot navigation approach;mobile robots;partial motion planning;emotional mechanism;robot motion trajectory,,4,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4120365,A Model for Virtual Emotional Human System,Markovain emotional model,Y,User Emotion to emotion output,Binary,2,Core,General Interaction,Prototype,Digital,"An ultimate aim of artificial intelligence (AI) research is to endow machines with human intelligence, such as reasoning and decision-making. Artificial emotion, as a branch of AI, is aimed at endowing robot with various emotions such as sorrow and happiness. So it becomes a more and more attractive research field than before and will be an advanced stage for AI. The research frame of the virtual emotional human system (VEHS) is represented in this paper. And the emotional model, method and realization technology are also investigated. The model was set up combined with six dimension emotional space and hidden Markov chains, which can be trained by the verbal and nonverbal information from a multiple databases. Furthermore a rudiment of VEHS was formed based on this model and evolved later from the communication with outside gradually. A simulation has been developed and the results are encouraging. It is expected to be applied into the interface between human and machine in the future",L. Peng; W. Li; X. Gu,"Control Sci. & Eng. Res. Center, Southern Yangtze Univ.; NA; NA",2006 IEEE International Conference on Automation Science and Engineering,,2006,,,310,313,,,,,,Humans;Hidden Markov models;Artificial intelligence;Machine intelligence;Automatic control;Computer interfaces;Space technology;Databases;Application software;Cognitive science,artificial life;hidden Markov models,virtual emotional human system;artificial intelligence;human intelligence;artificial emotion;hidden Markov chains,,1,,,,,,IEEE,IEEE Conferences,,
,A model of artificial emotions for behavior-modulation and implicit coordination in multi-robot systems,Rule-based Computational Model,N,Human and external to internal process,Custom Discrete,4,Core,Performance,Implemented and Evaluated,Custom Robot,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=647007,A model of fuzzy emotion and behaviour selection for an autonomous mobile robot,Fuzzy Rule Base,N,Human and external to internal process,CUstom Discrete,4,Core,General Interaction,Prototype,Digital,"This paper proposes a fuzzy model of emotion and behaviours selection for an autonomous mobile robot. Conventional behaviour-based robots can only exhibit a single behaviour or action after sensing an external event. In order to make a robot to adapt to its environment and to exhibit more complex behaviours, we try to model animal emotions and behaviours by a set of Fril's support logic fuzzy rules. This set of fuzzy rules will allow the robot to control and to select different behaviours depending on the environment and its experience. An summary of the calculus of support logic is given in this paper.",K. H. L. Ho,"RIKEN, Inst. of Phys. & Chem. Res., Saitama, Japan",Proceedings 6th IEEE International Workshop on Robot and Human Communication. RO-MAN'97 SENDAI,,1997,,,332,337,,,,,,Mobile robots;Fuzzy control;Robot sensing systems;Fuzzy sets;Mood;Calculus;Humans;Chemicals;Robot control;Batteries,mobile robots;adaptive systems;fuzzy logic;intelligent control;fuzzy control,fuzzy emotion model;fuzzy behaviour model;autonomous mobile robot;behaviour-based robots;animal emotion;Fril support logic fuzzy rules,,1,21,,,,,IEEE,IEEE Conferences,,
,A multimodal and multilevel system for robotics treatment of autism in children,Rule-based Computational Model,N,User Emotion to emotion output,Custom Discrete,4,Core,Autism,Implemented and Evaluated,Zeno R25,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6505128,A mutual effect model of desires and emotions in emotion for robots with growth function,Self-organizing map,N,Human and external to emotion output,Custom Discrete,7,Core,General Interaction,Prototype,Digital,"In this paper, we propose an emotion generation model for robots that considers the mutual effects of desires and emotions to enable generation of complex emotions like creature. Robots of conventional model had a problem that these robots are unable to express complex emotions like creature. This problem can lead to indifference in many people. Hence, to solve this problem, we attempt to realize the mutual effects of desires and emotions to robots in the proposed model. In the proposed model, the effects are expressed using the internal-states of a robot, such as physiological factors. By considering these effects, the proposed model can generate complex emotions like creature. These emotions are influenced by previously expressed emotions, the present state, and present desires of the robot. In addition, the proposed model distinguishes emotions from feelings using characteristics of emotions and feelings. The emotions of the proposed model are based on M. Lewis's study that focused on the development of emotions[1]. Feelings in the proposed model are stored as the internal-states of the robot. In this paper, we perform simulations with the proposed model to verify that it expresses complex emotions like creature. Our simulation results confirmed that the proposed model can express more complex and realistic emotions than those expressed by conventional models.",H. Nagano; M. Harata; M. Tokumaru,"Graduate School of Kansai University, 3-3-35 Yamate-cho, Suita-shi, Osaka 564-8680, Japan; Graduate School of Kansai University, 3-3-35 Yamate-cho, Suita-shi, Osaka 564-8680, Japan; Kansai University, 3-3-35 Yamate-cho, Suita-shi, Osaka 564-8680, Japan","The 6th International Conference on Soft Computing and Intelligent Systems, and The 13th International Symposium on Advanced Intelligence Systems",,2012,,,197,202,,,,,robot;self-organizing maps;emotion;desire;emotion generation;growth functions;mutual effects,,artificial intelligence;robots,desire effect;emotion effect;emotion generation model;robot growth function;robot physiological factor;robot emotion development,,1,5,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1242146,"A new mental model for humanoid robots for human friendly communication introduction of learning system, mood vector and second order equations of emotion",Rule-based BIology Model,Y,Human and external to emotion output,Eckman,6,Component ,General interaction,Prototype,WE-3,"The authors have been developing human-like head robots in order to develop new head mechanisms and functions for a humanoid robot that has the ability to communicate naturally with a human by expressing human-like emotion. Furthermore, the interaction between humans and robots is one of the essential factors for the Neuro-Robotics. We believed that the Mental Dynamics caused by the stimuli from the internal and external environment is important in expressing emotion. Therefore, we newly developed a human-like head robot WE-4 (Waseda Eye No.4) in 2002. The ""Learning System"", the ""Mood Vector"" and the ""Second Order Equations of Emotion"" were introduced to the mental model of the robot. Moreover, an internal clock was introduced as an autonomic nerve system to express the activation component of the Mood Vector. And, we realized the expression of mental transition caused by the stimuli from the internal and external environment of the robot. In this paper, we describe the new mental model of a human-like head robot WE-4.",H. Miwa; T. Okuchi; K. Itoh; H. Takanobu; A. Takanishi,"Graduate Sch. of Sci. & Eng., Waseda Univ., Tokyo, Japan; Graduate Sch. of Sci. & Eng., Waseda Univ., Tokyo, Japan; Graduate Sch. of Sci. & Eng., Waseda Univ., Tokyo, Japan; NA; NA",2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422),,2003,3,,3588,3593 vol.3,,,,,,Cognitive science;Humanoid robots;Humans;Learning systems;Mood;Equations;Robot kinematics;Service robots;Robot sensing systems;Eyes,artificial intelligence;learning systems;intelligent robots;man-machine systems;neurophysiology;interactive systems,mental model;humanoid robots;human friendly communication;learning system;mood vector;second order equation of motion;human-like head robots;human-like emotion;human-machine interaction;neuro robotics;mental dynamics;autonomic nerve system;intelligent robots,,52,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337841,A proposal of model of emotional expressions for robot learning with human,Factor table,N,Non-emotion stimuli to emotion output,Circumplex,24,Core,General Interaction,Model,Digital,"As robot technology grows, more attention is being paid to educational-support robots that assist in learning. For example, an educational-support robot may support students in their school life or help them learn other languages. However, users tend to lose interest in educational-support robots. To solve this problem, a model of emotional expressions has been proposed in human-agent interaction studies. This model, in which the screen agent is programmed to express emotions autonomously, has proven to be effective for interactions between agents and humans. Thus, this paper proposes an emotional expression model for use with educational-support robots. Using simulations, this paper also investigates the number of emotions that a robot can express.",F. Jimenez; T. Yoshikawa; T. Furuhashi; M. Kanoh,"Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan; Graduate School of Engineering, Nagoya University, Japan; School of Engineering, Chukyo University, Japan",2015 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),,2015,,,1,5,,,,,,Data models;Robot kinematics;Electronic mail;Collaborative work;Standards;Collaboration,educational robots;humanoid robots;linguistics,emotional expressions;robot technology;educational-support robots;school life;emotional expression model;human-agent interaction studies;simulations;robot learning;language learning,,,12,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8250127,A robot emotion model with history,Markovain emotional model,Y,Human and internal to emotion output,Discrete Custom,7,Core ,General Interaction,Implemented and Evaluated,Digital,"In this paper, we present a novel robot emotion model that can be used for social robots engaged in human-robot interactions (HRI). The proposed model effectively determines the robot's emotional state based on its own emotion history, the affect of the user whom the robot is interacting with, and the HRI task at hand. The model uniquely uses an nth order Markov Model (MM) to track the robot's emotion history during interactions. Simulated experiments were conducted using the robot emotion model to persuade different users to comply with various tasks. The results showed that the model is able to effectively determine a robot's emotion based on different input scenarios. Furthermore, the novel use of emotion history allows the robot emotion model to be trained faster.",X. Zhang; S. Alves; G. Nejat; B. Benhabib,"Autonomous Systems and Biomechatronics Laboratory, Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON M5S 3G8, Canada; Autonomous Systems and Biomechatronics Laboratory, Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON M5S 3G8, Canada; Autonomous Systems and Biomechatronics Laboratory, Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON M5S 3G8, Canada; Autonomous Systems and Biomechatronics Laboratory, Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON M5S 3G8, Canada",2017 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS),,2017,,,230,235,,,,,robot emotions;human-robot-interaction;nth order Markov model;emotional history,History;Robot sensing systems;Markov processes;Computational modeling;Probability distribution,emotion recognition;human-robot interaction;man-machine systems;Markov processes,social robots;human-robot interactions;emotion history;HRI;robot emotional state;nth order Markov model;robot emotion model;MM,,2,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4651172,A robotic KANSEI communication system based on emotional synchronization,Factor table,N,User Emotion to emotion output,Circumplex,NA,Core,General Interaction,Implemented and Evaluated,Kamin_FA1,"Human-robot communication is an important subject for housekeeping, elderly care and entertainment robots. To make a natural communication entrainment between human and robot emotions plays a vital role. From this view point we propose to make a KANSEI communication system based on emotional synchronization. We developed a robotic KANSEI communication system using entrainment of dynamics, and its effectiveness was examined by experiments of human-robot communication. The robotic emotion was entrained to human emotion by using a vector field of dynamics. The robotic facial expression using a communication robot ldquoKamin_FA1rdquo was realized dynamically based on the robotic emotion. In the experiment of communication, the human impression was changed by the strength of synchronization of robot. Then we confirmed that this method could utilize human-robot communication to keep a comfortable state.",T. Usui; K. Kume; M. Yamano; M. Hashimoto,"Shinshu University, Japan; Shinshu University, Japan; Shinshu University, Japan; Shinshu University, Japan",2008 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2008,,,3344,3349,,,,,,Robots;Synchronization;Humans;Communication systems;Design methodology;Emotion recognition;Polynomials,emotion recognition;human-robot interaction;robot vision,robotic KANSEI communication system;emotional synchronization;human-robot communication;elderly care robots;entertainment robots;housekeeping robots;robotic emotion;robotic facial expression;robot synchronization,,3,12,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5584383,A self-sufficiency model using urge system,Rule-based Computational Model,Y,Non-emotion stimuli to emotion output,Eckman,6,Core,General Interaction,Implemented and Evaluated,Ifbot,"The urge theory, in which emotion constitutes an autonomous system, is used to model a self-sufficiency system for communication robots. Using this model, a robot can convey its psychological and physiological conditions to the user through facial expressions, voice, behavior, and other means thereby producing psychological interaction with the user.",T. Ando; M. Kanoh,"Graduate School of Computer and Cognitive Sciences, Chukyo University, 101 Tokodachi, Kaizu-cho, Toyota 470-0393, Japan; Dept. of Mechanics and Information Technology, School of Information Science and Technology, Chukyo University, 101 Tokodachi, Kaizu-cho, Toyota 470-0393, Japan",International Conference on Fuzzy Systems,,2010,,,1,6,,,,,,Cognition;Decision making;Robots;Color;Psychology;Computational modeling;Pediatrics,emotion recognition;human-robot interaction,self-sufficiency model;urge system;communication robots;psychological interaction;psychological condition;physiological condition;urge theory,,3,8,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7090356,A situation-aware action selection based on individual's preference using emotion estimation,Factor table,N,Human and external to internal process,Eckman,6,Core,General Interaction,Implemented and Evaluated,Mofmof,"Long-term relationships between humans and robots will expand in the future. We therefore consider that an affinity to robots is one of the important components of a stable relationship. In this paper, we propose an action selection system for robots. We expect the system to select an appropriate action that matches human's individual preference. We used an emotion estimation system to achieve this. This is an approach to create an affinity to robots. As a human's preference will be affected by their emotions, we used emotion estimation to learn these preferences. In this paper, we outline the proposed system, experiments, and evaluation of its efficacy. We performed two types of experiments using a simulated robot over one week and four weeks. In each of the experiments, the robot was varying its behaviors, based on learning of individual's preferences.",K. Kumagai; J. Baek; I. Mizuuchi,"Department of Mechanical Systems Engineering, Tokyo University of Agriculture and Technology, 2-24-16 Nakacho Koganei, Tokyo 184-8588, Japan; Department of Mechanical Systems Engineering, Tokyo University of Agriculture and Technology, 2-24-16 Nakacho Koganei, Tokyo 184-8588, Japan; Department of Mechanical Systems Engineering, Tokyo University of Agriculture and Technology, 2-24-16 Nakacho Koganei, Tokyo 184-8588, Japan",2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),,2014,,,356,361,,,,,,Robots;Estimation;Face;Motion pictures;Meteorology;Mathematical model;Histograms,emotion recognition;human-robot interaction,situation-aware action selection;long-term human-robot relationships;stable relationship;human preference;emotion estimation system;robot affinity,,2,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5223189,A Soothing Software Robot: Modeling Users' Emotions from Utterances,Rule-based Computational Model,N,Non-emotion stimuli to emotion output,Custom Discrete,8,Core,General Interaction,Implemented and Evaluated,Lea,"In stressful modern societies, robot therapy has attracted attention. This therapy consists of talking, touching, and interacting with a robot, like a pet, in order to obtain comfort. Some such pet robots have already been built. In order to feel comforted, not only must robots have emotions but also they should interpret human emotions and be considerate of others. The software named ""Lea"" has two original concepts that are an emotion dictionary and a behavior database. Lea receives voice input, and a graphical user interface (GUI) displays text and expressive facial graphics. Experiments with Lea have shown that 79% of people reacted positively in spite of lowness that is 57% adequacy of reactions. It is considered that cuteness and friendliness redeemed inappropriate reactions. It issues that enhancing the accuracy of inferring the userpsilas emotion and deciding the reaction in the future.",Y. Tsuburaya; H. T. Chaminda; A. Saito; M. Osano,"Software Eng. Lab., Univ. of Aizu, Aizuwakamatsu, Japan; Software Eng. Lab., Univ. of Aizu, Aizuwakamatsu, Japan; Software Eng. Lab., Univ. of Aizu, Aizuwakamatsu, Japan; Software Eng. Lab., Univ. of Aizu, Aizuwakamatsu, Japan",2009 International Conference on Biometrics and Kansei Engineering,,2009,,,219,223,,,,,kansei engineering;soft robots;human emotions;user interaction;personal pet;soothing therapy,Humans;Service robots;Pediatrics;Animals;Software engineering;Medical treatment;Positron emission tomography;Protection;Laboratories;Computer architecture,artificial intelligence;emotion recognition;graphical user interfaces;human computer interaction;software agents,software robot;users emotion modelling;robot therapy;Lea software;emotion dictionary;behavior database;graphical user interface;GUI display;facial graphic display,,1,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1545035,A tension-moderating mechanism for promoting speech-based human-robot interaction,Rule-based Computational Model,Y,User Emotion to Internal Process and emotion output,Eckman extension,7,Core,General Interaction,Implemented and Evaluated,Robovie,"We propose a method for promoting human-robot interaction based on emotion recognition with particular focus on tension emotion. There are two types of emotions expressed in a short time. One is autonomic emotion caused by a stimulus, such as joy and fear. The other is self-reported emotion, such as tension, that is relatively independent of a single stimulus. In our preliminary experiment, we observed that tension emotion (self-reported emotion) obstructs the expression of autonomic emotion, which has demerits on speech recognition and interaction. Our method is based on detection and moderation of tension emotion. If a robot detects tension emotion, it tries to ease it so that a person will interact with it more comfortably and express autonomic emotions. It also retrieves nuances from expressed emotions for supplementing insufficient speech recognition, which will also promote interaction.",T. Kanda; K. Iwase; M. Shiomi; H. Ishiguro,"Dept. of Commun. Robots, ATR Intelligent Robotics & Commun. Labs., Kyoto, Japan; Dept. of Commun. Robots, ATR Intelligent Robotics & Commun. Labs., Kyoto, Japan; Dept. of Commun. Robots, ATR Intelligent Robotics & Commun. Labs., Kyoto, Japan; Dept. of Commun. Robots, ATR Intelligent Robotics & Commun. Labs., Kyoto, Japan",2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2005,,,511,516,,,,,human-robot interaction;emotion recognition;tension emotion;speech-based interaction,Humanoid robots;Robot sensing systems;Human robot interaction;Emotion recognition;Intelligent robots;Speech recognition;Cities and towns;Microphone arrays;Laboratories;Computer interfaces,speech recognition;humanoid robots;man-machine systems;emotion recognition,tension-moderating mechanism;speech-based human-robot interaction;emotion recognition;self-reported emotion;tension emotion detection;tension emotion moderation,,4,16,,,,,IEEE,IEEE Conferences,,
,Adaptive emotional expression in robot-child interaction ,Factor table,Y,User Emotion to emotion output,Cicurmplex,NA,Core,General Interaction,Implemented and Evaluated,Nao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188362,Adventurous robots equipped with basic emotions,Rule-based Computational Model,Y,Non-emotion stimuli to internal process,Discrete Single,1,Core,Performance,Prototype,Digital,"One of the grand challenges of the future generation intelligent systems is how to build a robot which can think in a way similar to human beings. In this case, cognitive robotics attempts to embed cognitive abilities of the natural intelligence, specially the human brain, in robotics applications. To provide the context of such an objective, an interdisciplinary approach which is a merger of different fields of study like artificial intelligence, cognitive informatics, psychoanalysis, and neuroscience, should be adopted. In this paper, to design the behavioral mechanism of adventurous robots, the Motivation/Attitude-Driven Behavior (MADB) model, which is a plausible computational model of human behavior with the purpose of simulating robots equipped with basic humanoid emotions, is exploited. As a result, the proposed model has provided adventurous robots with the capability of showing emotional behaviors. Finally, adventurous robots and conventional ones are separately implemented in a virtual ecosystem and their effort for survival is compared. Consequently, the simulation results show that adventurous robots have a greater chance to survive in the simulated environment.",M. M. R. Kashani; M. Jangjou; N. Khaefinejad; T. Laleh,"Electrical and Computer Engineering Department in Islamic Azad University, North Tehran Branch, Tehran, Iran; Islamic Azad University, U.A.E. Branch, Dubai, Emirates; Electrical and Computer Engineering Department of Islamic Azad University, North Tehran Branch, Tehran, Iran; Electrical and Computer Engineering Department of Islamic Azad University, North Tehran Branch, Tehran, Iran",2012 IEEE International Multi-Disciplinary Conference on Cognitive Methods in Situation Awareness and Decision Support,,2012,,,117,120,,,,,Cognitive robotics;adventurous robots;natural intelligence;machine psychodynamics;MADB model;virtual ecosystem,Robots;Humans;Ecosystems;Cognitive informatics;Educational institutions;Psychology;Decision making,cognitive systems;humanoid robots;intelligent robots,adventurous robots;robot emotion;future generation intelligent system;cognitive robotics;cognitive ability;natural intelligence;human brain;robotics application;artificial intelligence;cognitive informatics;psychoanalysis;neuroscience;behavioral mechanism;Motivation/Attitude-Driven Behavior model;human behavior computational model;humanoid emotion;emotional behavior;virtual ecosystem,,1,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7009178,Affective communication robot partners using associative memory with mood congruency effects,Rule-based Computational Model,Y,Human and external to emotion output and internal process,Eckman,6,Core,General Interaction,Implemented and Evaluated,iPhonoid,"Associative memory is one of the significant and effective functions in communication. Conventionally, several types of artificial associative memory models have been de-veloped. In the field of psychology, it is known that human memory and emotions are closely related each other, such as the mood-congruency effects. In addition, emotions are sensitive to sympathy for facial expressions of communication partners. In this paper, we develop the emotional models for the robot partners, and propose an interactive robot system with a complex-valued bidirectional associative memory model that associations are affected by emotional factors. We utilize multi-modal information such as gesture and facial expressions to generate emotional factors. The results of interactive communication experiment show that there is a possibility to provide the suitable information for the interactive space.",N. Masuyama; M. N. Islam; C. K. Loo,"Faculty of Computer Science and Information Technology, University of Malaya, 50603 Kuala Lumpur, Malaysia; Faculty of Computer Science and Information Technology, University of Malaya, 50603 Kuala Lumpur, Malaysia; Faculty of Computer Science and Information Technology, University of Malaya, 50603 Kuala Lumpur, Malaysia",2014 IEEE Symposium on Robotic Intelligence in Informationally Structured Space (RiiSS),,2014,,,1,8,,,,,,Robots;Mood;Associative memory;Shape;Face;Clustering algorithms,content-addressable storage;face recognition;gesture recognition;human-robot interaction;psychology,affective communication robot partners;mood congruency effects;artificial associative memory models;psychology;human memory;human emotions;communication partners;interactive robot system;complex-valued bidirectional associative memory model;multimodal information;facial expressions;gesture expressions,,1,47,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1442679,"Affective communication system with multimodality for a humanoid robot, AMI",Rule-based Computational Model,Y,User Emotion to emotion output,Discrete Custom,3,Component,General Interaction,Prototype,AMI,"Nonverbal communication plays a vital role in human interaction. To interact sociably with a human, a robot has to recognize and express emotions like a human. It also has to speak and determine its autonomous behavior while considering the emotional status of a human. In this paper, we present an affective human-robot communication system for a humanoid robot, AMI that we designed to communicate multi-modally with a human through dialogue. It communicates with humans by understanding and expressing nonverbal communication through channels such as facial expressions, voice, gestures and postures. Interaction between human and robot is made possible through the affective communication framework presented in this paper. The framework enables a robot to catch emotional status of current user and to respond appropriately. As a result, the robot naturally engages in dialogue with a human; it chooses appropriate conversation topics and behaves appropriately in response to human emotions. Moreover, the human partner perceives the robot to be more human-like and friendly, thus enhancing the interaction between the robot and human.",Hye-Won Jung; Yong-Ho Seo; M. S. Ryoo; H. S. Yang,"Dept. of Electr. Eng. & Comput. Sci., KAIST, Daejeon, South Korea; Dept. of Electr. Eng. & Comput. Sci., KAIST, Daejeon, South Korea; Dept. of Electr. Eng. & Comput. Sci., KAIST, Daejeon, South Korea; Dept. of Electr. Eng. & Comput. Sci., KAIST, Daejeon, South Korea","4th IEEE/RAS International Conference on Humanoid Robots, 2004.",,2004,2,,690,706 Vol. 2,,,,,,Humanoid robots;Ambient intelligence;Human robot interaction;Emotion recognition;Artificial intelligence;Laboratories;Mobile computing;Multimedia systems;Mobile communication;Context,humanoid robots;intelligent robots;emotion recognition,humanoid robot;nonverbal communication;human interaction;autonomous behavior;human-robot communication system;multimodal interaction;sociable robot,,3,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6651542,Affective gesturing with music mood recognition,Rule-based Computational Model,N,User Emotion to emotion output,Cicurmplex,NA,Core,General Interaction,Prototype,Hubo,"The recognition of emotions and the generation of appropriate responses is a key component for facilitating more natural human-robot interaction. Music, often called the ‚Äúlanguage of emotions,‚Äù is a particularly useful medium for investigating questions involving the expression of emotion. Likewise, movements and gestures, such as dance, can also communicate specific emotions to human observers. We apply an efficient, causal technique for estimating the emotions (mood) from music audio to enable a humanoid to perform gestures reflecting the musical mood. We implement this system using Hubo, an adult-sized humanoid that has been used in several applications of musical robotics. Our preliminary experiments indicate that the system is able to produce dance-like gestures that are judged by human observers to match the perceived emotion of the music.",D. K. Grunberg; A. M. Batula; E. M. Schmidt; Y. E. Kim,"Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, 19143, USA; Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, 19143, USA; Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, 19143, USA; Department of Electrical and Computer Engineering, Drexel University, Philadelphia, PA, 19143, USA",2012 12th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2012),,2012,,,343,348,,,,,,Mood;Robot motion;Correlation;Humanoid robots;Emotion recognition;Acoustics,audio signal processing;gesture recognition;humanoid robots;human-robot interaction;music,dance-like gestures;musical robotics;adult-sized humanoid;Hubo;musical mood;music audio;mood estimation;emotion estimation;causal technique;natural human-robot interaction;response generation;emotion recognition;music mood recognition;affective gesturing,,2,19,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6758580,Affective social interaction with CuDDler robot,Rule-based - Computational Model,N,User Emotion to emotion output,Discrete Custom,3,Core,General Interaction,Implemented and Evaluated,CuDDler,"This paper introduces an implemented affective social robot, called CuDDler. The goal of this research is to explore and demonstrate the utility of a robot that is capable of recognising and responding to a user's emotional acts (i.e., affective stimuli), thereby improving the social interactions. CuDDler uses two main modalities; a) audio (i.e., linguistics and non-linguistics sounds) and b) visual (i.e., facial expressions) to recognise the user's emotional acts. Similarly, CuDDler has two modalities; a) gesture and b) sound to respond or express its emotional responses. During the TechFest 2012 event, CuDDler successfully demonstrated its capability of recognising the user's emotional acts and responding its expression accordingly. Although, CuDDler is still in its early prototyping stage, the preliminary survey results indicate that the CuDDler has potential to not only aid in human-robot interaction but also contribute towards the long term goal of multi-model emotion recognition and socially interactive robot.",D. K. Limbu; W. C. Y. Anthony; T. H. J. Adrian; T. A. Dung; T. Y. Kee; T. H. Dat; W. H. Y. Alvin; N. W. Z. Terence; J. Ridong; L. Jun,"Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632; Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632; Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632; Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632; Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632; Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632; Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632; Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632; Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632; Institute of Infocomm Research, 1 Fusionpolis Way, #21-01 Connexis (South Tower), Singapore 138632","2013 6th IEEE Conference on Robotics, Automation and Mechatronics (RAM)",,2013,,,179,184,,,,,,Emotion recognition;Face recognition;Robot kinematics;Microphones;Robot sensing systems;Training,emotion recognition;human-robot interaction,affective social interaction;CuDDler robot;users emotional acts recognition;social interactions;audio modalities;visual modalities;gesture modalities;sound modalities;emotional response expression;human-robot interaction;multimodel emotion recognition;socially interactive robot,,6,12,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7074440,An adaptive control algorithm for autonomous mobile robots utilizing emotion modulation,Factor table,N,Non-emotion stimuli to internal process,Discrete Custom,7,Component,Performance,Prototype,Delphinus,"We seek a robust and generic control and navigation system for implementation on a diverse fleet of mobile robots capable of autonomous application. We establish a hybrid reactive-deliberative architecture using a combination of directional and velocity control. As the robots interact with their environment under this control architecture, they will be subject to various positive and negative stimuli that elicit an ‚Äúemotional‚Äù response from the robot. These emotions are used to modulate both the reactive and deliberative control parameters of our architecture. The result is a system that demonstrates few collisions and faster solution times over a wide range of test environments.",D. A. Carnegie; C. Lee-Johnson,"Computer Systems Engineering at Victoria University of Wellington, New Zealand; Faculty of Engineering at Victoria University of Wellington, New Zealand",2009 European Control Conference (ECC),,2009,,,430,435,,,,,,Robot sensing systems;Collision avoidance;Modulation;Robot kinematics;Navigation,adaptive control;mobile robots;multi-robot systems;navigation;path planning;robust control;velocity control,adaptive control algorithm;autonomous mobile robots;emotion modulation;generic control system;robust control;navigation system;autonomous application;hybrid reactive-deliberative architecture;directional control;velocity control;emotional response;deliberative control parameters;reactive control parameters,,,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8284239,An affective mood booster robot based on emotional processing unit,Factor table,N,User Emotion to emotion output,Eckman (no surprise),5,Core,General Interaction,Prototype,Custom Robot,"We propose a novel robotics system with affective interaction capability. Our proposed robot would act as a personal companion with focusing on the mood of the user. The robot has the ability to detect basic emotions of the user through visual and audio sensors. The emotional processing unit employs advances in the field of affective computing and artificial intelligence in order to estimate the emotional state of the user. Additionally, the artificial intelligence unit aims to propose certain behaviors of the robot in order to generate positive emotional interaction towards the user. Such expressions would be projected by various behaviors of the robot such as audio output that appropriate music would be played. Additionally, the robot would generate relevant smell accordingly by digital scent technology. The robot would be in the form of mobile that it can also act by appropriate physical movements. For example when the robot estimates the stressed emotion by the user, it would play relaxing music and produce relaxing scent and the robot would navigate smoothly around without disturbing the user.",J. H. Lui; H. Samani; K. Tien,"Department of Electrical Engineering, National Taipei University, New Taipei City, Taiwan; Department of Electrical Engineering, National Taipei University, New Taipei City, Taiwan; Department of Electrical Engineering, National Taipei University, New Taipei City, Taiwan",2017 International Automatic Control Conference (CACS),,2017,,,1,6,,,,,Social Robot;Emotion;Affective Computing,Mood;Face;Face recognition;Artificial intelligence;Software;Robot sensing systems,affective computing;audio signal processing;emotion recognition;face recognition;human-robot interaction;mobile robots;sensor fusion,affective mood booster robot;emotional processing unit;robotics system;affective interaction capability;personal companion;visual sensors;audio sensors;affective computing;artificial intelligence unit;positive emotional interaction;social robot;facial expression recognition;voice emotion detection,,3,17,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6980956,An alliance generation algorithm based on modified particle swarm optimization for multiple emotional robots pursuit-evader problem,Markovain emotional model,Y,Non-emotion stimuli to internal process,Discrete Custom,6,Core,Performance,Model,Digital,"This paper researches the alliance generation algorithm with emotional factors on the basis of multiple robots pursuit-evader problem. Firstly, this paper constructs an emotional model for pursuit robots: we not only apply the basic emotion method to the emotional expression, but also simulate the process of emotional transfer with Hidden Markov Model (HMM). Secondly, we determine the cooperation intention according to the robots' emotional factors, so that we can prevent the robots with the negative emotions from involving in the mission in case of a negative impact on the alliance. Then, we introduce the subgroup size on the foundation of particle swarm optimization (PSO) to avoid the premature convergence problem, thus the algorithm can obtain the maximum profit in a relatively short period of time. Finally, we bring in the dynamic redistribution mechanism for a better pursuit efficiency.",H. Wang; C. Luo; B. Fang,"Hefei University of Technology, Hefei, China; Hefei University of Technology, Hefei, China; Hefei University of Technology, Hefei, China",2014 11th International Conference on Fuzzy Systems and Knowledge Discovery (FSKD),,2014,,,886,891,,,,,emotional robot;multiple robots pursuit-evader problem;alliance generation algorithm;PSO algorithm;dynamic redistribution mechanism,Robots;Hidden Markov models;Heuristic algorithms;Resource management;Algorithm design and analysis;Vectors;Particle swarm optimization,convergence;hidden Markov models;multi-robot systems;particle swarm optimisation,alliance generation algorithm;modified particle swarm optimization;emotional robots pursuit-evader problem;multiple robots pursuit-evader problem;emotional expression;emotional transfer;hidden Markov model;HMM;cooperation intention;PSO;premature convergence problem;dynamic redistribution mechanism;pursuit efficiency,,2,9,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=981934,An autonomous robot that eats information via interaction with humans and environments,Rule-based - Computational Model,N,Non-emotion stimuli to internal process,Discrete Custom,7,Core,Performance,Prototype,EGO,"We describe a behavior control architecture, EGO, for autonomous robots, by which robot behaviours are selected to keep internal variables in proper ranges. The EGO is based on ethological study, so that both external stimuli and internal variables cause its behavior selection. In addition, introducing ""remaining information"" to one of the internal variables, we can develop ""information eating"" behavior of the autonomous robot via interaction with humans and environment, which is actually symbol acquisition behavior. We propose the concept of an emotionally grounded symbol, which gives information about the importance of the object for the survivability of an autonomous robot. In addition an emotionally grounded symbol gives information about emotions that were experienced during learning as well.",M. Fujita; R. Hasegawa; C. G. Tsuyoshi Takagi; J. Yokono; H. Shimomura,"Sony Corp., Tokyo, Japan; NA; NA; NA; NA",Proceedings 10th IEEE International Workshop on Robot and Human Interactive Communication. ROMAN 2001 (Cat. No.01TH8591),,2001,,,383,389,,,,,,Human robot interaction;Electronic mail;Knowledge acquisition;Animals;Terminology;Batteries;Temperature,robots;learning (artificial intelligence);knowledge acquisition;speech recognition;hidden Markov models,autonomous robot;behavior control architecture;EGO;internal variables;external stimuli;behavior selection;remaining information;information eating behavior;symbol acquisition behavior;emotionally grounded symbol,,14,31,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6493412,An Autonomous Social Robot in Fear,Self-organizing map,Y,Non-emotion stimuli to internal process,Single (Fear),1,Core,Performance,Implemented and Evaluated,Maggie,"Currently artificial emotions are being extensively used in robots. Most of these implementations are employed to display affective states. Nevertheless, their use to drive the robot's behavior is not so common. This is the approach followed by the authors in this work. In this research, emotions are not treated in general but individually. Several emotions have been implemented in a real robot, but in this paper, authors focus on the use of the emotion of fear as an adaptive mechanism to avoid dangerous situations. In fact, fear is used as a motivation which guides the behavior during specific circumstances. Appraisal of fear is one of the cornerstones of this work. A novel mechanism learns to identify the harmful circumstances which cause damage to the robot. Hence, these circumstances elicit the fear emotion and are known as fear releasers. In order to prove the advantages of considering fear in our decision making system, the robot's performance with and without fear are compared and the behaviors are analyzed. The robot's behaviors exhibited in relation to fear are natural, i.e., the same kind of behaviors can be observed on animals. Moreover, they have not been preprogrammed, but learned by real inter actions in the real world. All these ideas have been implemented in a real robot living in a laboratory and interacting with several items and people.",√Å. Castro-Gonz√°lez; M. Malfaz; M. √Å. Salichs,"RoboticsLab, Carlos III University of Madrid, Legan√©s, Spain; RoboticsLab, Carlos III University of Madrid, Legan√©s, Spain; RoboticsLab, Carlos III University of Madrid, Legan√©s, Spain",IEEE Transactions on Autonomous Mental Development,,2013,5,2,135,151,,,,,Autonomy;decision making;emotions;fear;social robot,Decision making;Appraisal;Robot sensing systems;Robot kinematics;Computer architecture;Animals,behavioural sciences computing;decision making;humanoid robots;human-robot interaction;mobile robots;social sciences computing,autonomous social robot;artificial emotions;affective states;robot behavior;adaptive mechanism;fear appraisal;fear emotion;fear releasers;decision making system;robot performance;real robot living,,8,51,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=816685,An avoidance planning of robots using fuzzy control considering human emotions,Fuzzy Rule Base,N,Non-emotion stimuli to internal process,Custom Discrete,1,Co,Performance,Prototype,Digital,"For the coexistence of human and robots, the psychological safety of human beings must be considered in the robot's movement for avoidance of unexpected human approaches. The robot's avoidance movement must be reassuring and acceptable for humans and must not have rapid and abrupt changes, which frighten humans. In order to realize the robot's avoidance motion taking human emotions into account, it is necessary to evaluate human emotions against the robot's motions and convert them into a strategy of robot control. Fuzzy control based on fuzzy evaluation is one effective method. In the fuzzy evaluation, the results of subjective evaluation such as the rating scale method are directly converted to fuzzy control rules. The effectiveness of the proposed method is confirmed by experiments using an existing two-degrees of freedom robot.",T. Yamamoto; M. Jindai; S. Shibata; A. Shimizu,"Dept. of Mech. Eng., Ehime Univ., Matsuyama, Japan; NA; NA; NA","IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028)",,1999,6,,976,981 vol.6,,,,,,Fuzzy control;Humans;Robot control;Acceleration;Robot sensing systems;Robot motion;Orbital robotics;Motion control;Mobile robots;Mechanical engineering,fuzzy control;robots;collision avoidance;man-machine systems;human factors,avoidance planning;human emotions;psychological safety;rating scale method;two-degrees of freedom robot;2 DOF robot,,1,5,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1374742,An embodied computational model of simulating depression,Rule-based - Computational Model,N,Non-emotion stimuli to internal process,Discrete Single,1,Core,Performance,Prototype,Digital,"To develop more accurate and realistic emotions in robots with facial expressions and animal robots, a model of emotions is proposed. Following the formulated principles of artificial brain methodology (Noda), a prototype of the model was constructed and used to simulate depression.",K. Noda; A. Tokosumi,"Dept. of Value & Decision Sci., Tokyo Inst. of Technol., Japan; Dept. of Value & Decision Sci., Tokyo Inst. of Technol., Japan",RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),,2004,,,131,133,,,,,,Computational modeling;Brain modeling;Robots;Humans;Robotics and automation;Animals;Cognitive robotics;Computer architecture;Electronic mail;Virtual prototyping,brain models;humanoid robots;emotion recognition;face recognition;biocybernetics,embodied computational model;depression simulation;robot emotion model;facial expressions;animal robots;artificial brain,,,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5334868,An emotion engine for intelligent robot,Factor table,Y,Non-emotion stimuli to emotion output,Discrete Custom,5,Component,General Interaction,Prototype,Thin-client and KOBIE,An emotion is the element that provides the various expression methods and continuous interest to a user. This paper focuses on an emotion engine for emotional interaction between a human and a robot. The emotion engine includes emotion feature generation and internal status module. We apply emotion engine to an emotional experimental robot platform. The proposed emotion engine can be used in the development of emotional robot or cyber characters.,Cheonshu Park; J. Kim,"Robot Research Department, Electronics and Telecommunication Research Institute, Daejeon, Korea; Robot Research Department, Electronics and Telecommunication Research Institute, Daejeon, Korea",2009 ICCAS-SICE,,2009,,,5703,5706,,,,,Emotion engine;intelligent robot;embedded system,Engines;Intelligent robots;Humans;Intelligent sensors;Robot sensing systems;Speech recognition;Cognitive robotics;Emotion recognition;Image recognition;Face,emotion recognition;human-robot interaction;intelligent robots;service robots,intelligent robot;emotion engine;human-robot interaction;cyber character,,,9,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4382195,An Emotion Expression System for the Emotional Robot,Factor table,N,User Emotion to emotion output,Discrete Custom,6,Core,General Interaction,Prototype,Kobie,"In this paper, we presents an emotion expression system for expressing emotion for the emotional robot, which have a plurality of different sensors sense information about internal/external stimuli. In detail, we propose method for processing information that is collected through various sensors in an intelligent robot, a method for determining an emotion, and a method for expressing a corresponding action. Our system can express a specific emotion of the emotional robot in the form recognizable by a user so that an emotional communication between the user and the emotional robot through affective communication. An emotional expression system is comprised of an emotion feature information collector component, an internal status management component, an action determiner component and an action expression component. Our system can be applied to the emotional robot. Also, our system can be used in developing the Cyber character having an emotion or developing the apparatus having an emotion in the ubiquitous environment.",C. Park; J. Ryu; J. Sohn; H. Cho,"Intelligent Robot Research Division, Electronics and Telecommunication Research Institute. bettle@etri.re.kr; Intelligent Robot Research Division, Electronics and Telecommunication Research Institute. ryu0914@etri.re.kr, bettle@etri.re.kr; Intelligent Robot Research Division, Electronics and Telecommunication Research Institute. jcsohn@etri.re.kr, bettle@etri.re.kr; Intelligent Robot Research Division, Electronics and Telecommunication Research Institute. hkcho@etri.re.kr, bettle@etri.re.kr",2007 IEEE International Symposium on Consumer Electronics,,2007,,,1,6,,,,,Sensor fusion;emotion engine;emotion model;affective communication;emotional expression robot,Intelligent robots;Robot sensing systems;Intelligent sensors;Humans;Emotion recognition;Speech recognition;Image recognition;Face;Biological system modeling;Cognitive robotics,emotion recognition;intelligent robots;sensor fusion,sensor fusion;emotion expression robot;intelligent robot;user recognition;emotion feature information collector;internal status management;action determiner;affective communication,,6,23,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1342021,An emotion-based approach to decision making and self learning in autonomous robot control,Fuzzy Rule Base,N,Non-emotion stimuli to internal process,Discrete Custom,4,Component,Performance,Prototype,Digital,"In recent years, the fact that emotions are essential in human intelligence has been noticed. This suggests that emotions may play an important role in autonomous robot control as well. Because emotions are fuzzy in nature, this paper presents a fuzzy emotion model for an autonomous robot. Equipped with emotions, the robot is capable of evaluating the changes of both the environment and its internal states. Also, the emotion model is integrated in a decision-making/self-learning system, which is based on the associative learning strategy we presented to implement adaptive behavior control. Simulations are conducted to test the performance of the emotion model and the associative learning strategy, and the results prove the validity of them.",Changsheng Yu; Li Xu,"Coll. of Electr. Eng., Zhejiang Univ., Hangzhou, China; Coll. of Electr. Eng., Zhejiang Univ., Hangzhou, China",Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788),,2004,3,,2386,2390 Vol.3,,,,,,Decision making;Robot control;Learning systems;Educational institutions;Humans;Intelligent robots;Appraisal;Virtual environment;Programmable control;Adaptive control,mobile robots;decision making;unsupervised learning;adaptive control;self-adjusting systems;fuzzy logic,decision making;self learning system;autonomous robot control;human intelligence;fuzzy emotion model;associative learning;adaptive behavior control,,5,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=813010,An emotion-based approach to robotics,Factor table,Y,Human and external to emotion output ,Eckman,6,Core,General Interaction,Prototype,Yuppy,"We describe a different approach to robotics in which emotions are at center-stage playing a much larger role than just that of facilitating emotional expression. Drawing inspiration from work in psychology, neuroscience, and ethology, we have developed a computational framework that captures important aspects of emotional processing and integrates these with other models of perception, attention, motivation, behavior, and motor control. We have followed this approach to control several autonomous agents, including a physical robot that is capable of emotional expression while exhibiting robust and effective behavior.",J. D. Velasquez,"Artificial Intelligence Lab., MIT, Cambridge, MA, USA",Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289),,1999,1,,235,240 vol.1,,,,,,Robot kinematics;Robot sensing systems;Mobile robots;Control systems;Computational modeling;Motor drives;Artificial intelligence;Laboratories;Intelligent robots;Psychology,robots;cognitive systems,emotion-based approach;robotics;psychology;neuroscience;ethology;emotional processing;perception;attention;motivation;behavior;motor control,,20,32,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7783498,An Emotion-Based Interaction Strategy to Improve Human-Robot Interaction,Rule-based - Computational Model,N,User Emotion to Internal Process,Binary,2,Component,General Interaction,Implemented and Evaluated,Digital,"Emotion and empathy are key subjects on human-robot interaction, especially regarding social robots. Several studies have investigated emotional reactions of humans toward robots, while others deal with development of actual systems to analyze how affective feedback may influence this kind of interaction. This paper presents an emotion-aware interaction strategy applied to an embodied virtual agent, implemented as an Android application. The system assigns two distinct paradigms to the virtual character, according to the user's emotion, inferred through facial expressions analysis. Within subject user experiments have been performed, in order to evaluate if the proposed strategy improves empathy and pleasantness.",C. M. Ranieri; R. A. F. Romero,"Inst. of Math. & Comput. Sci., Univ. of Sao Paulo, S√£o Carlos, Brazil; Inst. of Math. & Comput. Sci., Univ. of Sao Paulo, S√£o Carlos, Brazil",2016 XIII Latin American Robotics Symposium and IV Brazilian Robotics Symposium (LARS/SBR),,2016,,,31,36,,,,,Social robots;Emotions;Affective computing;Mobile devices,Robots,control engineering computing;human-robot interaction;smart phones,human-robot interaction improvement;social robots;emotional reactions;emotion-aware interaction strategy;embodied virtual agent;Android application;virtual character;facial expressions analysis;empathy;pleasantness,,1,19,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7578774,An emotion-driven attention model for service robot,Self-organizing map,N,User Emotion to emotion output,Discrete Custom,4,Core,General Interaction,Prototype,Robotic Arm,"This paper presents an Emotion-Driven Attention (EDA) model for the service robot based on cognitive structure of human, which integrates the emotion mechanism with cognitive system to manage attention allocation, and enable the robot react to emotional social cues appropriately. For a service robot, the typical tasks including interactive manipulation and object handover. During the interaction with human, the human's facial expression can be recognized by the robot in the real-time, which is considered as a social cue to trigger a corresponding emotion of the robot by Self-Organizing Map (SOM). Then, the robot's emotion plays as a reinforcement signal to regulate the attention parameters, which may result in grasping or avoiding the identified object according to the human intention. We estimate the proposal in both simulated situations and interactive scenarios, the dynamic variations of attention intensity and behaviors based on different emotional states indicate the effectiveness of the proposed model.",M. Ying; L. Zhentao,"Information and Electric Engineering College, Hunan University of Arts and Science, School of Information Science and Engineering, Central South University, China; School of Automation, China University of Geoscience, China",2016 12th World Congress on Intelligent Control and Automation (WCICA),,2016,,,1526,1531,,,,,,Service robots;Robot sensing systems;Appraisal;Face recognition;Emotion recognition,cognition;emotion recognition;human-robot interaction;self-organising feature maps;service robots,human intention;grasping;SOM;self-organizing map;human facial expression;object handover;interactive manipulation;emotional social cues;attention allocation;cognitive system;emotion mechanism;human cognitive structure;EDA model;service robot;emotion-driven attention model,,,25,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7016205,An emotion-generation model for a robot that reacts after considering the dialogist,Factor table,Y,Non-emotion stimuli to emotion output,Discrete Single,1,Component,General Interaction,Prototype,Digital,"This paper proposes an emotion-generation model for a robot that distinguishes different aspects of a human's personality. The robot reacts differently, depending on the human communication it receives. In this cutting-edge research area, several studies have demonstrated robots that generate reactions to humans by judging their interaction. However, these reactions do not change when the communicating human displays a variety of personality traits. This is because the robot only responds to the input without taking the human's personality into account. To solve this issue, we propose an emotion-generation model for robots that produces different reactions depending on the human communication it receives. In this model, the robot has a degree of intimacy that judges the human's personality. The degree of intimacy increases when the human satisfies the robot's desire and decreases when he/she does not. The simulation results confirmed that the robot shows a friendly reaction to a human with a high degree of intimacy and an unfriendly reaction to one with a low degree of intimacy.",S. Kinoshita; H. Takenouchi; M. Tokumaru,"Dept. Science and Engineering Graduate School of Kansai University Osaka, Japan; Faculty of Information Engineering Fukuoka Institute of Technology Fukuoka, Japan; Faculty of Engineering Science Kansai University Osaka, Japan","2014 International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management (HNICEM)",,2014,,,1,6,,,,,Emotion-generation model;Degree of intimacy;Desire;Emotion,Brightness;Temperature control;Mathematical model;Robot sensing systems;Equations;Interference,mobile robots;social sciences,dialogist;partner robots;human communication;emotion-generation model,,2,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6385941,An emotional adaption approach to increase helpfulness towards a robot,Factor table,N,User Emotion to emotion output,PAD,NA,Core,General Interaction,Implemented and Evaluated,EDDIE,"This paper describes a new methodological approach and robot system to trigger more prosocial human reactions towards a robot by transferring social-psychological principles from human-human interaction to human-robot interaction (HRI). The main idea is to trigger increased helpfulness by proactively creating similarity through dynamic emotional adaption of the robot to the mood of the human. This is achieved in an explicit and implicit way: Explicitly, by a similarity-statement of the robot of being in the same mood as the user, and implicitly by controlling the affective parameters of facial and verbal expressions of a robot head in an interaction scenario such that the current values of the human mood in the dimensions of pleasure, arousal, and dominance (PAD) are matched. In a first step, this is accomplished by an initial self-assessment by the human participant to be extended by automatic emotion recognition modules in a later stage. The effectiveness of the approach is confirmed by significant experimental results.",B. Gonsior; S. Sosnowski; M. Bu√ü; D. Wollherr; K. K√ºhnlenz,"Institute of Automatic Control Engineering (LSR), Technische Universit√§t M√ºnchen, D-80290 Munich, Germany; Institute of Automatic Control Engineering (LSR), Technische Universit√§t M√ºnchen, D-80290 Munich, Germany; Institute of Automatic Control Engineering (LSR), Technische Universit√§t M√ºnchen, D-80290 Munich, Germany; Institute of Automatic Control Engineering (LSR), Technische Universit√§t M√ºnchen, D-80290 Munich, Germany; Institute of Automatic Control Engineering (LSR), Technische Universit√§t M√ºnchen, D-80290 Munich, Germany",2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2012,,,2429,2436,,,,,,Robots;Humans;Mood;Games;Acoustics;Emotion recognition,emotion recognition;human-robot interaction;interactive systems,emotional adaption approach;helpfulness;robot system;prosocial human reaction;social-psychological principle;human-human interaction;human-robot interaction;HRI;robot dynamic emotional adaption;human mood;similarity statement;facial expression;verbal expression;robot head;interaction scenario;pleasure;arousal;dominance;automatic emotion recognition module,,16,34,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8542477,An Emotional Model for Social Robots [Late-Breaking Report],Rule-based - Computational Model,Y,Non-emotion stimuli to internal process and emotion,Discrete Custom,3,Core,General Interaction,Model,NA,"We developed an emotional model, which could help supporting robots to accomodate humans during a working task inside an industrial setting. The robot would recognize when a human is experiencing increased stress and decides whether it should assist the human or should do other tasks. We propose the model as a framework which was developed as part of‚ÄúThe Smart Virtual Worker‚Äú-project within the context of human-robot interactions. The emotional model is able to estimate a worker's emotional valence throughout a typical work task by applying a hierarchical reinforcement learning algorithm. Since emotions are generated by the human brain based on an individual's interpretation of a stimulus, we linked the genesis of emotions to empirical findings of the sports sciences in order to infer an emotional reaction. Furthermore, the model reproduces sympathetic reactions of the human body and is capable of remembering past actions in order to include possible future time constraints as an initiator for emotional responses in the upcoming iterations. This capability is crucial for accommodating long-term experiences since the emotional reaction is not only based on the present situation, but on the whole experimental setting.",M. Truschzinski; N. M√Øller,"Chair of Automation Technology Chemnitz University of Technology, Germany; Institute for Media Research Chemnitz University of Technology, Germany",2014 9th ACM/IEEE International Conference on Human-Robot Interaction (HRI),,2014,,,304,305,,,,,,Task analysis;Service robots;Human-robot interaction;Numerical models;Ergonomics;Brain modeling,emotion recognition;human-robot interaction;industrial robots;learning (artificial intelligence);occupational stress,emotional model;social robots;working task;human-robot interactions;human brain;emotional reaction;human body;emotional responses;industrial setting;human stress;The Smart Virtual Worker project;worker emotional valence;hierarchical reinforcement learning algorithm;sympathetic reactions,,,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5423177,An ethical adaptor: Behavioral modification derived from moral emotions,Rule-based - Computational Model,Y,Non-emotion stimuli to internal process,Single (Guilt),1,Component,Performance,Prototype,Digital,"This paper presents the motivation, basis and a prototype implementation of an ethical adaptor capable of using a moral affective function, guilt, as a basis for altering a robot's ongoing behavior. While the research is illustrated in the context of the battlefield, the methods described are believed generalizable to other domains such as eldercare and are potentially extensible to a broader class of moral emotions, including compassion and empathy.",R. C. Arkin; P. Ulam,"Mobile Robot Laboratory in the College of Computing at the Georgia Institute of Technology, Atlanta, GA, 30332; Mobile Robot Laboratory in the College of Computing at the Georgia Institute of Technology, Atlanta, GA, 30332",2009 IEEE International Symposium on Computational Intelligence in Robotics and Automation - (CIRA),,2009,,,381,387,,,,,,Ethics;Robots;Humans;Autonomous agents;Runtime;Laboratories;Prototypes;Mood;Weapons;System performance,robots,ethical adaptor;moral affective function;autonomous robots behavioral modification;eldercare;moral emotions,,15,24,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7533391,An extended Q learning system with emotion state to make up an agent with individuality,Reinforcement learning,N,Non-emotion stimuli to internal process,Discrete Custom,4,Core,Performance,Prototype,Digital,"Recently, researches for the intelligent robots incorporating knowledge of neuroscience have been actively carried out. In particular, a lot of researchers making use of reinforcement learning have been seen, especially, ‚ÄúReinforcement learning methods with emotions‚Äù, that has already proposed so far, is very attractive method because it made us possible to achieve the complicated object, which could not be achieved by the conventional reinforcement learning method, taking into account of emotions. In this paper, we propose an extended reinforcement (Q) learning system with amygdala (emotion) models to make up individual emotions for each agent. In addition, through computer simulations that the proposed method is applied to the goal search problem including a variety of distinctive solutions, it finds that each agent is able to have each individual solution.",M. Obayashi; S. Uto; T. Kuremoto; S. Mabu; K. Kobayashi,"Graduate School of Science and Engineering, Yamaguchi University, Ube, Japan; Graduate School of Science and Engineering, Yamaguchi University, Ube, Japan; Graduate School of Science and Engineering, Yamaguchi University, Ube, Japan; Graduate School of Science and Engineering, Yamaguchi University, Ube, Japan; School of Information Science and Technology, Aichi Prefectural University, Nagakute, Japan",2015 7th International Joint Conference on Computational Intelligence (IJCCI),,2015,3,,70,78,,,,,Reinforcement Learning;Amygdala;Emotional Model;Q Learning;Individuality,Computational modeling;Fuzzy logic;Learning systems;Learning (artificial intelligence);Brain modeling;Robot sensing systems;Computer simulation,,,,,11,,,,,IEEE,IEEE Conferences,,
,An intelligent agent with affect sensing from metaphorical language and speech,Rule-based - Computational Model,N,User Emotion to emotion output,Eckman (no disgust),5,Core,General interaction,Implemented and Evaluated,Digital,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4600646,Are emotional robots more fun to play with?,Factor table,Y,Non-emotion stimuli to emotion output,Discrete Custom,9,Core,General interaction,Implemented and Evaluated,iCat,"In this paper we describe a robotic game buddy whose emotional behaviour is influenced by the state of the game. Using the iCat robot and chess as the game scenario, an architecture for incorporating emotions as a result of a heuristic evaluation of the state of the game was developed. The game buddy was evaluated in two ways. First, we investigated the effects of the characterpsilas emotional behaviour on the userpsilas perception of the game state. And secondly we compared a robotic with a screen based version of the iCat in terms of their influence on userpsilas enjoyment. The results suggested that userpsilas perception of the game increases with the iCatpsilas emotional behaviour, and that the enjoyment is higher when interacting with the robotic version.",I. Leite; A. Pereira; C. Martinho; A. Paiva,"IST - Technical University of Lisbon and INESCID, Av. Professor Cavaco Silva - Taguspark, 2780-990 Porto Salvo, Portugal; IST - Technical University of Lisbon and INESCID, Av. Professor Cavaco Silva - Taguspark, 2780-990 Porto Salvo, Portugal; IST - Technical University of Lisbon and INESCID, Av. Professor Cavaco Silva - Taguspark, 2780-990 Porto Salvo, Portugal; IST - Technical University of Lisbon and INESCID, Av. Professor Cavaco Silva - Taguspark, 2780-990 Porto Salvo, Portugal",RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication,,2008,,,77,82,,,,,,Robots,man-machine systems;robots,emotional robots;robotic game buddy;iCat robot;heuristic evaluation;game state;user perception,,48,23,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473432,Artificial Emotion Model Based on Random Process,Markovain emotional model,Y,Human and external to internal process,Eckman,6,Core,General interaction,Prototype,Digital,"Artificial Emotion model is considered as a key component of to achieve a more effective human-computer interaction and its basic and fundamental are the essentially understanding and expression of natural emotion. The paper presents an emotion computing model Based on Random Process. The model simulates the dynamic process of emotional self-regulation and the dynamic process of emotional transference under the influence of external stimuli. The simulation results show that the change process of emotions simulated by the emotion computing model is consistent with the change rule of human emotion, and it provides a new mechanism for emotional decision-making of emotion robots.",G. Wang; S. Teng; K. Fu,NA; NA; NA,2010 2nd International Workshop on Intelligent Systems and Applications,,2010,,,1,4,,,,,,Random processes;Computational modeling;Psychology;Information technology;Humans;Intelligent robots;Electronic mail;Control engineering;Decision making;Artificial intelligence,artificial intelligence;decision making;human computer interaction;human-robot interaction;random processes,artificial emotion model;random process;human-computer interaction;emotion computing model;emotional self-regulation;emotional decision making;emotion robots,,1,7,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6023466,Artificial emotional interaction model based on EFSM,Markovain emotional model,Y,Human and external to emotion output,Binary,2,Core,General interaction,Prototype,Digital,"According to the basic emotional theory, the artificial emotional interaction model based on the hierarchical expanded finite state machine (EFSM)) was presented. In the EFSM, the variable set V was defined to offer the data for robot's behavior. In the EFSM model, the emotional space included the basic emotional space and the multiple emotional spaces. The emotion-switching diagram was defined and transition function was developed using Markov chain. The simulation model was built using Stateflow toolbox and Simulink toolbox based on the Matlab platform. And the model included three subsystems: the input one, the emotion one and the behavior one. In the emotional subsystem, the responses of different personalities to the external stimuli were described by defining personal space. This model takes states from an emotional space and updates its state depending on its current state and a state of its input (also a state-emotion). The simulation model realizes the process of switching the emotion from the neutral state to other basic emotions. The simulation result is proved to correspond to emotion-switching law of human beings.",M. Qing-mei; C. Ai-lian,"School of Mechanism Engineering, Changzhou University, Changzhou, 213016, China; School of Mechanism Engineering, Changzhou University, Changzhou, 213016, China",Proceedings of 2011 International Conference on Electronic & Mechanical Engineering and Information Technology,,2011,4,,1852,1855,,,,,expanded finite state machine;artificial emotion model;Markov chain;simulation,Mathematical model;Object oriented modeling;Humans;Educational institutions;Presses;Automata;Markov processes,artificial intelligence;finite state machines;human-robot interaction;Markov processes,artificial emotional interaction model;hierarchical expanded finite state machine;variable set;robot behavior;EFSM model;multiple emotional spaces;emotion-switching diagram;Markov chain;Stateflow toolbox;Simulink toolbox;Matlab platform,,2,21,,,,,IEEE,IEEE Conferences,,
,Artificial Emotions as Dynamic Modulators of Individual and Group Behavior in Multi-robot System,Rule-based - Computational Model,N,Human and external to internal process,Custom Discrete,4,Core,Performance,Prototype,Digital,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=367681,Artificial emotions as emergent phenomena,Rule-based Biology Model,N,Non-emotion stimuli to internal process,Custom Discrete,3,Core,Performance,Prototype,SA,"Although some researchers claim that emotion is unique to mammals, this paper describes a notion of artificial emotion as a phenomenon resulting from a series of modifications to emergent behaviors generated by a behavior-based artificial intelligence (AI) approach. Such modifications to behaviors are caused by stimuli (including those from humans) which a robot receives from its environment. The paper describes a series of experiments to generate and test artificial emotion using subsumption architecture (SA) robot platforms developed by the Massachusetts Institute of Technology (MIT). A ""hormone mechanism"", which is part of the behavior definition language, was used to generate artificial emotion. In addition, the action selection dynamics (ASD) paradigm proposed by Pattie Maes as a way to implement computational reflection was also tried. The latter is expected to permit the authors to investigate more profound ontological issues associated with artificial emotion as part of the experiments in computational reflection.<>",T. Gomi; J. Ulvr,"Appl. AI Syst. Inc., Kanata, Ont., Canada; Appl. AI Syst. Inc., Kanata, Ont., Canada",Proceedings of 1993 2nd IEEE International Workshop on Robot and Human Communication,,1993,,,420,425,,,,,,Emergent phenomena;Artificial intelligence;Robots;Reflection;Humans;Testing;Computer architecture;Paper technology;Variable speed drives;Ontologies,artificial intelligence;robots,artificial emotions;emergent phenomena;behavior-based artificial intelligence;robot;subsumption architecture;behavior definition language;hormone mechanism;computational reflection,,12,9,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6343901,Attentional and emotional regulation in human-robot interaction,Rule-based - Computational Model,N,User Emotion to Internal Process,Four Dimensional Model,NA,Core,Performance,Implemented and Evaluated,Robotic Arm,"In this paper, we propose a human-robot interaction system that exploits emotion and attention to regulate and adapt the robotic interactive behavior. In particular, we will focus on the relation between arousal, predictability, and attentional allocation considering as a case study a robotic manipulator interacting with a human operator. We rely on a frequency based model of attention allocation and a 4-dimensional model of emotion. The experiment reported in this paper explores the effectiveness of an attentional regulation mechanisms modulated by arousal and predictability values extracted from the human voice. The collected results show that the attentional modulation, mediated by basic emotional speech features, provides a natural and computationally light regulation mechanism for coordinating the robotic behaviors.",S. Iengo; A. Origlia; M. Staffa; A. Finzi,"DIS, Universit√† di Napoli ‚ÄúFederico II‚Äù, Italy; DSF, Universit√† di Napoli ‚ÄúFederico II‚Äù, Italy; DIS, Universit√† di Napoli ‚ÄúFederico II‚Äù, Italy; DSF, Universit√† di Napoli ‚ÄúFederico II‚Äù, Italy",2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication,,2012,,,1135,1140,,,,,,Humans;Clocks;Speech;Feature extraction;Switches;Robot kinematics,feature extraction;human-robot interaction;interactive systems;manipulators;speech processing,attentional regulation;emotional regulation;human-robot interaction system;robotic interactive behavior;arousal values;predictability values;attentional allocation;robotic manipulator;frequency based model;emotion 4-dimensional model;attentional regulation mechanisms;attentional modulation;emotional speech features;light regulation mechanism,,8,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6144898,Autonomous action selection with motivation-based consciousness and behavior architecture of animal,Rule-based BIology Model,N,Human and external to internal process,Binary,2,Component,Performance,Prototype,Conbe-I,"This paper presents an autonomous action selection system that incorporated a motivation model, and a motion control system to achieve natural behaviors showing human emotion such love, pity etc. We have attempted to give a robot ""consciousness"" and ""emotion"" such as that identified in humans and animals in order to enhance the affinity between humans and robots. A hierarchical structure model for such a robot has been developed to connect the robot's consciousness with the robot's behavior. However, it is difficult to autonomously control the timing and the motion that selects the consciousness and behavior of the robot, whatever the time and position. A motivation model has therefore been developed, and it was combined with the hierarchical structure model to induce and autonomously select consciousness and behavior. The action of dopamine in neurotransmitters was then incorporated into the motivation model to add activity to the robot in conjunction with the incentive to perform a behavior. As a result, this system allows a robot to behave naturally in any situation.",E. Hayashi; K. Ueyama; M. Yoshida,"Dept. of Mechanical Information Science and Technology, Kyushu Institute of Technology, Fukuoka-city, Japan; Graduated School of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka-city, Japan; Graduated School of Computer Science and Systems Engineering, Kyushu Institute of Technology, Fukuoka-city, Japan","The 5th International Conference on Automation, Robotics and Applications",,2011,,,294,299,,,,,Motion;selection;Consciousness;Motivation,Robots;Humans;Animals;Elbow;Wrist;Joints;Shoulder,mobile robots;motion control,autonomous action selection system;motivation-based consciousness;behavior architecture;motivation model;motion control system;robot consciousness;robot emotion;affinity enhancement;neurotransmitters,,2,18,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7727848,Bayesian perception of touch for control of robot emotion,Factor table,N,Non-emotion stimuli to internal process,Discrete Custom,4,Core,General Interaction,Prototype,iCub,"In this paper, we present a Bayesian approach for perception of touch and control of robot emotion. Touch is an important sensing modality for the development of social robots, and it is used in this work as stimulus through a human-robot interaction. A Bayesian framework is proposed for perception of various types of touch. This method together with a sequential analysis approach allow the robot to accumulate evidence from the interaction with humans to achieve accurate touch perception for adaptable control of robot emotions. Facial expressions are used to represent the emotions of the iCub humanoid. Emotions in the robotic platform, based on facial expressions, are handled by a control architecture that works with the output from the touch perception process. We validate the accuracy of our system with simulated and real robot touch experiments. Results from this work show that our method is suitable and accurate for perception of touch to control robot emotions, which is essential for the development of sociable robots.",U. Martinez-Hernandez; A. Rubio-Solis; T. J. Prescott,"Institute of Robotics, Design and Optimisation, School of Mechanical Engineering, The University of Leeds, UK; ACSE Department, The University of Sheffield, UK; Sheffield Robotics Laboratory, Department of Psychology, The University of Sheffield, UK",2016 International Joint Conference on Neural Networks (IJCNN),,2016,,,4927,4933,,,,,,Robot sensing systems;Humanoid robots;Skin;Bayes methods;Sequential analysis;Human-robot interaction,adaptive control;artificial intelligence;Bayes methods;humanoid robots;human-robot interaction;tactile sensors,Bayesian touch perception;sensing modality;social robot development;stimulus;human-robot interaction;sequential analysis approach;adaptable robot emotion control;facial expression;emotion represent;iCub humanoid;robotic platform;robot touch experiment,,9,32,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487217,Behavior decision model of intelligent agent based on artificial emotion,Markovain emotional model,Y,User Emotion to emotion output,Discrete Custom,12,Component,General Interaction,Prototype,Digital,"Emotion is now recognized as a central element of human behavior, and thus it should be embedded within the reasoning process when an intelligent agent or a robot aims to emulate human reactions. Therefore, current research in AI shows an increasing interest in artificial emotion for developing the human-like agent. Based on emotion psychology and artificial emotion, this paper presents a behavior decision model of intelligent agent, the model consists of emotions, motivations and behavior decision. The mapping relationship between exterior stimulates and emotion is built by D-S evidence theory. And the model applies the Markov decision process to determine emotion states to behaviors. The model provides a valid method to the emotional agent modeling and affective decision system.",Wang Guojiang; Wang Xiaoxiao; Fu Kechang,"School of Control Engineering, Chengdu University of Information Technology, 610225, China; School of Information and Engineering, University of Science and technology of Beijing, 100083, China; School of Control Engineering, Chengdu University of Information Technology, 610225, China",2010 2nd International Conference on Advanced Computer Control,,2010,4,,185,189,,,,,Behavior Decision Model;Artificial Emotion;D-S Evidence Theory;Markov Decision Process,Intelligent agent;Artificial intelligence;Humans;Machine intelligence;Control engineering;Information technology;Electronic mail;Emotion recognition;Intelligent robots;Psychology,Markov processes;uncertainty handling,behavior decision model;intelligent agent;artificial emotion;emotion psychology;D-S evidence theory;Markov decision process;motivations;emotional agent modeling;affective decision system,,4,12,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5214718,Behavior generation in robots by emotional motivation,Markov Model and Fuzzy Rule Base,Y,Non-emotion stimuli to emotion output,Custom Discrete,4,Core,General interaction,Prototype,Digital,Emotions are necessary in robotic system to get some extra benefits especially in intelligence and autonomy with the motivational mechanism for behavior generation. A robot needs to be intelligent enough to adjust with dynamic and flexible environment. Benefits can be amplified if emotional intelligence can be incorporated with the available control methods. We describe an emotion model to be used for a robotic system with an application in a simulated environment. The simulation shows satisfactory results in emotion generation and actions selection.,K. Izumi; S. C. Banik; K. Watanabe,"Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 840-8502, Japan; Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 840-8502, Japan; Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 840-8502, Japan",2009 IEEE International Symposium on Industrial Electronics,,2009,,,455,460,,,,,,Robots,artificial intelligence;robots,robots behavior generation;emotional motivation;robotic system;motivational mechanism;emotional intelligence;actions selection,,2,22,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4579232,Behavior generation through interaction in an emotionally intelligent robot system,Markovain emotional model,Y,Non-emotion stimuli to internal process,Custom Discrete,4,Core,Performance,Prototype,Digital,"This paper deals with the implementation of emotions to generate intelligent behavior among the cooperative and job distributed mobile robots performing a specified task and to develop an easier form of communication. A human emotion model is adapted to multirobot system to achieve their well organized tasks. With the emotional capability, each robot can distinguish the changed environment and can understand colleague robotpsilas state: i.e., it can adapt to and react with changed world. The behavior of a robot is derived from the dominating emotion and emotional interaction in an intelligent manner. Emotional interaction is happened among the robots and a robot is biased by the emotional state of the colleague robot in performing task. Here general emotional interaction rules are used for better understanding to read the colleaguepsilas state, for faster communication and better performance eliminating dead time. The characteristics of behavior obtained through simulation are analyzed. A stochastic model based on Markov theory is developed to model the emotional state of each robot.",S. C. Banik; C. D. Pathiranage; Keigo Watanabe; Kiyotaka Izumi,"Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 1-Honjomachi, 840-8502, Japan; Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 1-Honjomachi, 840-8502, Japan; Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 1-Honjomachi, 840-8502, Japan; Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 1-Honjomachi, 840-8502, Japan",2007 International Conference on Industrial and Information Systems,,2007,,,517,522,,,,,,Intelligent robots;Control systems;Multirobot systems;Communication system traffic control;Robot control;Communication system control;Centralized control;Human robot interaction;Robot sensing systems;Decision making,intelligent robots;Markov processes;mobile robots;multi-robot systems,emotionally intelligent robot system;behavior generation;job distributed mobile robot;cooperative mobile robot;human emotion model;multirobot system;emotional interaction;stochastic model;Markov theory,,,22,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1389786,Behavior selection and motion modulation in emotionally grounded architecture for QRIO SDR-4XII,Rule-based Computational Model,Y,Human and external to emotion output ,Eckman,6,Component,General Interaction,Prototype,QRIO,"This paper focuses OD the design and evaluation of behavior module selection and motion modulation based on emotion in the emotionally grounded (EGO) architecture that is applied in autonomous robot QRIO SDR-4 X II. In the EGO architecture, a behavior module is selected based on homeostasis in order for the robot to regulate its internal state within a certain range. Each behavior module has a value called activation level (AL) that is composed of motivation value (Mot) and releasing value (Rel). Mot determines the degree that the instinct drives the behavior module. It is derived from internal state. Rel is the degree that reflects how much external stimuli would satisfy an internal state as a result of the behavior. It is derived from the internal state and external stimuli. Each behavior module competes in AL to select a behavior module. Emotion is a key for motion modulation. It is derived from the internal state, its change, and the expected change of internal state associated with external stimuli in long-term memory. Through the implementation and experiments on QRIO SDR-4X II, we confirm the behavior selection and motion modulation processes in the EGO architecture.",T. Sawada; T. Takagi; M. Fujita,"Networked CE Dev. Lab., Sony Corp., Tokyo, Japan; NA; NA",2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566),,2004,3,,2514,2519 vol.3,,,,,,Human robot interaction;Computer architecture;Prototypes;Speech recognition;Laboratories;Intelligent robots;Artificial intelligence;Motion control;Face recognition;Batteries,motion control;mobile robots;control engineering computing;artificial intelligence,emotionally grounded architecture;motion modulation;autonomous robot;activation level;motivation value;releasing value,,21,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1254772,Behavior selection based on conditioned reflex and emotion,Fuzzy Rule Base,N,Non-emotion stimuli to internal process,Custom Discrete,3,Component,General Interaction,Prototype,Digital,"This paper deals with the behavior control strategy of autonomous robots. Since conditioned reflex and emotions make living things intelligent to adapt to different environments, they are combined with each other in the presented strategy to endow the robot with the ability of adapting to various conditions. The associative memory is also used to enhance the learning efficiency. Simulation results prove that the presented strategy is effective.",Ming Liu; Li Xu,"Coll. of Electr. Eng., Zhejiang Univ., Hangzhou, China; Coll. of Electr. Eng., Zhejiang Univ., Hangzhou, China",Proceedings of the 2003 IEEE International Symposium on Intelligent Control,,2003,,,990,995,,,,,,Educational institutions;Intelligent robots;Production;Associative memory;Learning;Humans;Appraisal;Emotion recognition;Computer architecture;Computational modeling,intelligent robots;content-addressable storage;learning (artificial intelligence),behavior control strategy;autonomous robots;conditioned reflex;associative memory;emotion;reinforcement learning,,1,18,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4153461,Behavioural Affective Modulation of Service Robotic Agents,Factor table,N,User Emotion to emotion output,Binary,2,Component,General Interaction,Prototype,Digital,"In the last years, the interest of the creation of robots with emotions has been one of the principal topics in the roboticist community. The important role of emotions in the control and the organisation of the behaviour of robotic systems has been identified. This branch of robotics has recently been enabled and therefore significant research is expected to be carried out. This paper presents a real-time emotional architecture (RTEA) that allows the regulation of the behaviour of robotic agents to fulfil the objectives depending on the emotional state, on the attitude and on the mental capabilities (processor) of the agent. RTEA has been embedded in a real-time Linux kernel to permit the robot to have a more suitable control of the mental capacity and to guarantee the system integrity. A service robotic application where the robot is programmed with different attitudes shows how each of the attitudes influence the robot behavioural control, the use of the mental capacity and the degrees of satisfaction of the achievement of the objectives",C. Dominguez; H. Hassan; A. Crespo,"Departamento de Inform√°tica de Sistemas y Computadores (DISCA), Universidad Polit√©cnica de Valencia (UPV), Camino de Vera 14 - 46022 Valencia, Spain. carlosd@disca.upv.es, husein@disca.upv.es; Departamento de Inform√°tica de Sistemas y Computadores (DISCA), Universidad Polit√©cnica de Valencia (UPV), Camino de Vera 14 - 46022 Valencia, Spain. husein@disca.upv.es; Departamento de Inform√°tica de Sistemas y Computadores (DISCA), Universidad Polit√©cnica de Valencia (UPV), Camino de Vera 14 - 46022 Valencia, Spain. alfons@disca.upv.es, husein@disca.upv.es",IECON 2006 - 32nd Annual Conference on IEEE Industrial Electronics,,2006,,,4119,4124,,,,,,Control systems;Attitude control;Robot control;Robot sensing systems;Kernel;Real time systems;Linux;Neuroscience;Organisms;Concrete,control engineering computing;Linux;operating system kernels;real-time systems;service robots,behavioural affective modulation;service robotic agents;roboticist community;real-time emotional architecture;real-time Linux kernel;robot behavioural control,,1,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6889813,Bio-inspired architecture for a reactive-deliberative robot controller,Factor table,N,Non-emotion stimuli to internal process,Custom Single,1,Component,Performance,Implemented and Evaluated,MODI,"An incremental, bio-inspired control architecture for robots is proposed. The architecture is composed of two layers where each layer is intended to react in an analogous way to how our brain reacts to external and internal stimuli, using instinctive or deliberative reactions. The first layer, the Drive/Emotional Controller (DE Controller), uses Action Programs which are instinctual, low-level responses to a certain external stimuli. The second layer, the Deliberative/Reflective Controller (DR Controller), can only react to changes in the internal state of the DE controller. Memory, self-reflection, feelings and imagination are some of the concepts that could be considered by the DR Controller architecture, which is intended to generate high-level conscious reactions. These controllers integrate emotions into standard behavior-based architectures. We tested the proposed architecture in a task of free exploration using MODI, a two-wheeled mobile robot. Two DR controllers are tested in three different scenarios validating the proposed architecture in robotic applications.",F. Rubilar; M. Escobar; T. Arredondo,"Universidad T√©cnica Federico Santa Mar√≠a, Department of Electronics Engineering, Avenida Espa√±a 1680, Valpara√≠so, Chile; Universidad T√©cnica Federico Santa Mar√≠a, Department of Electronics Engineering, Avenida Espa√±a 1680, Valpara√≠so, Chile; Universidad T√©cnica Federico Santa Mar√≠a, Department of Electronics Engineering, Avenida Espa√±a 1680, Valpara√≠so, Chile",2014 International Joint Conference on Neural Networks (IJCNN),,2014,,,2027,2035,,,,,,Vectors;MODIS;Robot sensing systems;Actuators;Process control,intelligent robots;mobile robots,bioinspired control architecture;reactive deliberative robot controller;incremental control architecture;drive-emotional controller;action programs;deliberative-reflective controller;DE controller;DR controller architecture;emotion integration;standard behavior-based architecture;MODI;wheeled mobile robot;self-reflection,,2,20,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6385691,Can we teach what emotions a robot should express?,Probability table,N,User Emotion to emotion output,Eckman extension,7,Core,General Interaction,Prototype,Digital,"This paper presents a possibility that we can teach what emotions a robot should express. For this, we design an artificial emotion decision system learned by feedbacks of users. The proposed system consists of three parts: a personality space with probability model, an emotion decision process, and an emotion learning process. (1) The personality space is designed based on the Five-Factor Model. In the personality space, we set up probability distributions of emotions. (2) The emotion decision process determines the probability values of emotions using the probability distributions of emotions in the personality space. (3) The emotion learning process updates the probability distributions by the feedbacks that are the teaching information from users; then, different probability values of emotions are determined. By applying to a humanoid robot system, we have verified the validity of the proposed system by being learned from two persons who have different personalities.",H. S. Ahn; J. Y. Choi,"Intelligent Robotics and Communication Laboratories, Advanced Telecommunications Research Institute International, Kyoto 619-0288, Japan; School of Electrical Engineering and Computer Science, ASRI, PIL, Seoul National University, Korea",2012 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2012,,,1407,1412,,,,,,Probability distribution;Education;Humans;Humanoid robots;Vectors;Psychology,control engineering computing;decision theory;humanoid robots;intelligent robots;learning (artificial intelligence);statistical distributions;teaching,artificial emotion decision system;user feedback;personality space design;emotion learning process;five-factor model;probability distribution;teaching information;humanoid robot system,,6,27,,,,,IEEE,IEEE Conferences,,
,Closing the loop: from affect recognition to empathic interaction,Rule-based Computational Model,N,Non-emotion stimuli to emotion output,Binary,2,Core,General Interaction,Prototype,icat,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7114067,Cognitive emotion model for eldercare robot in smart home,Factor table,N,Human and external to emotion output and internal process,Eckman,6,Core,General interaction,Prototype,Custom Robot,"Based on the smart home and facial expression recognition, this paper presents a cognitive emotional model for eldercare robot. By combining with Gabor filter, Local Binary Pattern algorithm (LBP) and k-Nearest Neighbor algorithm (KNN) are facial emotional features extracted and recognized. Meanwhile, facial emotional features put influence on robot's emotion state, which is described in AVS emotion space. Then the optimization of smart home environment on the cognitive emotional model is specially analyzed using simulated annealing algorithm (SA). Finally, transition probability from any emotional state to a state of basic emotions is obtained based on the cognitive reappraisal strategy and Euclidean distance. The simulation and experiment have tested and verified the effective in reducing negative emotional state.",H. Jing; X. Lun; L. Dan; H. Zhijie; W. Zhiliang,"School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China",China Communications,,2015,12,4,32,41,,,,,eldercare robot;cognitive emotion model;emotional state transition;AVS emotion space;expression recognition;smart home,Smart homes;Robots;Computational modeling;Mouth;Emotion recognition;Analytical models;Senior citizens,control engineering computing;emotion recognition;face recognition;feature extraction;Gabor filters;geriatrics;medical robotics;probability;robot vision;simulated annealing,cognitive emotion model;eldercare robot;smart home;facial expression recognition;Gabor filter;local binary pattern algorithm;LBP;k-nearest neighbor algorithm;KNN;facial emotional feature extraction;AVS emotion space;simulated annealing algorithm;SA;transition probability;emotional state;cognitive reappraisal strategy;Euclidean distance;negative emotional state reduction,,3,,,,,,IEEE,IEEE Magazines,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7011488,Cognitive robots of human character towards development of anthropomimetic robots with human personality,Fuzzy Rule Base,N,User Emotion to emotion output,Custom Discrete,7,Component,General interaction,Prototype,Nao,"It is expected in the future that Robots will be reliable partners of humans in accomplishing different activities and thereby to express high degree of mutual understanding, compatibility and coordination between each-other. In that sense, along with the advance physical abilities, personal robots will be required to perceive, understand and express (use) the emotions as well as to react in a socially accepted manner by enhancing in such a way their interaction with social environment. In a word, robot is expected to possess a character, i.e. personality traits like human as live model. Possessing of character is of great importance for robot-partners due to reason of better acceptance amongst the humans as well as in order to make robots to be able of better understanding people behavior. The fact proved is that high degree of interpersonal compatibility, emotive complementarity and mutual understanding within a team or group ensures better outcomes than the team consists of superior individuals of high intelligence quotients (IQs). People choose partners in a way to be complementary with them and ones that manifest in general sense high level of mutual understandings and agreements. On the other hand, people do not enjoy the opposed persons of incompatible or conflict character. From these reasons, we investigate in the paper the answers if possible and how to give robots different characters i.e. attributes of human personalities.",A. D. Rodiƒá; I. R. Stevanoviƒá; M. D. Jovanoviƒá,"Institute Mihailo Pupin, University of Belgrade, Serbia; Institute Mihailo Pupin, University of Belgrade, Serbia; Institute Mihailo Pupin, University of Belgrade, Serbia",12th Symposium on Neural Network Applications in Electrical Engineering (NEUREL),,2014,,,141,146,,,,,Cognitive robots;emotional intelligence;emotion-driven behavior;social robots;embodied mind,Robot kinematics;Psychology;Robot sensing systems;Social factors;Software;Cognition,humanoid robots,cognitive robots;human character;anthropomimetic robots;human personality;mutual understanding;physical abilities;personal robots;social environment;interpersonal compatibility;intelligence quotients;IQs,,,25,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8028425,Communication atmosphere in humans and robots interaction based on fuzzy analytical hierarchy process,Fuzzy Rule Base,N,User Emotion to emotion output,Cicurmplex,NA,Component,General Interaction,Prototype,Nao,"Communication atmosphere in Human-Robot Interaction (HRI) is estimated by integrating emotional states of humans and robots based on the concept of Fuzzy Atmosfield (FA), where human emotion is estimated from bimodal communication cues (i.e., speech and facial expression) and robot emotion is generated by emotional expression synthesis. Fuzzy Analytical Hierarchy Process (FAHP) is used for dynamic weight calculation of emotional states of humans and robots in the FA model, in which a three-level hierarchy is adopted for the analysis of communication atmosphere and four acoustic cues (i.e., volume, rate, pitch, and duration) are utilized to calculate the dynamic weights. Experiment is conducted in a multi-modal emotional communication based humans-robots interaction (MEC-HRI) system, by which experimental results demonstrate the validity of proposed FA model. Understanding the communication atmosphere can help to facilitate smooth communication between humans and robots by adjusting robot behavior for emotion expression. The proposal is being planned for an atmosphere representation system for realizing causal communication in HRI and background music is being considered for the FA model.",R. Zhang; Y. He; Z. Liu,"School of Automation, China University of Geosciences, Wuhan 430074, China, Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems; School of Automation, China University of Geosciences, Wuhan 430074, China, Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems; School of Automation, China University of Geosciences, Wuhan 430074, China, Hubei Key Laboratory of Advanced Control and Intelligent Automation for Complex Systems",2017 36th Chinese Control Conference (CCC),,2017,,,6767,6772,,,,,Communication Atmosphere;Human-Robot Interaction;Fuzzy Analytical Hierarchy Process;Dynamic Weight,Atmospheric modeling;Robots;Speech;Solid modeling;Real-time systems;Acoustics,analytic hierarchy process;fuzzy control;human-robot interaction,communication atmosphere;fuzzy analytical hierarchy process;human-robot interaction;fuzzy atmosfield;human emotion estimation;bimodal communication cues;robot emotion generation;emotional expression synthesis;FAHP;dynamic weight calculation;three-level hierarchy;acoustic cues;dynamic weights;multimodal emotional communication;MEC-HRI system;emotion expression;atmosphere representation system;causal communication;background music,,2,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6622536,Communication based on Frankl's psychology for humanoid robot partners using emotional model,Rule-based Frankls Psychology,Y,User Emotion to emotion output,Custom Discrete,4,Core,General Interaction,Implemented and Evaluated,Palro,"This paper discusses a robot partner system for natural communication using emotional models. In our daily life, robot partners should have an emotional model in order to co-exist and to realize natural communication with people. In this paper, we propose several emotional models for human-robot interaction based on computational intelligence. First we discuss the importance of emotion and its functions in the social interaction. Next, we propose an emotional model based on emotion, feeling, and mood. Furthermore, we use the emotional model as a method for communication system, and also, we discuss Frankl's psychology as the basis of communication. Finally, we show several experimental results of the proposed method, and discuss the utterance systems for a robot partner.",Jinseok Woo; N. Kubota; J. Shimazaki; H. Masuta; Y. Matsuo; Hun-ok Lim,"Graduate School of System Design, Tokyo Metropolitan University, Japan; Graduate School of System Design, Tokyo Metropolitan University, Japan; Graduate School of System Design, Tokyo Metropolitan University, Japan; Dept. of Mechanical Engineering, Kanagawa University, Yokohama, Japan; Graduate School of System Design, Tokyo Metropolitan University, Japan; Dept. of Mechanical Engineering, Kanagawa University, Yokohama, Japan",2013 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),,2013,,,1,8,,,,,Robot Partners;Emotional Models;Computational Intelligence;Human-robot interaction;Neural Network,Robot sensing systems;Neurons;Educational institutions;Mood;Computational modeling,humanoid robots;human-robot interaction;psychology,Frankl psychology;humanoid robot partner sytem;emotional model;human-robot interaction;computational intelligence;social interaction;communication system;utterance systems,,,36,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=727840,Communication between behavior-based robots with emotion model and humans,Rule-based Biology Model,N,User Emotion to emotion output,Custom Discrete,4,Core,General Interaction,Prototype,WAMOEBA-2,"This study discusses the communication between autonomous robots and humans through the development of a robot which has an emotion model. The model refers to the internal secretion system of humans, and it has four kinds of hormone parameters to be used for adjusting various internal conditions such as motor output cooling fan output and sensor gain. We surveyed 126 visitors at '97 International Robot Exhibition held in Tokyo, Japan, in order to evaluate psychological impressions of the robot. As a result, the human friendliness of the robot was confirmed and some factors of the human-robot emotional communication were discovered.",T. Ogata; S. Sugano,"Dept. of Mech. Eng., Waseda Univ., Tokyo, Japan; NA","SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",,1998,2,,1095,1100 vol.2,,,,,,Humans;Fluids and secretions;Intelligent robots;Robot sensing systems;Psychology;Hardware;Communication system control;Man machine systems;Electronic mail;Biochemistry,robots;man-machine systems;interactive systems,behavior-based robots;emotion model;communications;autonomous robots;man machine systems;psychological impressions;human friendliness,,4,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252082,Computation mechanism for situated sentient robot,Factor table (finite state),N,Human and external to emotion output and internal process,Custom Discrete,24,Component,General Interaction,Prototype,Digital,"Emotions shape how we remember our world, how we perceive it, and which decisions we take. This study proposed a novel three-component computation mechanism that enables a robot to reason about emotions. The mechanism contains the following parts: (i) information acquisition, (ii) formal knowledge description in a form of ontology, and (iii) Bayesian Network (BN). An entropy reduction method from information theory is used to design an effective Human-Robot Interaction (HRI) and to gain a deeper understanding about proposed reasoning mechanism. The method also revealed the most influential BN variables that efficiently resolve the reasoning ambiguities. The modified OCC model of emotions in BN is implemented to ensure adaptation of the system to multiple sources of uncertainty. Variables in a hand crafted BN are linked together, where each link is quantified by spreading influences of a different strength that parent nodes have on child nodes. The paper introduces also the system architecture for realization of the physical robot setup.",T. Stipancic; Y. Ohmoto; S. A. Badssi; T. Nishida,"Graduate school of Informatics, Kyoto University, Kyoto, Japan; Graduate school of Informatics, Kyoto University, Kyoto, Japan; Graduate school of Informatics, Kyoto University, Kyoto, Japan; Graduate school of Informatics, Kyoto University, Kyoto, Japan",2017 Computing Conference,,2017,,,64,73,,,,,affective robotics;emotions;context-awareness;probabilistic graphical models;ontology;ubiquitous computing,Cognition;Robot sensing systems;Games;Ontologies;Uncertainty;Informatics,Bayes methods;belief networks;entropy;human-robot interaction;inference mechanisms;ontologies (artificial intelligence),reasoning mechanism;human-robot interaction;Bayesian network;physical robot setup;modified OCC model;reasoning ambiguities;influential BN variables;information theory;entropy reduction method;formal knowledge description;information acquisition;three-component computation mechanism;situated sentient robot,,,29,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8947977,Computational modeling of Emotion-motivated Decisions for Continuous Control of Mobile Robots,Rule-based Biology Model,N,Non-emotion stimuli to internal process,Custom Discrete,4,Core,Performance,Implemented and Evaluated,Digital,"Immediate rewards are usually very sparse in the real world, which brings a great challenge to plain learning methods. Inspired by the fact that emotional reactions are incorporated into the computation of subjective value during decision-making in humans, an emotion-motivated decision-making framework is proposed in this paper. Specifically, we firstly build a brain-inspired computational model of amygdala-hippocampus interaction to generate emotional reactions. The intrinsic emotion derives from the external reward and episodic memory, and represents three psychological states: valence, novelty and motivational relevance. Then, a model-based decision-making approach with emotional intrinsic rewards is proposed to solve the continuous control problem of mobile robots. This method can execute online model-based control with the constraint of the model-free policy and global value function, which is conducive to getting a better solution with a faster policy search. The simulation results demonstrate that the proposed approach has higher learning efficiency and maintains a higher level of exploration, especially in some very sparse-reward environments.",X. Huang; W. Wu; H. Qiao,"State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China, and also with Beijing Key Laboratory of Research and Application for Robotic Intelligence of Hand-Eye-Brain Interaction, Beijing, 100190 and the University of Chinese Academy of Sciences, Beijing, 100049.; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China, and also with Beijing Key Laboratory of Research and Application for Robotic Intelligence of Hand-Eye-Brain Interaction, Beijing, 100190 and the University of Chinese Academy of Sciences, Beijing, 100049.; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China, also with the Beijing Key Laboratory of Research and Application for Robotic Intelligence of Hand-Eye-Brain Interaction, Beijing, 100190 and the University of Chinese Academy of Sciences, Beijing, 100049, and also with the CAS Center for Excellence in Brain Science and Intelligence Technology, and the Cloud Computing Center, Chinese Academy of Sciences.",IEEE Transactions on Cognitive and Developmental Systems,,2019,PP,99,1,1,,,,,Brain-inspired Computing;Emotion-motivated Learning;Emotion-memory Interactions;Decision-making;Reinforcement Learning.,,,,,,,,,,,IEEE,IEEE Early Access Articles,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1398288,Conceptual spaces and robotic emotions,Rule-based Computational Model,N,Human and external to emotion output and internal process,Binary,2,Component,Performance,Prototype,Digital,"A robot architecture is proposed that integrates in a simple and principled way artificial vision, artificial emotions and symbolic knowledge representation by means of a rich and expressive conceptual representation where affective computing takes place. The role of artificial emotions is to handle the expectation and confirmation mechanism at the basis of the evolution of the architecture. Experimental results are related to an experimental setup in which an anthropomorphic robotic hand system interacts with a human opponent",A. Chella; I. Infantino; I. Macaluso,"DINFO, Palermo Univ., Italy; NA; NA","2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",,2004,1,,144,149 vol.1,,,,,,Orbital robotics;Robot kinematics;Robot sensing systems;Computer architecture;Layout;Human robot interaction;Intelligent robots;Cognitive robotics;Robot vision systems;Anthropomorphism,artificial intelligence;cognitive systems;emotion recognition;knowledge representation;manipulators,conceptual spaces;robotic emotion;robot architecture;artificial vision;artificial emotion;symbolic knowledge representation;confirmation mechanism;anthropomorphic robotic hand system,,1,21,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6100891,Converting emotional voice to motion for robot telepresence,Factor table,N,User Emotion to emotion output,Circumplex,NA,Core,General Interaction,Implemented and Evaluated,Nao,"In this paper we present a new method for producing affective motion for humanoid robots. The NAO robot, like other humanoids, does not possess facial features to convey emotion. Instead, our proposed system generates pose-independent robot movement using a description of emotion through speed, intensity, regularity and extent (DESIRE). We show how the DESIRE framework can link the emotional content of voice and gesture, without the need for an emotion recognition system. Our results show that DESIRE movement can be used to effectively convey at least four emotions with user agreement 60-75%, and that voices converted to motion through SIRE maintained the same emotion significantly higher than chance, even across cultures (German to Japanese). Additionally, portrayals recognized as happiness were rated significantly easier to understand with motion over voice alone.",A. Lim; T. Ogata; H. G. Okuno,"Graduate School of Informatics, Sakyo, Kyoto, Japan; Graduate School of Informatics, Sakyo, Kyoto, Japan; Graduate School of Informatics, Sakyo, Kyoto, Japan",2011 11th IEEE-RAS International Conference on Humanoid Robots,,2011,,,472,479,,,,,,Speech;Emotion recognition;Humanoid robots;Jitter;Joints;Animation,emotion recognition;humanoid robots,affective motion;emotional voice;robot telepresence;NAO robot;DESIRE framework;humanoid robots,,7,37,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4745877,Cooperative Negotiation and Control Strategy of A Shape-shifting Robot,Rule-based Computational Model,N,Non-emotion stimuli to internal process,Custom Discrete,3,Component,Performance,Prototype,Custom Robot,The complex environment requires mobile robots to possess high capability of obstacle negotiation. Cooperative negotiation is proposed to endow the AMOEBA-I robot with capability of obstacle negotiation and to reinforce the adaptability of the robot in unstructured environment. A mathematical model is established. The relationship between the height that the robot can overcome and angle with gravity offset's variation is analyzed theoretically. The maximum heights that conventional negotiation method can reach and cooperative negotiation method can reach are compared. Control strategy of autonomous negotiation is presented. The emotion model is established and the robot's control strategy is fine-tuned according to the change of emotion. Experimental results prove the validity of the cooperative negotiation method and autonomous control strategy.,B. Li; S. Ma; T. Liu; J. Liu,"Robotics Laboratory of Chinese Academy of Sciences, Shenyang Institute of Automation (SIA) No.114 Nanta Street Shenyang, Liaoning, China, libin@sia.cn; Center for Promotion of the COE Program, Ritsumeikan University 1-1-1 Nojihigashi, Kusatsu-Shi Shiga-ken, Japan, shugen@fc.ritsumei.ac.jp; Robotics Laboratory of Chinese Academy of Sciences, Shenyang Institute of Automation (SIA) No. 114 Nanta Street Shenyang, Liaoning, China, tlliu@sia.cn; Robotics Laboratory of Chinese Academy of Sciences, Shenyang Institute of Automation (SIA) No. 114 Nanta Street Shenyang, Liaoning, China, liujinguo@sia.cn","2008 IEEE International Workshop on Safety, Security and Rescue Robotics",,2008,,,53,57,,,,,shape-shifting robot;cooperation;negotiation;emotion,Shape control;Mobile robots;Robotics and automation;Machine intelligence;Gravity;Robot control;Intelligent robots;Potentiometers;Wheels;Conferences,mobile robots,cooperative negotiation;shape-shifting robot;mobile robots;AMOEBA-I robot;obstacle negotiation;unstructured environment;cooperative negotiation method;autonomous negotiation,,2,17,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007506,Decision making based on reinforcement learning and emotion learning for social behavior,Reinforcement Learning,N,Non-emotion stimuli to internal process,Discrete Single,1,Core,General Interaction,Prototype,Digital,"In this paper, we propose a decision making method based on reinforcement learning and emotion learning (DRE) for inducing social behaviors of robots. Emotion of animals has an important role in their social interactions. We attempt to incorporate emotion into decision making of robots. To make a social decision making, the DRE combines a decision based on intrinsic fear emotion with a strategic decision obtained by reinforcement learning. Agents with the DRE learn state values by reinforcement learning and learn emotion values by fear emotion learning. In simulation experiments, the effectiveness of the DRE is verified concerning the emergence of social behaviors and the adaptability to an environmental change through an unmoving target search problem.",A. Matsuda; H. Misawa; K. Horio,"Graduate School of Life Science and Systems Engineering, Kyushu Institute of Technology, 2-4 Hibikino, Wakamatsu, Kitakyushu 808-0196 Japan; Graduate School of Life Science and Systems Engineering, Kyushu Institute of Technology, 2-4 Hibikino, Wakamatsu, Kitakyushu 808-0196 Japan; Graduate School of Life Science and Systems Engineering, Kyushu Institute of Technology, 2-4 Hibikino, Wakamatsu, Kitakyushu 808-0196 Japan",2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011),,2011,,,2714,2719,,,,,decision making;reinforcement learning;emotion;fear emotion learning;social behavior,Robots;Learning;Animals;Decision making;Humans;Adaptation models;Search problems,decision making;learning (artificial intelligence);multi-robot systems;object detection,decision making;reinforcement learning;emotion learning;robot social behaviors;animals emotion;DRE;intrinsic fear emotion;strategic decision;fear emotion learning;unmoving target search problem,,6,8,,,,,IEEE,IEEE Conferences,,
,Design and Evaluation of a Peripheral Robotic Conversation Companion,Rule-based Computational Model,N,Non-emotion stimuli to emotion output,Discrete Custom,3,Trivial,General Interaction,Implemented and Evaluated,Kipl,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4058870,Design of a Social Mobile Robot Using Emotion-Based Decision Mechanisms,Factor table,Y,Non-emotion stimuli to emotion output,PAD,NA,Component,general Interaction,Prototype,RWI Magellan Pro,"In this paper, we describe a robot that interacts with humans in a crowded conference environment. The robot detects faces, determines the shirt color of onlooking conference attendants, and reacts with a combination of speech, musical, and movement responses. It continuously updates an internal emotional state, modeled realistically after human psychology research. Using empirically-determined mapping functions, the robot's state in the emotion space is translated to a particular set of sound and movement responses. We successfully demonstrate this system at the AAAI '05 Open Interaction Event, showing the potential for emotional modeling to improve human-robot interaction",G. A. Hollinger; Y. Georgiev; A. Manfredi; B. A. Maxwell; Z. A. Pezzementi; B. Mitchell,"The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA 15213. gholling@andrew.cmu.edu; Department of Engineering, Swarthmore College, Swarthmore, PA 19081. yavor.georgiev@alum.swarthmore.edu; Department of Engineering, Swarthmore College, Swarthmore, PA 19081. amanfre1@swarthmore.edu; Department of Engineering, Swarthmore College, Swarthmore, PA 19081. maxwell@swarthmore.edu; Department of Computer Science, Johns Hopkins University, Baltimore, MD 21218. zap@cs.jhu.edu; Department of Computer Science, Johns Hopkins University, Baltimore, MD 21218. ben@cs.jhu.edu",2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2006,,,3093,3098,,,,,human-robot interaction;robot emotions;face recognition,Mobile robots;Decision making;Intelligent robots;Human robot interaction;Orbital robotics;Ethics;Face detection;Robot sensing systems;Educational institutions;Computer science,face recognition;intelligent robots;mobile robots;robot vision,social mobile robot;emotion-based decision mechanisms;face detection;internal emotional state;AAAI '05 Open Interaction Event;human-robot interaction,,16,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1491594,Design of behavior decision system with storage in mobile robots,Factor table,N,Human and external to emotion output and internal process,Discrete Custom,10,Component,general Interaction,Model,NA,"This paper presents a design of the previous proposed behavior decision system with storage in mobile robots. An index, that is, the functional called tension level with two or more emotions and fuzzy similarity level are noticed as important factors. The former is memorized with another data in a storage module and is used in a reproduction module and a behavior decision module. The latter is used in a matching processing between memory and current status.",S. Yamada; M. Katoh; Xue Li; K. Wada,"Osaka Inst. of Technol., Japan; Osaka Inst. of Technol., Japan; Osaka Inst. of Technol., Japan; Osaka Inst. of Technol., Japan",SICE 2004 Annual Conference,,2004,2,,1159,1163 vol. 2,,,,,,Mobile robots;Polynomials;Emotion recognition;Data processing;Image storage;Frequency;Roads;Safety;Brightness;Temperature,mobile robots;storage media;fuzzy set theory,mobile robot;storage system;tension level;behavior decision system;fuzzy similarity level;reproduction module,,,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6839819,Design of emotion generation model and action selection for robots using a Self Organizing Map,Factor table,N,Human and external to emotion output and internal process,Discrete Custom,6,Component,Performance,Prototype,Robotic Arm,"Our research has been focused on developing an interaction between humans and robots to enhance an intellectual action of the service robots. From our previous research, we have constructed a model of mechanism of consciousness and behaviors, this software architecture is called Consciousness-Based Architecture (CBA). Furthermore, the robot should select the action and express the emotion by itself, which depends on its surrounding environment. Therefore, this research presents a system which forms and expresses the emotions of the robot. The intrinsic motivation and external situations of robot are used to analyze and classify the behavior and the emotion by a Self-Organizing Map (SOM). We attempt to describe the integration of a behavior map and an emotion map into CBA module. We confirmed the effectiveness of the proposed system by an experiment in an environment using a conscious behavior robot (Conbe-I).",W. Jitviriya; E. Hayashi,"Dept. of Mechanical Information Science and Technology, Kyushu Institute of Technology (Iizuka campus), Fukuoka, Japan; Dept. of Mechanical Information Science and Technology, Kyushu Institute of Technology (Iizuka campus), Fukuoka, Japan","2014 11th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON)",,2014,,,1,6,,,,,Motivation module;Self-Organizing Map (SOM);Emotion model;Consciousness-Based Architecture (CBA),Green products;Vectors;Cameras;Robot vision systems;Equations;Mathematical model,emotion recognition;human-robot interaction;intelligent robots;self-organising feature maps;service robots;software architecture,intellectual action;service robots;consciousness-based architecture;CBA module;intrinsic motivation;external robot situations;behavior classification;emotion classification;self-organizing map;SOM;conscious behavior robot;Conbe-I,,1,12,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5651005,Designing reactive emotion generation model for interactive robots,Rule-based - Computational Model,N,Human and external to emotion output ,Discrete Custom,4,Core,General Interaction,Prototype,GOMY,Design of reactive emotion generation mechanism for interactive robots is proposed in this paper. Sorts of reactive emotions and the framework to generate these emotions against stimuli were identified based on psychological researches on humans' emotions. Computational models of reactive emotion system were also proposed with dynamic models. Each model realized necessary characteristics for reactive process successfully. The developed model was implemented in a toy-like robot which is called `GOMY'. The robot can show emotional response reactively against stimulus change. The proposed reactive emotion model can be considered as the most basic foundation of general emotional process for interactive robots.,H. Kim; S. Koo; D. Kwon,"Human-Robot Interaction Research Center, Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea; Human-Robot Interaction Research Center, Department of Mechanical Engineering, KAIST, Daejeon, Republic of Korea; Human-Robot Interaction Research Center and with Faculty of Mechanical Engineering, KAIST, Daejeon, Republic of Korea",2010 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2010,,,2270,2275,,,,,,Computational modeling;Mathematical model;Adaptation model;Equations;Robot sensing systems;Appraisal,emotion recognition;humanoid robots;human-robot interaction;psychology,reactive emotion generation model;interactive robots;psychology;humans' emotions;toy-like robot;GOMY,,1,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4937697,Developing preferential attention to a speaker: A robot learning to recognise its carer,Factor table ,N,User Emotion to Internal Process and emotion output,Custom Discrete,5,Component,General Interaction,Prototype,Erwin,"In this paper we present a socially interactive multi-modal robotic head, ERWIN - Emotional Robot With Intelligent Networks, capable of emotion expression and interaction via speech and vision. The model presented shows how a robot can learn to attend to the voice of a specific speaker, providing a relevant emotional expressive response based on previous interactions. We show three aspects of the system; first, the learning phase, allowing the robot to learn faces and voices from interaction. Second, recognition of the learnt faces and voices, and third, the emotion expression aspect of the system. We show this from the perspective of an adult and child interacting and playing a small game, much like an infant and caregiver situation. We also discuss the importance of speaker recognition in terms of human-robot-interaction and emotion, showing how the interaction process between a participant and ERWIN can allow the robot to prefer to attend to that person.",J. C. Murray; L. Canamero,"Adaptive Systems Research Group, University of Hertfordshire, College Lane, Hatfield, AL10 9AB, UK; Adaptive Systems Research Group, University of Hertfordshire, College Lane, Hatfield, AL10 9AB, UK",2009 IEEE Symposium on Artificial Life,,2009,,,77,84,,,,,,Human robot interaction;Intelligent robots;Robot vision systems;Speaker recognition;Emotion recognition;Speech recognition;Face recognition;Adaptive systems;Educational institutions;Intelligent networks,emotion recognition;face recognition;human-robot interaction;intelligent networks;learning (artificial intelligence);speaker recognition,robot learning;interactive multimodal robotic head;ERWIN;Emotional Robot With Intelligent Networks;emotion expression;speaker recognition;human-robot-interaction,,,21,,,,,IEEE,IEEE Conferences,,
,Development of an Emotion-Competent SLAM Agent,Rule-based Biology Model,Y,Non-emotion stimuli to internal process and emotion,Circumplex,NA,Component,Performance,Implemented and Evaluated,Digital,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6926287,Development of behavior and emotion models for Conbe-I using a Self-Organizing Map learning,Factor table ,N,Non-emotion stimuli to internal process and emotion,Custom Discrete,5,Component,General Interaction,Prototype,Conbe-I,"We are attempting to develop a robot with a ‚Äúconsciousness‚Äù resembling that of a human or an animal in order to enhance an intellectual activity of the robot. In our previous study, we have constructed a model of mechanism of consciousness and behaviors based on the relationship between the action strategies and consciousness levels, this software architecture is called Consciousness-Based Architecture (CBA) module. In addition, the robot should select the behavior and express the emotion by itself, which depends on its surrounding environment. Therefore, in this paper, we have examined the intrinsic motivation and the external situations of robot are used to analyze and classify the behavior and the emotion by a Self-Organizing Map (SOM) that is trained using unsupervised learning, and we attempt to describe the integration of a behavior map and an emotion map into a CBA module. The conscious behavior robot (Conbe-I) has been implemented to show the effectiveness of the proposed system.",W. Jitviriya; M. Koike; E. Hayashi,"Graduated School of Computer Science and System Engineering, Kyushu Institute of Technology, Fukuoka, Japan; Graduated School of Computer Science and System Engineering, Kyushu Institute of Technology, Fukuoka, Japan; Dept. of Mechanical Information Science and Technology, Faculty of Computer Science and System Engineering, Kyushu Institute of Technology, Fukuoka, Japan",The 23rd IEEE International Symposium on Robot and Human Interactive Communication,,2014,,,411,416,,,,,Consciousness-Based Architecture (CBA);Motivation Module;Self-Organizing Map (SOM);Emotion model,Mathematical model;Equations;Service robots;Neurons;Green products;Vectors,control engineering computing;humanoid robots;intelligent robots;learning (artificial intelligence);self-organising feature maps;software architecture,behavior model;emotion model;conscious behavior robot;Conbe-I;self-organizing map learning;SOM;robot intellectual activity;software architecture;consciousness-based architecture module;CBA module,,,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5756911,Dynamic behaviour conception for EmI companion robot,Factor table ,N,Human and external to emotion output,Eckman,6,Core,General interaction,Prototype,Digital,"This article presents research work done in the domain of nonverbal emotional interaction for the EmotiRob project. It is a component of the MAPH project, the objective of which is to give comfort to vulnerable children and/or those undergoing long-term hospitalisation through the help of an emotional robot companion. It is important to note that we are not trying to reproduce human emotion and behavior, but trying to make a robot emotionally expressive. The studies carried out on perception and emotional synthesis have allowed us to develop our emotional model of interaction: iGrace. iGrace actually allow a system display emotions as a static mode. This mode has ever been evaluated with our avatar: ArtE, we developped in Flash. The rate of satisfaction (86%) of the evaluation allowed us embeded static mode on our robotics platform: EmI - Emotional Model of Interaction. Now, we want add dynamics on EmI robot and add lifelike in its reactions. This paper will present different hypothesis we used for iGrace emotional model, algorithm for behaviour dynamic , evaluation for static and dynamic mode, and EmI robotics conception. We begin the article by MAPH and EmotiRob project presentation. Then, we quickly describe the computational model of emotional experience iGrace that we have created, the integration of dynamics and iGrace evaluation. We conclude with a description of the architecture of Emi, as well as improvements to be made to its next generation.",S. Saint-Aime; C. Jost; B. Le-Pevedic; D. Duhaut,"Valoria - University of Bretagne Sud, Vannes, France; Valoria - University of Bretagne Sud, Vannes, France; Valoria - University of Bretagne Sud, Vannes, France; Valoria - University of Bretagne Sud, Vannes, France",ISR 2010 (41st International Symposium on Robotics) and ROBOTIK 2010 (6th German Conference on Robotics),,2010,,,1,8,,,,,,Robot kinematics;Avatars;Humans;Eyebrows;Lips;Speech,,,,1,,,,,,VDE,VDE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6181741,Effect of emotional synchronization using facial expression recognition in human-robot communication,Factor table ,N,User Emotion to emotion output,Circumplex,NA,Core,General interaction,Implemented and Evaluated,KAMIN_FA1,"In this paper, we developed a KANSEI communication system between human and robot based on emotional synchronization to human emotional state using facial expression recognition. And we conducted experiments to evaluate the effectiveness of the proposed system. The robot recognizes human emotion through their facial expressions, and synchronizes its own emotion with the recognized emotion dynamically by using a vector field of dynamics. Then the robot expresses its own emotions by facial expressions. In the communication experiment, we found that the subjects' feeling became much comfortable after communicating with the robot in the case of emotional synchronization, while that the subjects felt a little uncomfortable after communicating with the robot in the case of non-synchronization. Meanwhile, subjects in the case of emotional synchronization communicated much more with the robot, and the communication time was as double times as the time when communicated in the case of non-synchronization. Furthermore, subjects communicated in the case of emotional synchronization had good impressions on the robot, and also were much better than the impressions in the case of non-synchronization. So it was confirmed in this study that the emotional synchronization in human-robot communication could be effective to make human keeping a comfortable state and would make the robot much more favorable and acceptable to human.",Y. Li; M. Hashimoto,"Department of Kansei Engineering, Shinshu University, Nagano, Japan; Shinshu University, Ueda, Nagano 386-8567, Japan",2011 IEEE International Conference on Robotics and Biomimetics,,2011,,,2872,2877,,,,,,Humans;Robots;Synchronization;Emotion recognition;Face recognition;Vectors;Face,emotion recognition;human-robot interaction,emotional synchronization;facial expression recognition;human robot communication;KANSEI communication system;human emotional state;communication time,,5,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5326232,Effects of emotional synchronization in human-robot KANSEI communications,Factor table ,N,User Emotion to emotion output,Circumplex,NA,Core,General interaction,Implemented and Evaluated,KAMIN_FA1,"Human-robot communication is an important subject for housekeeping, elderly care and entertainment robots. To make a natural communication entrainment between human and robot, emotion plays a vital role. From this view point we have developed a KANSEI communication system based on emotional synchronization. The robotic emotion was entrained to human emotion by using a vector field of dynamics, and then the robot made a facial expression to express the robot emotion. In this paper we investigate the effect of the emotional synchronization in human-robot KANSEI communications. We conducted experiments to evaluate the effects of the proposed system based on emotional synchronization. In the experiments of human-robot interaction using the emotional synchronization, we found that human feeling became comfortable when the robot made the synchronized facial expression to human emotion. Then it was confirmed that emotional synchronization in human-robot interaction could be effective to keep a comfortable state.",M. Hashimoto; M. Yamano; T. Usui,"Shinshu University, Japan; Shinshu University, Japan; Okamura Corporation, Japan",RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,,2009,,,52,57,,,,,,Human robot interaction;Robot sensing systems;Senior citizens;Intelligent robots;Artificial intelligence;Aging;Hospitals;Symbiosis;Displays;Atmosphere,artificial intelligence;emotion recognition;humanoid robots;human-robot interaction,emotional synchronization;human-robot KANSEI communication;robotic emotion;vector field;human-robot interaction,,7,10,,,,,IEEE,IEEE Conferences,,
,Eliciting caregiving behavior in dyadic human-robot attachment-like interactions,Rule-based - Computational Model,x,Non-emotion stimuli to internal process and emotion,Single (Arousal),1,Core,General interaction,Implemented and Evaluated,AIBO,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6722184,Embedded Design of an Emotion-Aware Music Player,Rule-based - Computational Model,N,User Emotion to emotion output,Discrete Custom,6,Core,General Interaction,Implemented and Evaluated,Digital,"In this paper, a novel human-robot interaction(HRI) design is proposed where emotional recognition from the speech signal is used to create an emotion-aware music player that can be implemented in an embedded platform. The proposed system maps an inputted short-speech utterance to a two dimensional emotional plane of valence and arousal. This strategy allows the system to automatically select a piece of music from a database of songs, of which emotions are also expressed using arousal and valence values. Furthermore, a cheer-up strategy is proposed such that music songs with varying emotional content are played in order to cheer up the user to a more neutral/happy state. The proposed system has been implemented in a Beagle board. The online test verified the feasibility of the system. A questionnaire survey shows that 80% of subjects agree with the songs selected by the proposed cheer-up strategy based on the emotional model.",C. A. Cervantes; K. Song,"Inst. of Electr. Control Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan; Inst. of Electr. Control Eng., Nat. Chiao Tung Univ., Hsinchu, Taiwan","2013 IEEE International Conference on Systems, Man, and Cybernetics",,2013,,,2528,2533,,,,,emotion recognition;human-robot interaction;emotional model,Speech;Databases;Feature extraction;Speech recognition;Emotion recognition;Speech processing;Vectors,embedded systems;emotion recognition;human-robot interaction;music;speech processing,Beagle board;short-speech utterance;speech signal;emotional recognition;HRI design;human-robot interaction;emotion-aware music player;embedded design,,1,23,,,,,IEEE,IEEE Conferences,,
,Embodying Care in Matilda: An Affective Communication Robot for Emotional Wellbeing of Older People in Australian Residential Care Facilities,Fuzzy Rule Base,N,Human and external to emotion output and internal process,Binary,2,Component,General Interaction,Implemented and Evaluated,Matilda,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,Embodying care in Matilda: an affective communication robot for the elderly in Australia,Fuzzy Rule Base,N,Human and external to emotion output and internal process,Binary,2,Component,General Interaction,Implemented and Evaluated,Matilda,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506869,Emergence of mind in robots for human interface - research methodology and robot model,Factor table,N,Non-emotion stimuli to emotion output,Custom Discrete,4,Component,General Interaction,Prototype,WAMOEBA-IR,"The objective of this work is to develop the technology for human-machine communication through the research of the emergence of mind in mechanical systems. In this paper, the hypothesis about the emergence of mind is proposed. First, a system chart expressing the human brain information processing and the development of an autonomous mobile robot ""WAMOEBA-IR"" (Waseda artificial mind on emotion base) are described. The conception of the WAMOEBA-IR design is that robots should have a self-presentation evaluation function. Further more, the method to evaluate the whole system is described from the viewpoint of the animal psychology. As a result of the experiments, WAMOEBA-IR showed specific emotional reactions with color appearances to some situations. WAMOEBA-IR has the sense of values about colors and sounds based on self-preservation as the first step of the emergence of mind.",S. Sugano; T. Ogata,"Dept. of Mech. Eng., Waseda Univ., Tokyo, Japan; Dept. of Mech. Eng., Waseda Univ., Tokyo, Japan",Proceedings of IEEE International Conference on Robotics and Automation,,1996,2,,1191,1198 vol.2,,,,,,Humans;Communications technology;Man machine systems;Mobile communication;Mechanical systems;Information processing;Mobile robots;Robot sensing systems;Animals;Psychology,mobile robots;intelligent control;man-machine systems;biocybernetics;brain models,robot model;human interface;human-machine communication;emergence of mind;human brain information processing;autonomous mobile robot;WAMOEBA-IR;Waseda artificial mind;self-presentation evaluation function;emotional reactions,,34,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030013,Emergent emotion via neural computational energy conservation on a humanoid robot,Neural network,N,Non-emotion stimuli to internal process,Custom Single,1,Core,Performance,Implemented and Evaluated,DaRwIn-OP,"This paper presents our initial work on how emotion based behaviors may emerge through computational mechanisms. We hold that in addition to basic emotions such as anger and fear that serves bodily well being of the organism, high level emotions such as boredom and affection have evolved to facilitate low cost brain computations. Higher level of emotions can be considered as affective state of the organism or mood, rather than the reflex-like physiologically triggered emotional responses such as fear and anger. In large and complex brains (e.g. primate brains), the neuronal energy consumption for cognition is non-negligible. We propose that for such organisms computational regulatory mechanisms for decision making give rise to behaviors that can be explained by various emotional states. As a proof of concept for this idea, we envision a robotic cognitive system and a select function that we assign a neural cost for its operation. To be concrete, we use a small humanoid robot platform (Darwin-OP) and implement a neural network (Hopfield Network) that allows the robot to recall learned patterns that it sees through its camera. As a model of neural computational energy consumption, we postulate that a change in the state of a neural unit of the network consumes one unit of (neural) energy. Therefore, the total computational energy consumed is determined by the incoming stimuli. The robot is programmed to avoid high energy consumption by showing aversive behavior when the energy consumption is high. Otherwise, the robot demonstrates engaging behavior. For an external observer these responses may be perceived as robot's having certain emotional (affectional) preference for input stimuli. In this article in addition to robot experiments, we also emphasize the biological support for our proposal and provide detailed exposition of biological background and its relevance for the hypothesis that (certain) emotions may emerge through computational mechanisms.",M. Kƒ±rtay; E. Oztop,"Department of Computer Science, √ñzyeƒüin University, √áekmek√∂y Campus, Ni≈üantepe Mah., Orman Sk. No:13, 34794, ƒ∞stanbul/Turkey; Department of Computer Science, √ñzyeƒüin University, √áekmek√∂y Campus, Ni≈üantepe Mah., Orman Sk. No:13, 34794, ƒ∞stanbul/Turkey",2013 13th IEEE-RAS International Conference on Humanoid Robots (Humanoids),,2013,,,450,455,,,,,,Robots;Energy consumption;Biology;Convergence;Neural networks;Cameras;Noise,cognitive systems;control engineering computing;decision making;emotion recognition;Hopfield neural nets;humanoid robots,emotion based behavior;neural computational energy conservation;humanoid robot;Darwin-OP;robotic cognitive system;neural network;Hopfield network;decision making,,2,15,,,,,IEEE,IEEE Conferences,,
,Emotion and Memory Model to Promote Mathematics Learning - An Exploratory Long-term Study,Rule-based Computational Model,Y,Human and external to emotion output and internal process,Binary,2,Component,General Interaction,Implemented and Evaluated,Nao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999495,Emotion dynamic express by fuzzy function for emotion robot,Fuzzy Rule Base,N,Non-emotion stimuli to internal process,Discrete Custom,3,Core,Performance,Prototype,Lego,This paper proposes the novel emotion dynamic equation for emotion implementation like human's emotion by fuzziness. Almost general method use artificial approach such as neutral networks to classify emotion by using speech and face image data for human's emotion recognition. But high-dimension and large size of this data cause low-speed learning in robot system. The main idea of the proposed dynamic equation method is to dynamically express emotion by fuzzy function.,D. Kim; P. Baranyi; Nair,"Dept. of Instrumentation and Control Eng., Hanbat National University, Daejeon City, Korea; Cognitive Informatics research group involved in the System and Control Laboratory, Computer and Automation Research Institute of the Hungarian Academy of Sciences (MTA SZTAKI); IITG, India",2011 2nd International Conference on Cognitive Infocommunications (CogInfoCom),,2011,,,1,4,,,,,,Robot sensing systems;Mood;Engines;Sockets;Face,emotion recognition;fuzzy set theory;learning (artificial intelligence);mobile robots;neural nets,emotion dynamic express;fuzzy function;emotion robot;emotion dynamic equation;emotion implementation;artificial approach;neutral networks;emotion classification;speech data;face image data;human emotion recognition;low-speed learning;dynamic equation method,,1,12,,,,,IEEE,IEEE Conferences,,
,Emotion Influenced Robotic Path Planning,Rule-based Computational Model,N,Non-emotion stimuli to internal process,Custom Discrete,2,Component,Performance,Prototype,Digital,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7257263,Emotion inspired adaptive robotic path planning,Reinforcement learning,N,Non-emotion stimuli to internal process,NA (Learnt in training),NA,Core,Performance,Implemented and Evaluated,Pioneer P3-DX,"This paper presents an emotion inspired adaptive path planning approach for autonomous robotic navigation. Ideally a robotic navigation system should adapt its path planning and behaviour to overcome a variety of obstacles within an environment, without the need for single location planning approaches. Emotional analogies are appealing as they enable general planning, but require hard coding of `emotions'. Humans have a bias on what is an emotion, e.g. fear, which can adversely affect performance. We aim to provide the robot with the generalising ability of emotion without the pre-specifying bias. Inspired by theories on `emotion', the system presented utilises a Learning Classifier System (LCS) to learn a `bow-tie' structure of emotional reinforcers to intermediary emotion categories to a behavioural modifier that adapts the robot's navigation behaviour. The emotional states are not pre-set and are judged post learning based on the learned behaviour. The bow-tie creates a simple compact set of rules to adapt a robot's behaviour to better navigate its environment. The emotion system was verified on a state-of-the-art navigation system to learn a variety of parameters that control the robot's behaviour. The results show two easy to understand learned emotional states; the first is considered to be a model `fear', which increases obstacle avoidance while lowering speed when pain is induced or novelty is high. The second emotion is considered to be `happiness', which increases speed and lowers wall avoidance when pain is not present. Compared to the default non-adapting navigation system, the emotional responses decreased the overall number of collisions and improved time to navigate.",H. Williams; C. Lee-Johnson; W. N. Browne; D. A. Carnegie,"School of Engineering and Computer Science, Victoria University of Wellington; School of Engineering and Computer Science, Victoria University of Wellington; School of Engineering and Computer Science, Victoria University of Wellington; School of Engineering and Computer Science, Victoria University of Wellington",2015 IEEE Congress on Evolutionary Computation (CEC),,2015,,,3004,3011,,,,,,Robot sensing systems;Navigation;Collision avoidance;Pain;Accuracy;Biology,adaptive control;collision avoidance;learning systems;mobile robots,emotion inspired adaptive robotic path planning;autonomous robotic navigation;emotional analogies;learning classifier system;LCS;emotional reinforcer bow-tie structure;obstacle avoidance;wall avoidance,,2,29,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4415108,Emotion Interaction System for a Service Robot,Factor table,N,User Emotion to emotion output,Custom Discrete,4,Core,General interaction,Implemented and Evaluated,Digital,"This paper introduces an emotion interaction system for a service robot. The purpose of emotion interaction systems in service robots is to make people feel that the robot is not a mere machine, but reliable living assistant in the home. The emotion interaction system is composed of the emotion recognition, generation, and expression systems. A user's emotion is recognized by multi-modality, such as voice, dialogue, and touch. The robot's emotion is generated according to a psychological theory about emotion: OCC (Ortony, Clore, and Collins) model, which focuses on the user's emotional state and the information about environment and the robot itself. The generated emotion is expressed by facial expression, gesture, and the musical sound of the robot. Because the proposed system is composed of all the three components that are necessary for a full emotional interaction cycle, it can be implemented in the real robot system and be tested. Even though the multi- modality in emotion recognition and expression is still in its rudimentary stages, the proposed system is shown to be extremely useful in service robot applications. Furthermore, the proposed framework can be a cornerstone for the design of emotion interaction and generation systems for robots.",D. Kwon; Y. K. Kwak; J. C. Park; M. J. Chung; E. Jee; K. Park; H. Kim; Y. Kim; J. Park; E. H. Kim; K. H. Hyun; H. Min; H. S. Lee; J. W. Park; S. H. Jo; S. Park; K. Lee,"Dept. of Mechanical Engineering, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea. e-mail: kwonds@kaist.ac.kr; Dept. of Mechanical Engineering, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Computer Science Division, EECS Department, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Electrical Engineering Division, EECS Department, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; JS Human & Robot Music Research Institute, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Dept. of Mechanical Engineering, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Dept. of Mechanical Engineering, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Dept. of Mechanical Engineering, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Dept. of Mechanical Engineering, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Dept. of Mechanical Engineering, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Dept. of Mechanical Engineering, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Computer Science Division, EECS Department, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Electrical Engineering Division, EECS Department, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Electrical Engineering Division, EECS Department, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Electrical Engineering Division, EECS Department, KAIST, Daejeon, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Dept. of Composition, Han-Yang Univ., Seoul, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea; Bundang Saemmul Christian School, Seongnam-si, Korea; Human-Robot Interaction Research Center, KAIST, Daejeon, Korea",RO-MAN 2007 - The 16th IEEE International Symposium on Robot and Human Interactive Communication,,2007,,,351,356,,,,,,Service robots;Human robot interaction;Emotion recognition;Robot sensing systems;Cognitive robotics;Mechanical engineering;Speech recognition;Psychology;System testing;Acoustic sensors,emotion recognition;service robots,service robot;emotion interaction system;emotion recognition;emotion generation;emotion expression system;psychological theory;facial expression,,11,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1013194,Emotion model in robot assisted activity,Fuzzy Rule Base,N,Human and external to emotion output,Binary,2,Component,General Interaction,Model,NA,"This paper discusses the robot assisted activity, which is physical and mental support for a human. The author proposes a function (mood congruent effect) that modifies the behavior of a robot based on its own emotion, and a control model (emotion-driven agent model) for the robot. The emotion-driven agent model has a recurrent type association memory and hierarchical knowledge. In the simulation, the agent showed a psychological defensive reaction.",T. Hashimoto,"Dept. of Urban Econ., Nasu Univ., Japan",Proceedings 2001 IEEE International Symposium on Computational Intelligence in Robotics and Automation (Cat. No.01EX515),,2001,,,184,188,,,,,,Robots;Helium;Humans;Mood;Psychology;Aging;Control systems;Fuzzy cognitive maps;Animals;Knowledge engineering,robots;knowledge based systems;man-machine systems;software agents,robot assisted activity;mental support;mood congruent effect;emotion model;emotion-driven agent;association memory;hierarchical knowledge,,3,5,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1067995,Emotion-based control of cooperating heterogeneous mobile robots,Factor table,N,Non-emotion stimuli to internal process,Custom Discrete,7,Component,Performance,Implemented and Evaluated,Digital,"Previous experiences show that it is possible for agents such as robots cooperating asynchronously on a sequential task to enter deadlock, where one robot does not fulfil its obligations in a timely manner due to hardware or planning failure, unanticipated delays, etc. Our approach uses a formal multilevel hierarchy of emotions where emotions both modify active behaviors at the sensory-motor level and change the set of active behaviors at the schematic level. The resulting implementation of a team of heterogeneous robots using a hybrid deliberative/reactive architecture produced the desired emergent societal behavior. Data collected at two different public venues illustrate how a dependent agent selects new behaviors (e.g., stop serving, move to intercept the refiner) to compensate for delays from a subordinate agent (e.g., blocked by the audience). The subordinate also modifies the intensity of its active behaviors in response to feedback from the dependent agent. The agents communicate asynchronously through knowledge query and manipulation language via wireless Ethernet.",R. R. Murphy; C. L. Lisetti; R. Tardif; L. Irish; A. Gage,"Dept. of Comput. Sci. & Eng., Univ. of South Florida, Tampa, FL, USA; NA; NA; NA; NA",IEEE Transactions on Robotics and Automation,,2002,18,5,744,757,,,,,,Mobile robots;Robot sensing systems;System recovery;Delay;Computer science;Hardware;Feedback;Ethernet networks;Multirobot systems;Transportation,mobile robots;multi-robot systems;wireless LAN;emotion recognition;multi-agent systems,emotion-based control;cooperating heterogeneous mobile robots;sequential task;deadlock;unanticipated delays;formal multilevel hierarchy;hybrid deliberative/reactive architecture;emergent societal behavior;public venues;dependent agent;knowledge query;manipulation language;wireless Ethernet;cooperative teams;interdependent tasks,,53,42,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4399080,Emotion-based parameter modulation for a hierarchical mobile robot planning and control architecture,Rule-based Computational Model,N,Non-emotion stimuli to internal process,Custom Discrete,5,Core,Performance,Prototype,Digital,"Autonomous robots are presently unable to match the adaptive capabilities of even the simplest of animals. Affective processes such as emotions are highly effective facilitators of adaptive behavior in humans and animals. Thus, it can be argued that emotions can bestow robots with similar adaptive advantages. In particular, artificial emotions can improve a robot's performance by modulating actions, prioritizing goals and providing reinforcements for learning. A hierarchical robot architecture that incorporates reactive and deliberative emotions has been developed to test this hypothesis. Reactive emotions arise from predictions of emotion-eliciting events from short-term sensor data and internal representations. Deliberative emotions are modeled as learned associations between environmental states and previous emotion-eliciting events. Emotions interact with multiple architectural levels by modulating parameters controlling the robot's degree of bias towards various competing drives, such as goal-seeking, safety and exploration. The model has been implemented on a simulated mobile robot for a navigation task.",C. P. Lee-Johnson; D. A. Carnegie,"Victoria University of Wellington, New Zealand; Victoria University of Wellington, New Zealand",2007 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2007,,,2839,2844,,,,,,Mobile robots;Robot control;Human robot interaction;Robot sensing systems;Intelligent robots;Control systems;Animals;Cognitive robotics;USA Councils,artificial intelligence;mobile robots;path planning,emotion-based parameter modulation;hierarchical mobile robot planning;autonomous robots;artificial emotions;emotion-eliciting events;navigation task,,4,27,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7554491,Emotion-Driven Attention of the robotic manipulator for action selection,Self-organizing map,N,User Emotion to Internal Process,Custom Discrete,2,Core,Performance,Prototype,Robot Arm,"The capacity of attention is crucial for robotic manipulator performing many tasks. This paper presents an Emotion-Driven Attention(EDA) model for robotic manipulator action selection, which integrates emotion with the robotic manipulator to manage its attention allocation, and enable it react to emotional social cue appropriately. During the interaction with human, the human's facial expression can be recognized by the robot in the real-time, which is considered as a social cue to trigger a corresponding emotion of the robot by Self-Organizing Map (SOM). Then, the robot's emotion plays as a reinforcement signal to regulate the attention parameters, guiding the robot's visual attention on the identified object and making it behave appropriately according to the human intentions, e.g., grasping or avoiding the object. We estimate the proposal in both simulated situations and interactive scenarios, the robot's simulated attention intensity and the attention behaviors driven by different emotions indicates the effectiveness of the proposal.",Y. Mei,"Information and Electric Engineering College, Hunan University of Arts and Science, Changde 415000, China",2016 35th Chinese Control Conference (CCC),,2016,,,7173,7178,,,,,Robotic Manipulator;Action Selection;Attention Mechanism;Artificial Emotion;Facial Expression,Manipulators;Appraisal;Resource management;Robot sensing systems;Face recognition,control engineering computing;emotion recognition;face recognition;human-robot interaction;manipulators;self-organising feature maps,emotion-driven attention;robotic manipulator;action selection;EDA;emotional social cue;facial expression;self-organizing map;SOM;reinforcement signal,,,26,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1442120,Emotion-sensitive robots - a new paradigm for human-robot interaction,Rule-based Computational Model,N,Human and external to emotion output ,Binary,2,Component,General Interaction,Implemented and Evaluated,Oracle,"An emotion-sensitive human-robot cooperation framework where a robot is sensitive to the emotions of the human working with it and is also capable of changing its behavior based on this perception is presented in this paper. Peripheral physiological responses of a human are measured through wearable biofeedback sensors to detect and identify his/her underlying level of anxiety. A control architecture inspired by Riley's original information-flow model is designed. In this human-robot interaction framework, the robot is responsive to the psychological states of the human and detects both implicit and explicit communication from the human to determine its own behavior. Human-robot cooperation experiments using a mobile robot as a test bed are performed where the robot senses anxiety level of the human and responds appropriately. The results presented here validate the proposed framework and demonstrated a new way of achieving emotion-based interaction between a human and a robot.",P. Rani; N. Sarkar,"Dept. of Electr. Eng. & Comput. Sci., Vanderbilt Univ., Nashville, TN, USA; Dept. of Electr. Eng. & Comput. Sci., Vanderbilt Univ., Nashville, TN, USA","4th IEEE/RAS International Conference on Humanoid Robots, 2004.",,2004,1,,149,167 Vol. 1,,,,,,Human robot interaction;Robot sensing systems;Mobile robots;Anthropometry;Biosensors;Communication system control;Psychology;Mobile communication;Testing;Performance evaluation,mobile robots;man-machine systems;feedback;intelligent robots;self-adjusting systems;biosensors;emotion recognition,emotion-sensitive robots;human-robot interaction;emotion-sensitive human-robot cooperation framework;peripheral physiological responses;wearable biofeedback sensors;Riley original information-flow model;implicit communication;explicit communication;mobile robot,,11,64,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8023271,Emotional action generation model supporting real-time operation,Markovain emotional model,N,User Emotion to emotion output,Custom Discrete,7,Core,General Interaction,Prototype,Digital,"In this paper, we propose an emotional action generation model for robots that supports real-time operation. Emotional actions make users feel better. However, some conventional robot emotion generation models do not support real-time operation and do not generate natural actions that make users feel better. The proposed model enables robots to perform natural actions that positively influence communication between the user and the robot. Through two simulations, we evaluate the generation of emotional actions and real-time operation. The experimental results confirm confirmed the effectiveness of the proposed model.",T. Nakamura; H. Takenouchi; M. Tokumaru,"Graduate School of Kansai University, 6-2-1 Kizugawa-dai, Kizugawa-shi, Kyoto 619-0225, Japan; Fukuoka Institute of Technology, Fukuoka 811-0295, Japan; Kansai University, 3-3-35 Yamate-cho, Suita-shi, Osaka 564-8680, Japan",2017 Joint 17th World Congress of International Fuzzy Systems Association and 9th International Conference on Soft Computing and Intelligent Systems (IFSA-SCIS),,2017,,,1,5,,,,,robot;real-time;emotional action,Real-time systems;Robot sensing systems;Euclidean distance;Markov processes;Psychology;Shape,emotion recognition;human-robot interaction,emotional action generation model;real-time operation;conventional robot emotion generation models;natural action generation,,,9,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6916374,Emotional and Conditional Model for Pet Robot based on Neural Network,Neural network,N,User Emotion to emotion output,PAD,NA,Core,General Interaction,Prototype,Pet Robot,"Recently more and more pet robot products are launched, showing the increasing market demand for pet robots. A pet robot has a healing effect for suitably developing companionship with people. A plenty of researches pointed out that the interaction between human and robot is important. This paper introduces the concentration and conditioning to model the emotion and behavior of a pet robot. For the overall system of this pet robot, a condition matrix is properly designed to support the pet robot for the adaption of several kinds of stimuli and response about behaviors. The behavior controller is achieved by the means of a neural network with learning mechanism, which can be trained for the behavioral control of voice, expression and action. All these mechanisms are established by psychological principles, accordingly the pet robot can behave naturally.",C. M. Hsu; T. T. Chen; J. S. Heh,"Dept. of Inf. & Comput. Eng., Chung Yuan Christian Univ., Chungli, Taiwan; Dept. of Inf. & Comput. Eng., Chung Yuan Christian Univ., Chungli, Taiwan; Dept. of Inf. & Comput. Eng., Chung Yuan Christian Univ., Chungli, Taiwan",2014 7th International Conference on Ubi-Media Computing and Workshops,,2014,,,305,308,,,,,Pet Robot;Classical Conditioning;Neural Network;Emotion Model;Learning Agent,Positron emission tomography;Robot sensing systems;Mobile robots;Neural networks;Educational institutions;Computers,human-robot interaction;learning (artificial intelligence);neural nets,psychological principles;action behavioral control;expression behavioral control;voice behavioral control;learning mechanism;condition matrix;human-robot interaction;neural network;pet robot;emotional model;conditional model,,5,22,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4209403,Emotional Architecture for the Humanoid Robot Head ROMAN,Factor table,N,Human and external to emotion output ,Eckman,6,Core,General Interaction,Prototype,ROMAN,"Humanoid robots as assistance or educational robots is an important research topic in the field of robotics. Especially the communication of those robots with a human operator is a complex task since more than 60% of human communication is conducted non-verbally by using facial expressions and gestures. Although several humanoid robots have been designed it is unclear how a control architecture can be developed to realize a robot with the ability to interact with humans in a natural way. This paper therefore presents a behavior-based emotional control architecture for the humanoid robot head ROMAN. The architecture is based on 3 main parts: emotions, drives and actions which interact with each other to realize the human-like behavior of the robot. The communication with the environment is realized with the help of different sensors and actuators which will also be introduced in this paper.",J. Hirth; N. Schmitz; K. Berns,"Robotics Research Lab, Department of Computer Science, University of Kaiserslautern Germany. Email: j_hirth@informatik.uni-kl.de; Robotics Research Lab, Department of Computer Science, University of Kaiserslautern Germany. Email: nschmitz@informatik.uni-kl.de; Robotics Research Lab, Department of Computer Science, University of Kaiserslautern Germany. Email: berns@informatik.uni-kl.de",Proceedings 2007 IEEE International Conference on Robotics and Automation,,2007,,,2150,2155,,,,,humanoid robot head;emotional architecture;behavior based control,Humanoid robots;Magnetic heads;Educational robots;Human robot interaction;Robotics and automation;Machine intelligence;Eyes;Computer science;Communication system control;Robot sensing systems,humanoid robots;intelligent robots;man-machine systems,humanoid robot head;ROMAN;facial expressions;gestures;human-robot interaction;behavior-based emotional control,,33,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4150072,Emotional Communication with the Robot Head MEXI,Rule-based Computational Model,Y,Human and external to emotion output,Custom Discrete,4,Component,General interaction,Prototype,Mexi,"This paper presents the robot head MEXI which is able to communicate to humans in an emotional way. MEXI recognizes emotions of its human counterpart from the prososdy of his or her natural speech using a fuzzy rule based approach. MEXI reacts on its perceptions by showing artificial emotions in its facial expressions and in the prosody of its synthesized natural speech. MEXI does not rely on a world model to control and plan its actions like usual goal based agents. Instead MEXI uses its internal state consisting of emotions and drives to evaluate its perceptions and action alternatives and controls its behavior on the basis of this evaluation. For MEXI, the behavior based programming paradigm originally developed by Arkin for robot navigation was extended to support a multidimensional control architecture based on emotions and drives",N. Esau; L. Kleinjohann; B. Kleinjohann,"C-LAB, University of Paderborn, Paderborn, Germany. nesau@c-lab.de; C-LAB, University of Paderborn, Paderborn, Germany. lisa@c-lab.de; C-LAB, University of Paderborn, Paderborn, Germany. bernd@c-lab.de","2006 9th International Conference on Control, Automation, Robotics and Vision",,2006,,,1,7,,,,,human-robot communication;robot head;emotion;drive;reactive architecture;behavior based;emotional control,Humans;Emotion recognition;Communication system control;Computer architecture;Humanoid robots;Natural languages;Robot sensing systems;Intelligent robots;Speech analysis;Speech recognition,artificial intelligence;emotion recognition;fuzzy set theory;man-machine systems;robot programming;robot vision,emotional communication;robot head MEXI;fuzzy rule;behavior based programming;robot navigation;multidimensional control architecture;human-robot communication,,4,23,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304330,Emotional contagion and personality driven multi-robot task allocation algorithm,Rule-based Computational Model,N,Non-emotion stimuli to internal process,Custom Discrete,4,Core,Performance,Prototype,Digital,"Many scholars in the fields of psychology and computer science have already carried out in-depth research on emotions and established some related models. But how to deal with the cooperation among emotional robots in task allocation is a new research issue. In this paper, we research the emotion and personality of robot, the influencing mechanism of emotions among robots, and propose an algorithm of multi-robot task allocation based on emotional contagion which turns robots' emotions into a positive state. According to different emotion values and personalities, we select the robot with a higher value of leadership as the team leader, and then choose other team members based on emotional contagion, thus forming a team that meets the mission requirements. Finally, experiments analyze factors affecting emotional contagion model and verify the effectiveness of the proposed algorithm.",B. Fang; Z. Wang; Y. Li; W. Hao,"School of Computer and Information, Hefei University of Technology, Hefei 230009, China; CAAC Academy of Flight, Technology and Safety, Civil Aviation Flight, University of China, Guanghan, China; School of Computer and Information, Hefei University of Technology, Hefei 230009, China; School of Computer and Information, Hefei University of Technology, Hefei 230009, China","2017 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)",,2017,,,503,508,,,,,Task allocation;Affective robot;Emotional contagion;Personality,Robot kinematics;Task analysis;Resource management;Mathematical model;Attenuation;Security,multi-robot systems;psychology,emotional robots;personality;personalities;emotional contagion model;emotion values;multirobot task allocation algorithm,,,19,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8470348,Emotional Contagion System By Perceiving Human Emotion Based on Physiological Signals,Markovain emotional model - HMM,Y,User Emotion to Internal Process,Custom Discrete,6,Core,General Interaction,Prototype,Digital,"The various wearable equipment enables the robot to measure some people emotional analysis by physiological signals. In our research, we present one emotional contagion system which could develop robotic emotion based on human interactive emotion. First, we research the physiological emotion recognition as the robotic sensory generation. Second, this paper considers the influence of the sensory on perception generation and establishes a tensor representing the real-time perception. Finally, based on previous work, we establish the emotional transition model for generating the robotic emotion and considering the correlation between the previous perception and emotion for cognitive and emotional continuity. In experiment part, we invited six postgraduates wrapping the wearable strap to watch 40 kinds of affective videos. We recorded their physiological signals while be transferring to the robot synchronously. We find emotional contagion system could have the superior performance with whatever is single user's interactive situation or multi-users' one.",M. Li; L. Xie; Z. Tan; Z. Wang; F. Ren,"School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing, China; College of Computer Science, Hefei University of Technology, Hefei, China",2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia),,2018,,,1,6,,,,,emotional contagion system;physiological signals;sensory generation;perception;emotional state transition,Robot sensing systems;Hidden Markov models;External stimuli;Emotion recognition;Cognition,emotion recognition;human-robot interaction;wearable robots,emotional contagion system;physiological signals;human interactive emotion;physiological emotion recognition;robotic sensory generation;emotional transition model;cognitive continuity;wearable equipment,,,20,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4406829,Emotional head robot with behavior decision model and face recognition,Rule-based Computational Model,N,Rule-based Computational Model,Custom Discrete,12,Component,General Interaction,Prototype,PIL ,"There has been a lot of research for developing intelligent robots that can effectively perform human robot interaction. Our motivation for this research is to develop a robot that can interact with people and assist them in their daily routines, in common places such as homes, super markets, hospitals or offices. In order to accomplish these tasks a robot must be human friendly showing some emotions and exhibiting a friendly character and personality. We present an emotional and behavior based intelligent head robot that performs face recognition, and effectively communicates with people by expressing emotions using a 3D character on its screen. The behavior of the robot depends on its interaction with people. Face recognition capability of our robot is a novel classification method based on Support Vector Domain Description (SVDD). This method allows the system to be trained rapidly and improve the recognition rate gradually by learning face incrementally. For the emotional behavior of the system we implement an emotional behavior decision model that defines the character of our robot and makes different behavior decisions.",Ho Seok Ahn; Pyo Jae Kim; Jeong Hwan Choi; Shamyl Bin Mansoor; Woo-Sung Kang; Seok Min Yoon; Jin Hee Na; Young Min Baek; Hyung Jin Chang; Dong Sung Song; Jin Young Choi; Hyeong-Seok Ko,"School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea; School of Electrical Engineering and Computer Science, Automation and Systems Research Institute, Seoul National University, Seoul, Korea","2007 International Conference on Control, Automation and Systems",,2007,,,2719,2724,,,,,Emotional Robot;Head Robot;Emotion Expression;Face Recognition,Face recognition;Human robot interaction;Intelligent robots;Robotics and automation;Emotion recognition;Speech recognition;Head;Humanoid robots;Speech synthesis;Control system synthesis,avatars;emotion recognition;face recognition;robots,face recognition;intelligent robots;human robot interaction;emotional-based intelligent head robot;behavior-based intelligent head robot;3D character;classification method;support vector domain description;emotional behavior decision model;behavior decisions,,5,8,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8470388,Emotional Human Machine Conversation Generation Based on SeqGAN,GAN (LSTM),N,User Emotion to emotion output,Custom Discrete,5,Core,General Interaction,Prototype,Digital,"In recent years, artificial intelligence has made a significant breakthrough and progress in the field of humanmachine conversation. However, how to generate high-quality, emotional and subhuman conversation still a troublesome work. The key factor of man-machine dialogue is whether the chatbot can give a good response in content and emotional level. How to ensure that the robot understands the user's emotions, and consider the user's emotions then give a satisfactory response. In this paper, we add the emotional tags to the post and response from the dataset respectively. The emotional tags, as the emotional tags of post and response, represent the emotions expressed by this sentence. The purpose of our emotional tags is to make the chatbot understood the emotion of the input sequence more directly so that it has a recognition of the emotional dimension. In this paper, we apply the mechanism of GAN network on our conversation model. For the generator: We make full use of Encoder-Decoder structure form a seq2seq model, which is used to generate a sentence's response. For the discriminator: distinguish between the human-generated dialogues and the machine-generated ones.The outputs from the discriminator are used as rewards for the generative model, pushing the system to generate dialogues that mostly resemble human dialogues. We cast our task as an RL(Reinforcement Learning) problem, using a policy gradient method to reward more subhuman conversational sequences, and in addition we have added an emotion tags to represent the response we want to get, which we will use as a rewarding part of it, so that the emotions of real responses can be closer to the emotions we specify. Our experiment shows that through the introduction of emotional intelligence, our model can generate responses appropriate not only in content but also in emotion, which can be used to control and adjust users emotion. Compared with our previous work, we get a better performance on the same data set, and we get less ''safe'' response than before, but there will be a certain degree of existence.",X. Sun; X. Chen; Z. Pei; F. Ren,"School of Computer and Information, Hefei University of Technology, Hefei, Anhui, China; School of Computer and Information, Hefei University of Technology, Hefei, Anhui, China; School of Computer and Information, Hefei University of Technology, Hefei, Anhui, China; School of Computer and Information, Hefei University of Technology, Hefei, Anhui, China",2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia),,2018,,,1,6,,,,,Seq2Seq;Reinforcement-Learning;GAN;Emotional category;Emotion Intelligence,Logic gates;Task analysis;Neurons;Gallium nitride;Man-machine systems;Robots;Emotion recognition,codecs;discriminators;emotion recognition;gradient methods;human computer interaction;humanoid robots;interactive systems;learning (artificial intelligence),emotional intelligence;users emotion;emotional human machine conversation generation;emotional level;emotional tags;SeqGAN;artificial intelligence;high-quality conversation;troublesome work;man-machine dialogue;chatbot;content level;robot;satisfactory response;emotional dimension recognition;GAN network;conversation model;encoder-decoder structure;seq2seq model;sentences response;human-generated dialogues;discriminator;generative model;human dialogues;reinforcement learning problem;policy gradient method;subhuman conversational sequences,,3,27,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6926286,Emotional memories in autonomous robots,Rule-based Biology Model,Y,Human and external to emotion output and internal process,Custom Discrete,8,Core,General Interaction,Model,NA,"This is a theoretical study aiming at proposing a computation model for memory and emotion, using ideas inspired by neuroscience research into neural-endocrine systems interaction. Human robot interaction (HRI) ideally requires the robot to be able to detect emotional changes and understand the emotional implications of these changes. The model proposed here will allow a robot to create its own emotional memory, and to use that memory to predict future emotional states based on past experiences. This model would be able to monitor the emotional state of a person, to identify if that individual is in a state of flow, providing positive support and at times praise that may be needed. Further evaluation and validation are proposed including a study case.",R. Valverde Ib√°√±ez; M. U. Keysermann; P. A. Vargas,"Robotics Laboratory, School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, UK; Robotics Laboratory, School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, UK; Robotics Laboratory, School of Mathematical and Computer Sciences, Heriot-Watt University, Edinburgh, UK",The 23rd IEEE International Symposium on Robot and Human Interactive Communication,,2014,,,405,410,,,,,,Robots;Biochemistry;Adaptation models;Predictive models;Computational modeling;Labeling;Encoding,artificial intelligence;human-robot interaction;neurophysiology,emotional memories;autonomous robots;neuroscience research;neural-endocrine systems interaction;human robot interaction;HRI;emotional memory,,3,51,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6563853,Emotional models for multi-modal communication of robot partners,Rule-based Computational Model,Y,Non-emotion stimuli to emotion output,Custom Discrete,4,Core,General Interaction,Prototype,iPhonoid,"This paper discusses the availability of emotional models for natural communication of robot partners with people. Recently, the need of robot partners to support elderly people in their daily life is increasing. Such a robot should have an emotional model in order to co-exist with people, and to realize natural communication with people. In this paper, we propose several computational models for emotional interactions of robot partners based on computational intelligence. First, we discuss the functions of emotion in social interaction. Next, we propose an emotional model based on emotions, feelings, and mood. Furthermore, we propose a method for multi-modal communication based on the emotional model. Finally, we show several experimental results of the proposed method, and discuss the availability of the emotional models.",A. Yorita; J. Botzheim; N. Kubota,"Graduate School of System Design, Tokyo Metropolitan University, Tokyo, Japan; Graduate School of System Design, Tokyo Metropolitan University, Tokyo, Japan; Graduate School of System Design, Tokyo Metropolitan University, Tokyo, Japan",2013 IEEE International Symposium on Industrial Electronics,,2013,,,1,6,,,,,Robot Partners;Emotional Models;Computational Intelligence;Human-robot interaction,Robot sensing systems;Mood;Computational modeling;Senior citizens;Educational institutions,,,,9,17,,,,,IEEE,IEEE Conferences,,
,Emotional Robot Pursuit Task Allocation Algorithm Based on Emotional Constraint,Rule-based Computational Model,N,Non-emotion stimuli to internal process,Custom Single,1,Component,Performance,Implemented and Evaluated,Digital,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4259908,Emotional Sensibility and Behavioural Control of Real-Time Robotic Agents,Rule-based Computational Model,N,Non-emotion stimuli to internal process,Binary (courage and fear),2,Core,Performance,Prototype,Digital,"Recent research in emotional systems has identified the important role of emotions in the control and the organisation of the behaviour of robotic systems. RTEA is a real-time emotional architecture for robotic agents. Emotions in RTEA modulate the thoughts' motivation that affect the final agent's behaviour. An emotional state is reached from the appraisal of a situation of the environment. The way this appraisal contributes to the emotional state and how this state affects the behaviour depends on the emotional sensibility. This paper focuses in the adjustment of the sensibility of the agent. A key point in the process of situation appraisal is the configuration of the contribution functions (CF). An adaptation of a multivariable optimisation method to find the optimal CF that affect the modulation of the emotion level and hence the robot anima, is proposed. Experiments on mobile robotics show that the adjustment of the emotional sensibility produces stable and predictable behavioural control.",C. Dominguez; H. Hassan; A. Crespo,"Departamento de Inform√°tica de Sistemas y Computadores (DISCA), Universidad Polit√©cnica de Valencia (UPV), Camino de Vera 14 - 46071 Valencia, Spain, carlosd@disca.upv.es; Departamento de Inform√°tica de Sistemas y Computadores (DISCA), Universidad Polit√©cnica de Valencia (UPV), Camino de Vera 14 - 46071 Valencia, Spain, husein@disca.upv.es; Departamento de Inform√°tica de Sistemas y Computadores (DISCA), Universidad Polit√©cnica de Valencia (UPV), Camino de Vera 14 - 46071 Valencia, Spain, alfons@disca.upv.es",2006 World Automation Congress,,2006,,,1,6,,,,,robotics;agent;intelligence;appraisal system;emotion;behaviour;real-time,Robot control;Robot sensing systems;Appraisal;Control systems;Mobile robots;Orbital robotics;Robotics and automation;Real time systems;Optimization methods;Intelligent robots,behavioural sciences;emotion recognition;mobile robots;real-time systems;software agents,emotional sensibility;behavioural control;real-time robotic agent;emotional system;real-time emotional architecture;situation appraisal system;contribution function;multivariable optimisation;robot anima;mobile robotics,,,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007428,Emotional states based 3-D Fuzzy Atmosfield for casual communication between humans and robots,Fuzzy Rule Base,N,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital,"Emotional states based three-dimensional (3-D) Fuzzy Atmosfield (FA) is proposed to express the feeling between humans and robots in communication, and is built with 3-D coordinates, i.e. ""friendly-hostile"", ""lively-calm"", and ""casual formal"" axes. The FA aims to be an effective tool to proceed with the communication paying attention to the atmosphere generated by individual emotional state which is calculated from bimodal communication cues namely emotional-speech and emotional gesture by using weighted fusion and fuzzy inference. A novel emotion recognition approach is presented which consists of two steps, i.e., classification of six basic emotions for initial emotional states in the Affinity-Pleasure-Arousal emotion space, and emotional transition from prior state by using fuzzy logic. Home party enjoying demonstration confirms FA's availability empirically by questionnaires from unrelated persons of authors' group, where smooth communication between four humans and five eye robots is realized in Mascot Robot System.",Z. Liu; F. Dong; K. Hirota; M. Wu; D. Li; Y. Yamazaki,"Department of Computational, Intelligence and Systems Science, Tokyo Institute of Technology, Yokohama, Japan; Department of Computational, Intelligence and Systems Science, Tokyo Institute of Technology, Yokohama, Japan; Department of Computational, Intelligence and Systems Science, Tokyo Institute of Technology, Yokohama, Japan; School of Information Science and Engineering, Central South University, Changsha, P. R. China; School of Information Science and Engineering, Central South University, Changsha, P. R. China; Department of Electrical, Electronic, and Information Engineering, Kanto Gakuin University, Yokohama, Japan",2011 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE 2011),,2011,,,777,782,,,,,human-robot communication;emotion recognition;emotional state;communication atmosphere;fuzzy inference,Robots;Emotion recognition;Speech;Speech recognition;Humans;Atmosphere;Semantics,emotion recognition;fuzzy logic;fuzzy reasoning;fuzzy set theory;human-robot interaction;robot vision,emotional states based 3D fuzzy atmosfield;casual human-robot communication;3D coordinates;friendly-hostile axes;lively-calm axes;casual-formal axes;bimodal communication cues;emotional-speech;emotional-gesture;weighted fusion;fuzzy inference;emotion recognition approach;affinity-pleasure-arousal emotion space;emotional transition;fuzzy logic;mascot robot system;eye robots,,4,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1044234,Emotionally influenced coordination of behaviors for autonomous mobile robots,Rule-based Biology Model,N,Non-emotion stimuli to internal process,Binary,2,Component,General interaction,Prototype,Digital,A model of amygdala is used for an emotional intervention on a behavior coordination mechanism for autonomous mobile robot navigation. Behaviors such as goal following and obstacle avoidance ones are a priori derived by Q-learning. A collision free goal following behavior is carried out by combining of previously learned behaviors. The basic mechanism of this behavior coordination is based on simple summation of corresponding action value functions. The artificial emotion mechanism is proposed to weigh the different action value functions in the summation process. The proposed behavior coordination method improves the performance of the navigation system with respect to its obstacle avoidance capability. The results are confirmed by simulations.,D. D. Tsankova,"Control Syst. Dept., Tech. Univ. of Sofia, Plovdiv, Bulgaria",Proceedings First International IEEE Symposium Intelligent Systems,,2002,1,,92,97 vol.1,,,,,,Mobile robots;Robot kinematics;Navigation;Robotic assembly;Intelligent robots;Organisms;Learning;Biological neural networks;Artificial neural networks;Convergence,mobile robots;robot programming;collision avoidance,amygdala;emotional intervention;behavior coordination mechanism;autonomous mobile robot navigation;obstacle avoidance;action value functions;summation process;navigation system;Q-learning;collision free goal following behavior,,3,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1398413,Emotionally motivated reinforcement learning based controller,Fuzzy Rule Base,N,User Emotion to emotion output,Custom Discrete,3,Core,General Interaction,Prototype,Lego,There have been several attempts to model emotions in autonomous agents and robotics. The use of emotions in conjunction with reinforcement learning in particular has attracted attention since both notions are borrowed analogies from psychology. The work presented here is an approach to robot control based on modeling emotions within reinforcement learning algorithm. The main contribution of this paper is the use of fuzzy cognitive maps (FCM) to facilitate the modeling of emotions and inferencing for action selection. This approach does not use feeling estimation; instead a direct link between sensory data and emotions is used for emotional estimation. An emotion based reinforcement learning algorithm is proposed for action selection in robotic control,A. Ayesh,"De Montfort Univ., Leicester, UK","2004 IEEE International Conference on Systems, Man and Cybernetics (IEEE Cat. No.04CH37583)",,2004,1,,874,878 vol.1,,,,,,Learning;Psychology;Computational intelligence;Neural networks;Fuzzy cognitive maps;Cognitive robotics;Robot control;Robot sensing systems;Inference algorithms;Fuzzy logic,cognitive systems;fuzzy set theory;learning (artificial intelligence);robots,emotionally motivated reinforcement learning;robot control;fuzzy cognitive maps;emotional estimation,,14,21,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4600648,EmotiRob: An emotional interaction model,Rule-based Computational Model,N,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital - EmotiRob,"This paper presents our work on the therapeutic robotics project EmotiRob which is the continuity of the MAPH (active media for the handicap) project in emotion synthesis. Our aim is to maintain emotional interaction with children. For this, word, movement, and emotion synthesis are used. After defining a face for our robot, which is a compromise between the richness of expression and simplified mechanics, we propose the internal model of it in order to achieve and maintain emotional interaction.",S. Saint-Aime; B. Le Pevedic; D. Duhaut,"Valoria Laboratory of the University of Bretagne Sud, Vannes, France; Valoria Laboratory of the University of Bretagne Sud, Vannes, France; Valoria Laboratory of the University of Bretagne Sud, Vannes, France",RO-MAN 2008 - The 17th IEEE International Symposium on Robot and Human Interactive Communication,,2008,,,89,94,,,,,,Robots,handicapped aids;interactive systems;medical robotics,EmotiRob;emotional interaction model;therapeutic robotics;active media;handicap,,4,23,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7376599,Empathic Interaction Using the Computational Emotion Model,Fuzzy Rule Base,N,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital - Grimace,"This paper describes the empathy oriented human-robot interaction model. It is projected to design the model capable of different empathic responses (parallel and reactive) during the course of interaction with the user, depending upon the personality and mood factors of the robot. The proposed model encompasses three main stages i.e., Perception, empathic appraisal and empathic expression. Perception refers to capturing user's emotion state via facial expression recognition. Empathic appraisal is based on the computational emotional model for generating its internal emotions, mood state and empathic responses. The internal emotions are defined using psychological studies and generated on 2D (pleasure-arousal) scaling model, whereas, fuzzy logic is used to calculate the intensity of the each emotion. A virtual facial expression simulator is applied for expression of resultant empathic emotions. Preliminary experimental results show that the proposed model is capable of exhibiting different empathic responses with respect to the personality and mood factors.",Z. Rasool; N. Masuyama; M. N. Islam; C. K. Loo,"Dept. of Artificial Intell., Univ. of Malaya, Kuala Lumpur, Malaysia; Dept. of Artificial Intell., Univ. of Malaya, Kuala Lumpur, Malaysia; Dept. of Artificial Intell., Univ. of Malaya, Kuala Lumpur, Malaysia; Dept. of Artificial Intell., Univ. of Malaya, Kuala Lumpur, Malaysia",2015 IEEE Symposium Series on Computational Intelligence,,2015,,,109,116,,,,,,Computational modeling;Shape;Mood;Robots;Face;Face recognition;Clustering algorithms,emotion recognition;human-robot interaction,empathic interaction;computational emotion model;empathy oriented human-robot interaction model;empathic response;robot personality;robot mood factor;perception stage;empathic appraisal stage;empathic expression stage;facial expression recognition;computational emotional model;pleasure-arousal scaling model;fuzzy logic;virtual facial expression simulator,,,37,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8068769,Empathizing with emotional robot based on cognition reappraisal,Markovain emotional model - HMM,Y,User Emotion to emotion output,PAD,NA,Core,General Interaction,Prototype,Digital,"This paper proposes a continuous cognitive emotional regulation model for robot in the case of external emotional stimulus from interactive person's expressions. It integrates a guiding cognitive reappraisal strategy into the HMM (Hidden Markov Model) emotional interactive model for empathizing between robot and person. The emotion is considered as a source in the 3D space (Arousal, Valence, and Stance). State transition and emotion intensity can be quantitatively analyzed in the continuous space. This cognition-emotion interactive model have been verified by the expression and behavior robot. Empathizing is the main distinguishing feature of our work, and it is realized by the emotional regulation which operated in a continuous 3D emotional space enabling a wide range of intermediate emotions. The experiment results provide evidence with acceptability, accuracy, richness, fluency, interestingness, friendliness and exaggeration that the robot with cognition and emotional control ability could be better accepted in the human-robot interaction (HRI).",X. Liu; L. Xie; Z. Wang,"School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China; School of Computer and Communication Engineering, University of Science and Technology Beijing, Beijing 100083, China",China Communications,,2017,14,9,100,113,,,,,emotional robot;human-robot interaction;guiding cognitive reappraisal;emotional regulation;active field emotion space,Robots;Hidden Markov models;Cognition;Psychology;Three-dimensional displays;Aerospace electronics;Biological system modeling,cognition;emotion recognition;hidden Markov models;human-robot interaction;interactive systems,emotional robot;cognition reappraisal;continuous cognitive emotional regulation model;external emotional stimulus;guiding cognitive reappraisal strategy;HMM emotional interactive model;Hidden Markov Model;cognition-emotion interactive model;behavior robot;continuous 3D emotional space;intermediate emotions;emotional control ability;human-robot interaction;interactive person expression;emotional regulation,,1,,,,,,IEEE,IEEE Magazines,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=365929,Emulation of emotion using vision with learning,Factor table,N,Non-emotion stimuli to internal process and emotion,Custom Discrete,6,Core,Performance,Prototype,R-3,"Concerns the implementation of emotional behavior in an artificial agent. Action Selection Dynamics (ASD), or Behavior Network, provides Subsumption Architecture (SA) with additional flexibility in coordinating behavior activation in a fully distributed manner. The agent can effectively monitor the environment and adapt to changes as they occur rather than the human observer having to manually adjust the priority structure that governs behavior action. The addition of vision to this framework provides an additional sensory input so that the SA robot with ASD is further aware of its environment at all times. The vision system was designed and implemented based on a behavior-based vision methodology. With the vision added, the robot can respond to minute changes in the environment, which other sensors are not capable of detecting, while at the same time it enhances the area of the environment that is monitored. This makes the interaction between the robot and human considerably richer. Responses by the robot are based on comments the robot receives from a human interrogator. The robot's response to its environment is unique each time it is run, an important consideration when emulating human-like emotions. Further interaction with humans in the environment is provided with the addition of speech recognition/synthesis capabilities to the robot. Furthermore, the robot will not only demonstrate human-like emotions through its behaviors but with the addition of the speech it can also vocalize those emotions.<>",T. Gomi; K. Ide,"Appl. AI Syst. Inc., Ottawa, Ont., Canada; Appl. AI Syst. Inc., Ottawa, Ont., Canada",Proceedings of 1994 3rd IEEE International Workshop on Robot and Human Communication,,1994,,,210,215,,,,,,Emulation;Robot kinematics;Robot sensing systems;Variable speed drives;Monitoring;Robot vision systems;Human robot interaction;Humanoid robots;Machine vision;Speech recognition,intelligent control;robot vision;learning (artificial intelligence);computerised monitoring,emotion emulation;vision;learning;Action Selection Dynamics;Behavior Network;Subsumption Architecture;ASD;SA;environment monitoring;human-like emotions,,5,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8956386,Establishing Human-Robot Trust through Music-Driven Robotic Emotion Prosody and Gesture,Rule-based - Computational Model,Y,User Emotion to emotion output,Circumplex,NA,Core,General Interaction,Implemented and Evaluated,Shimi,"As human-robot collaboration opportunities continue to expand, trust becomes ever more important for full engagement and utilization of robots. Affective trust, built on emotional relationship and interpersonal bonds is particularly critical as it is more resilient to mistakes and increases the willingness to collaborate. In this paper we present a novel model built on music-driven emotional prosody and gestures that encourages the perception of a robotic identity, designed to avoid uncanny valley. Symbolic musical phrases were generated and tagged with emotional information by human musicians. These phrases controlled a synthesis engine playing back pre-rendered audio samples generated through interpolation of phonemes and electronic instruments. Gestures were also driven by the symbolic phrases, encoding the emotion from the musical phrase to low degree-of-freedom movements. Through a user study we showed that our system was able to accurately portray a range of emotions to the user. We also showed with a significant result that our non-linguistic audio generation achieved an 8% higher mean of average trust than using a state-of-the-art text-to-speech system.",R. Savery; R. Rose; G. Weinberg,"Georgia Tech Center for Music Technology,Atlanta,GA,USA; Georgia Tech Center for Music Technology,Atlanta,GA,USA; Georgia Tech Center for Music Technology,Atlanta,GA,USA",2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN),,2019,,,1,7,,,,,,,affective computing;human-robot interaction;music;social aspects of automation,human-robot trust;music-driven robotic emotion prosody;gesture;human-robot collaboration;affective trust;emotional relationship;interpersonal bonds;human musicians;nonlinguistic audio generation;music-driven emotional gestures,,,54,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4631205,Evolutionary personalized robotic doll: GomDoll,Probability table,N,Non-emotion stimuli to emotion output ,Custom Continuous,4,Component,General Interaction,Prototype,GomDoll,"Genetic robot is one of artificial creatures and has its own genome in which each chromosome consists of many genes that contribute to defining its personality. By using the concept of genetic robot, this paper proposes personalized robotic doll by applying evolutionary process to generate unique propensity, defined by its genome. A genome population is evolved such that it customizes the genome satisfying a propensity desired by user based on Big Five personality dimensions. Robotic doll has emotion and motivation to reflect its internal state and to provide human friendly interaction. To demonstrate the effectiveness of this scheme, a bear-like robotic doll, GomDoll, is developed and the evolved genome is implanted to it to see its manner of internal and external responses to stimuli.",Dong-Hyun Lee; Jong-Hwan Kim,"Department of Electrical Engineering and Computer Science, KAIST, 373-1 Guseong-dong, Yusung-gu, Daejeon 305-701, Republic of Korea; Department of Electrical Engineering and Computer Science, KAIST, 373-1 Guseong-dong, Yusung-gu, Daejeon 305-701, Republic of Korea",2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence),,2008,,,3019,3024,,,,,,Robots;Sensors;Robot sensing systems;Genomics;Bioinformatics;Tactile sensors;Evolutionary computation,human computer interaction;robots,evolutionary personalized robotic doll;GomDoll;genetic robot;evolutionary process;genome population;Big Five personality dimension;human friendly interaction;bear-like robotic doll,,1,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8172404,Ex-amp robot: Expressive robotic avatar with multimodal emotion detection to enhance communication of users with motor disabilities,Factor table (one to one),N,User Emotion to emotion output,Custom Discrete,5,Core,General Interaction,Prototype,Pepper,"In current society, there are numerous robots made for various purposes, including manufacturing, cleaning, therapy, and customer service. Other robots are used for enhancing H2H communication. In this research, we proposed a robotic system which detects the user's emotions and enacts them on a humanoid robot. By using this robotic avatar, users with motor disabilities are able to extend their methods of communication, as a physical form of expression will be added to the conversation.",A. Kashii; K. Takashio; H. Tokuda,"Faculty of Environment and Information Studies, Keio University, 5322 Endo Fujisawa Kanagawa, Japan; Faculty of Environment and Information Studies at Keio University; Faculty of Environment and Information Studies at Keio University",2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),,2017,,,864,870,,,,,,Robot sensing systems;Avatars;Speech recognition;Senior citizens;Dictionaries;Speech,avatars;control engineering computing;customer services;emotion recognition;handicapped aids;humanoid robots;human-robot interaction,customer service;robotic system;humanoid robot;motor disabilities;Ex-amp robot;expressive robotic avatar;multimodal emotion detection,,1,31,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=956078,Experiences with an autonomous robot attending AAAI,Rule-based - Computational Model,N,Non-emotion stimuli to emotion output,Continuous Custom,4,Component,General Interaction,Implemented and Evaluated,Lolitta Hall,"Integrated intelligence experiments provide new opportunities for autonomous systems to assist humans in real-life situations. Using artificial emotions and human-robot communication, the authors designed an autonomous robot to attend AAAI. The robot must register itself at the conference as a student volunteer, perform various tasks, and give a presentation on its experiences at the conference. The authors report their experiences.",F. Michaud; J. Audet; D. Letourneau; L. Lussier; C. Theberge-Turmel; S. Caron,"Sherbrooke Univ., Que., Canada; NA; NA; NA; NA; NA",IEEE Intelligent Systems,,2001,16,5,23,29,,,,,,Robot kinematics;Robot sensing systems;Intelligent robots;Mobile robots;Robot control;Humans;Artificial intelligence;Laboratories;Intelligent systems;Software design,mobile robots;planning (artificial intelligence);robot vision;user interfaces,integrated intelligence experiments;autonomous systems;artificial emotions;human-robot communication;autonomous robot;student volunteer;AAAI Mobile Robot Challenge,,8,13,,,,,IEEE,IEEE Magazines,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7745227,Expressive touch: Control of robot emotional expression by touch,Factor table,N,User Emotion to emotion output,Custom Discrete,4,Core,General Interaction,Prototype,iCub,"In this paper, we present a work on control of robot emotional expression using touch sensing. A tactile Bayesian framework is proposed for recognition of different types of touch gestures. We include a sequential analysis method that, based on the accumulation of evidence from tactile interaction, allows to achieve accurate results for recognition of touch. Input data to our method is obtained from touch sensing, which is an important modality for social robotics. Here, emotion in the robot platform are represented by facial expressions, that are handled by a developed control architecture. We validate our method with experiments on tactile interaction in simulated and real robot environments. Results demonstrate that our proposed method is suitable and accurate for control of robot emotions through interaction with humans using touch sensing. Furthermore, it is demonstrated the potential that touch provides as a non-verbal communication channel for the development of social robots capable to interact with humans.",U. Martinez-Hernandez; T. J. Prescott,"Sheffield Robotics Laboratory, The University of Sheffield, U.K.; Sheffield Robotics Laboratory, The University of Sheffield, U.K.",2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),,2016,,,974,979,,,,,,Robot sensing systems;Humanoid robots;Skin;Probabilistic logic;Bayes methods,Bayes methods;face recognition;gesture recognition;haptic interfaces;humanoid robots;human-robot interaction,social robot development;nonverbal communication channel;tactile interaction;facial expressions;social robotics;sequential analysis method;touch gestures;tactile Bayesian framework;touch sensing;robot emotional expression control;expressive touch,,7,25,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7379177,Facial Expression of Social Interaction Based on Emotional Motivation of Animal Robot,Rule-based Biology Model,N,Human and external to emotion output and internal process,Binary,2,Component,General interaction,Prototype,Digital,"This paper aims to develop the research based on a pet robot and its artificial consciousness. We propose the animal behavior and emotion using the artificial neurotransmitter and motivation. This research still implements the communication between human and a pet robot respecting to a social cognitive and interaction. Thus, the development of cross-creature communication is crucial for friendly companionship. This system focuses on three points. The first that is the organization of the behavior and emotion model regarding the phylogenesis. The second is the method of the robot that can have empathy with user expression. The third is how the robot can socially perform its expression to human for encouragement or being delighted based on its own emotion and the human expression. This paper eventually presents the performance and the experiment that the robot using cross-perception and cross-expression between animal robot and social interaction of human communication based on the consciousness based architecture (CBA).",S. Chumkamon; K. Masato; E. Hayashi,"Grad. Sch. of Comput. Sci. & Syst. Eng., Kyushu Inst. of Technol., Iizuka, Japan; Grad. Sch. of Comput. Sci. & Syst. Eng., Kyushu Inst. of Technol., Iizuka, Japan; Grad. Sch. of Comput. Sci. & Syst. Eng., Kyushu Inst. of Technol., Iizuka, Japan","2015 IEEE International Conference on Systems, Man, and Cybernetics",,2015,,,185,190,,,,,Social Robot;Human-Robot Interactio;CBA;Facial Expression Recognition,Animals;Neurotransmitters;Face;Shape;Mathematical model;Manipulators,face recognition;human-robot interaction;robot vision,facial expression recognition;social interaction;emotional motivation;animal robot;pet robot;artificial consciousness;animal behavior;artificial neurotransmitter;social cognitive;cross-creature communication development;phylogenesis;user expression;human expression;human communication;cross-perception;cross-expression,,1,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1347464,Facial expressive robotic head system for human-robot communication and its application in home environment,Rule-based - Computational Model,N,Human and external to emotion output and internal process,Custom Continuous,2,Component,General interaction,Prototype,Digital,"This paper describes a robotic-head system as a multimodal communication device for human-robot interaction, and the system's potential application in home environments. Most robotic systems for natural user interaction have facial expressions, since facial expressiveness is regarded as a key component to developing personal attachment along with prosodic expressiveness. In the first part of the paper is the description of our robotic head system Character Robot Face (CRF). A deformation approach and a parametric normalization scheme are proposed to produce facial expressions of nonhuman face models with high recognition rates. In the second half of the paper, CRF is endowed with artificial emotions and assigned tasks conceivable in home environments. A coordination mechanism between the robot's mood (an activated emotion) and its task is proposed so that the robot can, by referring to the emotion-task history, select a task depending on its current mood if there is no explicit task command from the user. When the robot performs a task, a particular emotion value gets boosted according to the same emotion-task history so that the emotion is more likely to be activated.",T. Fukuda; Myung-Jin Jung; M. Nakashima; F. Arai; Y. Hasegawa,"Dept. of Micro Syst. Eng., Nagoya Univ., Japan; NA; NA; NA; NA",Proceedings of the IEEE,,2004,92,11,1851,1865,,,,,,Robot kinematics;Intelligent robots;Systems engineering and theory;Human robot interaction;Mood;History;Intelligent agent;Deformable models;Face recognition;Software agents,man-machine systems;face recognition;robots;matrix algebra,facial expressive robotic head system;human-robot communication;home environment;multimodal communication device;natural user interaction;character robot face;deformation;parametric normalization scheme;artificial emotions;emotion task history;matrix algebra,,18,40,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=633250,Facial interaction between animated 3D face robot and human beings,Factor table,N,User Emotion to emotion output,Eckman,6,Core,General interaction,Prototype,Robot Face,"We study the realization of a realistic human-like response of an animated 3D face robot in communicative interaction with human beings. The face robot can produce human-like facial expressions and recognize human facial expressions using facial image data obtained by a CCD camera mounted inside the left eyeball. We developed the real time machine recognition of facial expressions by using a layered neural network and achieved a high correct recognition ratio of 85% with respect to 6 typical facial expressions of 15 subjects in 55 ms. We also developed a new small-size actuator for display of facial expressions on the face robot, giving the same speed in dynamic facial expressions as in human even in the case of a high-speed expression of ""surprise"". For facial interactive communication between the face robot and human beings, we integrated these two technologies to produce the facial expression in respond to the recognition result of the human facial expression in real time. This implies a high technological potential for the animated face robot to undertake interactive communication with human when an artificial emotion being implemented.",H. Kobayashi; F. Hara,"Dept. of Comput. Sci., Zurich Univ., Switzerland; NA","1997 IEEE International Conference on Systems, Man, and Cybernetics. Computational Cybernetics and Simulation",,1997,4,,3732,3737 vol.4,,,,,,Facial animation;Human robot interaction;Face recognition;Humanoid robots;Image recognition;Charge coupled devices;Robot vision systems;Charge-coupled image sensors;Cameras;Neural networks,robots;face recognition;robot vision;interactive systems;real-time systems;feedforward neural nets;actuators,facial interaction;3D face robot;animation;facial expression recognition;CCD camera;multilayer neural network;actuator;real time systems;interactive communication,,39,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7237708,Feasibility study of a novel rehabilitation training system for upper limb based on emotional control,Factor table ,N,User Emotion to Internal Process,Custom Discrete,4,Core,Performance,Prototype,Digital,"This paper introduces a new way to help people who lose motor function regain their abilities of activities of daily living (ADL). As is proved, repeated training can help the paralytics rebuild the strength of muscles, while active participation of the patients will improve the outcome of rehabilitation than them barely assisted by robots. Brain-computer interface (BCI) technology brings paralytics a new way to join in the training process actively. The novel idea of our study is to treat the robot as a co-worker and the paralytic interacts in the training process with emotional states based on his satisfaction level of the robot's work. This system consists of two main parts: the robot and BCI. The robot can work in three different modes in training process. This paper focuses on the feasibility study of emotional control of the robot. Experiments were conducted with a healthy male subject. Brain signals of the subject were extracted by an electroencephalogram (EEG) headset. Four different mental states were detected and interpreted into control commands to start the robot, stop the robot, maintain training mode and switch training mode. Raw EEG data were recorded for off-line analysis. Powers of four frequency bands of EEG signals were analyzed to find their relationship with different emotional states. Experimental results proved the feasibility of our system and shown that it's much easier to control the training process with the collaborating of the semi-autonomous robot. We also found that different EEG frequency bands carry important messages about different emotions, which may provide references for further study of emotional control.",S. Guo; X. Zhao; W. Wei; J. Guo; F. Zhao; Y. Hu,"Tianjin Key Laboratory for Control, Theory and Applications in Complicated Systems, Tianjin University of Technology, 391 Binshui Xidao, Xiqing District Tianjin 300384, China; Tianjin Key Laboratory for Control, Theory and Applications in Complicated Systems, Tianjin University of Technology, 391 Binshui Xidao, Xiqing District Tianjin 300384, China; College of Physics, Optoelectronics and Energy, Soochow University, 1, Shizi Street, Suzhou 215006, Jiangsu, China; Tianjin Key Laboratory for Control, Theory and Applications in Complicated Systems, Tianjin University of Technology, 391 Binshui Xidao, Xiqing District Tianjin 300384, China; Tianjin Key Laboratory for Control, Theory and Applications in Complicated Systems, Tianjin University of Technology, 391 Binshui Xidao, Xiqing District Tianjin 300384, China; Tianjin Key Laboratory for Control, Theory and Applications in Complicated Systems, Tianjin University of Technology, 391 Binshui Xidao, Xiqing District Tianjin 300384, China",2015 IEEE International Conference on Mechatronics and Automation (ICMA),,2015,,,1507,1512,,,,,Brain-Computer Interface;Emotional States;Upper Limb Exoskeleton Rehabilitation Device;Rehabilitation Training,Training;Robots;Electroencephalography;Exoskeletons;Headphones;Medical treatment;Software,brain-computer interfaces;electroencephalography;medical robotics;patient rehabilitation,rehabilitation training system;upper limb;emotional control;motor function;activities of daily living;ADL;repeated training;active patients participation;brain-computer interface technology;BC!;training process;emotional states;healthy male subject;brain signals;electroencephalogram headset;EEG;emotional states;semiautonomous robot;EEG frequency bands,,4,22,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1291666,Function meets style: insights from emotion theory applied to HRI,Rule-based Computational Model,Y,Human and external to emotion output ,Eckman,6,Component,General Interaction,Prototype,Kismet,"As robot designers, we tend to emphasize the cognitive aspect of intelligence when designing robot architectures while viewing the affective aspect with skepticism. However, scientific studies continue to reveal the deeply intertwined and complementary roles that cognition and emotion play in intelligent decision-making, planning, learning, attention, communication, social interaction, memory, and more. Such findings provide valuable insights and lessons for the design of autonomous robots that must operate in complex and uncertain environments and perform in cooperation with people. This paper presents a concrete implementation of how these insights have guided our work, focusing on the design of sociable autonomous robots that interact with people as capable partners.",C. Breazeal,"Massachusetts Inst. of Technol., Cambridge, MA, USA","IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)",,2004,34,2,187,194,,,,,,Cognitive robotics;Intelligent robots;Cognition;Human robot interaction;Humanoid robots;Concrete;Animals;Face;Muscles;Information processing,robots;planning (artificial intelligence);cognitive systems;emotion recognition;decision making;human computer interaction;learning (artificial intelligence),cognition;autonomous robot design;intelligent decision making;planning;learning;attention;communication;social interaction;memory;uncertain environments;complex environments;autonomous robots;human-robot interaction;humanoid robot;emotion theory;social robot,,87,23,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6704075,Fuzzy based emotion generation mechanism for an emoticon robot,Fuzzy Rule Base,N,Human and external to emotion output,Eckman,6,Core,General Interaction,Implemented and Evaluated,Custom Robot,"This paper discusses the architecture in which the emotion of a robot is designed and generated. The proposed architecture integrates long term affective characteristic and short term interactive changes into the emotion generation mechanism of a robot. Emotion of a robot is generated by a fuzzy logic from three inputs: the robot's personality, the ambient environment and the interaction with human. The virtual personality of this robot is expressed via an LED-face using emoticon facial expressions. The robots with different type of personalities were tested in various environments. Test subjects can identify different robot's personality from the interaction.",N. Daosodsai; T. Maneewarn,"Institute of Field Robotics (FIBO), King Mongkut's University of Technology Thonburi 126 Pracha-u-thit, Tungkru, Bangmod, Bangkok, Thailand; Institute of Field Robotics (FIBO), King Mongkut's University of Technology Thonburi 126 Pracha-u-thit, Tungkru, Bangmod, Bangkok, Thailand","2013 13th International Conference on Control, Automation and Systems (ICCAS 2013)",,2013,,,1073,1078,,,,,Architecture;Emotion of a robot;Affective characteristics;LED-face,Robot sensing systems;Microcontrollers,ambient intelligence;fuzzy control;human-robot interaction;intelligent robots;service robots,emoticon robot;fuzzy based emotion generation mechanism;fuzzy logic;ambient environment;human-robot interaction;emoticon facial expressions,,5,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6783849,Fuzzy Controlled PAD Emotional State of a NAO Robot,Fuzzy Rule Base,Y,User Emotion to emotion output,Continuous Custom,3D,Core,General Interaction,Prototype,NAO,"Various Emotion Models (e.g. Circumplex Model [1], Vector Model [2], PANA (Positive Activation - Negative Activation) Model [3], PAD (Pleasure Arousal Dominance) Model [4], etc...) can be used to represent the different emotional states of a robot. In this paper we chose to use a PAD Emotional Space [5] to simulate the emotional state of a NAO Robot (NAO is the name of a humanoid robot developed and commercialized by Aldebaran Robotics). But one difficulty is to write an algorithm that makes evolve the emotional state according to external and internal stimuli. Simulating a coherent Emotional State over the time is a real challenge for designing a virtual personality. As human emotions are fuzzy by nature, many researchers explored using Fuzzy State Machine [6], [7] or Fuzzy Logic [8], [9], [10], [11], [12] to control the emotions of a virtual character or robot. Following the same approach, in this paper we propose to use a Fuzzy Control System [13] to control the emotional state of a NAO robot by injecting attractors in his PAD Emotional Space. Fuzzy Control Systems are usually good controller of uncertainty and easy to write thanks to their syntax close to the human language. The result of our experiments showed that the evolution of the Emotional State of our NAO robot was smooth and coherent with the situation met when interacting with humans. Moreover with different set of rules it becomes easy to switch the personality of the robot (meaning the robot can react differently to the same stimuli according to the different set of rules used).",A. Nanty; R. Gelin,"A-Lab., Aldebaran Robot., Shanghai, China; A-Lab., Aldebaran Robot., Paris, France",2013 Conference on Technologies and Applications of Artificial Intelligence,,2013,,,90,96,,,,,emotion;robot;NAO;PAD;Fuzzy Control System;emotion controller,Robots;Fuzzy control;Aerospace electronics;Input variables;Merging;Speech;Writing,finite state machines;fuzzy control;humanoid robots,fuzzy controlled PAD emotional state;NAO robot;humanoid robot;Aldebaran Robotics;virtual personality;human emotions;fuzzy state machine;fuzzy logic;fuzzy control system;emotional state evolution,,7,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1244500,"Fuzzy perception, emotion and expression for interactive robots",Fuzzy Rule Base,N,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Aryan,"Future robots need transparent interface that regular people can interpret, such as an emotional human-like face. Moreover, such robots must exhibit behaviors that are perceived believable and life-like. In this work we propose the use of fuzzy logic for effectively constructing the whole behavior system of these robots. This not only simplifies the design tasks, but also enriches human-robot interaction. The latter claim is justified by effortlessly generating intermediate and blend of emotions from a few basic emotions. Additionally, fuzzy motor commands yield smooth life-like motions and therefore improve believability.",H. Mobahi; S. Ansari,"Dept. of Electr. & Comput. Eng., Tehran Univ., Iran; NA","SMC'03 Conference Proceedings. 2003 IEEE International Conference on Systems, Man and Cybernetics. Conference Theme - System Security and Assurance (Cat. No.03CH37483)",,2003,4,,3918,3923 vol.4,,,,,,Human robot interaction;Face;Humanoid robots;Logic;Intelligent robots;Artificial intelligence;Intelligent agent;Programming profession;Speech recognition;Feedback,fuzzy logic;human computer interaction;intelligent robots,fuzzy perception;interactive robots emotion;interactive robots expression;emotional human-like face;fuzzy logic;human-robot interaction;fuzzy motor commands;life-like motions,,3,31,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=781800,Fuzzy rule expression for emotional generation model based on subsumption architecture,Fuzzy Rule Base,N,Non-emotion stimuli to emotion output ,Custom Discrete,3,Core,General Interaction,Prototype,Khepera,"The purpose of our research is to attempt to represent emotions which are difficult to express into a robot as compared with the logical knowledge. The emotional simulator for an autonomous mobile robot which is able to express various emotions based on three basic emotional vectors, described only with simplified fuzzy rules, was developed in this research. We represented the emotional auto-generation model with Subsumption Architecture (SSA). We also report the result of experiments performed with a miniature robot for the purpose of confirming the efficiency of this simulator.",Y. Maeda,"Osaka Electro-Commun. Univ., Neyagawa, Japan",18th International Conference of the North American Fuzzy Information Processing Society - NAFIPS (Cat. No.99TH8397),,1999,,,781,785,,,,,,Robot kinematics;Mobile robots;Humans;Robotics and automation;Intelligent robots;Fuzzy logic;Computer architecture;Computational modeling;Robot sensing systems;Intelligent sensors,mobile robots;man-machine systems;fuzzy set theory;fuzzy logic;knowledge based systems;psychology,fuzzy rule expression;emotional generation model;subsumption architecture;logical knowledge;emotional simulator;autonomous mobile robot;basic emotional vectors;simplified fuzzy rules;emotional auto-generation model;miniature robot,,5,8,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6393419,Giving robots a flexible persona: The five factor model of artificial personality in action,Rule-based Computational Model,N,User Emotion to emotion output,Custom Discrete,5,Component,General Interaction,Implemented and Evaluated,Modroid,"A computational framework for artificial personality in cognitive robots is introduced. While every robot has some form of personality, the framework reported here is flexible and enables the exploration of different behaviors on the same robotic platform. The framework described here maintains a probabilistic representation of an internal state that includes emotion, motivation, sensing, and previous action. The next action is computed by using a massive number of rules implemented using Bayes Rule. This flexible Bayesian representation of personality allows the robots personality to be designed by a personality generator algorithm. The authors present results in a real robot and compare the behavior of robots with differing personalities.",K. Sohn; S. Krishnamoorthy; O. Paul; M. A. Lewis,"Department of Mechanical Engineering and Mechanics, Drexel University, Philadelphia 19104, USA; Department of Electrical and Computer Engineering, University of Arizona, Tucson 85721, USA; Department of Mechanical Engineering and Mechanics, Drexel University, Philadelphia 19104, USA; Department of Electrical and Computer Engineering, University of Arizona, Tucson 85721, USA","2012 12th International Conference on Control, Automation and Systems",,2012,,,133,139,,,,,Artificial Personality;Big Five;Cognitive Robotics,Robot sensing systems;Generators;Humans;Bayesian methods;Loading;Engines,artificial intelligence;Bayes methods;robots,flexible persona;five factor model;artificial personality;computational framework;cognitive robots;robotic platform;probabilistic representation;internal state;emotion;motivation;sensing;Bayes rule;flexible Bayesian representation;robot personality;personality generator algorithm,,,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4579234,Giving robots some feelings towards interaction with humans in ubiquitous environment,Fuzzy Rule Base,N,Non-emotion stimuli to emotion output,Custom Discrete,3,Core,General Interaction,Prototype,Custom Robot,"There were many successful milestones that researchers had passed achieving dasiahumanoid robotspsila, that are little closer to humans but not at whole. Although, the expectation level of the intelligence of these new systems is still unknown, it can be fairly assumed that reaching a goal at least up to an intelligence level of a human baby, may be a big success. In order to be more close to the human, it is necessary to analyze the behavioral patterns of humans in order to apply them for the AI machines. Humans being emotional creatures have feelings on their own as well as many towards the others. These emotions get into effect in all the dealings they performed. Some of the topics that this research project discusses are, is there anything these feelings can do to improve robots, will there be any change to robot by having them, etc. In this research work authors are analyzing some dasiaface emotionspsila based on dasiapersonal spacepsila to enhance the human-robot interactions in ubiquitous environments.",J. C. Balasuriya; K. Watanabe; A. Pallegedara,"Department of Advanced Systems Control Engineering, Saga University, Japan; Department of Advanced Systems Control Engineering, Saga University, Japan; Millennium Information Technologies (MIT) Pvt. Ltd., Sri Lanka",2007 International Conference on Industrial and Information Systems,,2007,,,529,534,,,,,,Human robot interaction;Mobile robots;Orbital robotics;Service robots;Pattern analysis;Intelligent robots;Navigation;Electrical equipment industry;Industrial control;Information systems,control engineering computing;humanoid robots;man-machine systems;ubiquitous computing,human-robot interaction;ubiquitous environment;humanoid robot;behavioral pattern;AI machines;face emotions;personal space,,2,19,,,,,IEEE,IEEE Conferences,,
,Group-based Emotions in Teams of Humans and Robots,Rule-based Computational Model,N,User Emotion to emotion output,Custom Discrete,4,Core,General Interaction,Implemented and Evaluated,EMYS,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744094,How Recognition of Human Facial Expression can be incoporated in Robot Control,Factor table (one to one),N,User Emotion to Internal Process,Custom Discrete,5,Core,General Interaction,Prototype,Bubble Robot,"An amusement robot which can recognize and respond to human facial expressions is proposed. Human facial recognition being integrated into the control systems of robots is necessary in order to improve their entertainment value. Generally, the entertainment value and the success of the events which use such robots are evaluated by the number of attendees, the return rate of customers, the result of questionnaires, and so on. However, it takes a long time to gather and evaluate the data to improve such robots and events. We are proposing a new technology which uses a camera to read and respond to human facial expressions. This new technology can be used together with the traditional methods to provide better design technology for the entertainment industries. As the preliminary research, a portable bubble ejection robot was fabricated. The robot produces soap bubbles like a fountain. The ejected soap bubbles are illuminated by LEDs. The direction of the ejection nozzle and the amount of the ejected bubbles are controlled by using an Android tablet. The human facial expressions are read by a facial expression detection system. This paper will explain the design of the bubble ejection robot and the control system which reads human facial expressions, and the experimental results of human reaction to the bubble ejection. The experimental results revealed the relationship between the soap bubble ejection and the human emotions.",N. Hasegawa; Y. Takahashi,"Dept. of Mechanical Systems Engineering, Kanagawa Institute of Technology, Atsugi city, Kanagawa Prefecture, Japan; Dept. of Mechanical Systems Engineering, Kanagawa Institute of Technology, Atsugi city, Kanagawa Prefecture, Japan",2019 20th International Conference on Research and Education in Mechatronics (REM),,2019,,,1,6,,,,,human emotion;human facial expression;bubble robot;communication robot;bubble ejection,,bubbles;emotion recognition;entertainment;face recognition;light emitting diodes;nozzles;robot vision;soaps,entertainment industries;ejection nozzle;Android tablet;entertainment value;human facial recognition;amusement robot;robot control;control system;facial expression detection system;portable bubble ejection robot;human facial expression,,,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=933189,Human interface using PC display with head pointing device for eating assist robot and emotional evaluation by GSR sensor,Factor table,N,User Emotion to Internal Process,Binary,2,Component,Performance,Prototype,Robotic Arm,"This paper proposes the human interface of an eating assistant robot to assist people with severe disability to gain/regain independence in eating. A spoon and a CCD camera are attached on the tip of the robotic arm. The spoon can be actuated in three orthogonal directions, and can also be rotated. The PC display indicates the image of the CCD camera and a control panel of the robot. The human interface proposed uses the PC display and a head pointing device. A user can easily control the eating assist robot by using his/her head action and a puff activated switch. This paper describes also the evaluation of user's emotion during the operation of the eating assistant robot. A galvanic skin reflex (GSR) sensor is used to detect the user's emotion. Using the experimental results of the GSR sensor, an optimal movement scheme by considering the user's emotion has been decided. The eating assistant experiments on a disabled person with cervical vertebrae damage are also described briefly.",Y. Takahashi; N. Hasegawa; K. Takahashi; T. Hatakeyama,"Dept. of Syst. Design Eng., Kanagawa Inst. of Technol., Japan; NA; NA; NA",Proceedings 2001 ICRA. IEEE International Conference on Robotics and Automation (Cat. No.01CH37164),,2001,4,,3674,3679 vol.4,,,,,,Humans;Displays;Robot sensing systems;Head;Charge coupled devices;Robot vision systems;Charge-coupled image sensors;Cameras;Switches;Galvanizing,manipulators;handicapped aids;computer vision;user interfaces;interactive systems,head pointing device;eating assistant robot;CCD camera;robotic arm;user interface;puff activated switch;galvanic skin reflex sensor;disabled person;handicapped aid,,17,8,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332947,Human-like patient robot with chaotic emotion for injection training,Rule-based Computational Model (Chaos),N,Non-emotion stimuli to emotion output,Custom Discrete,4,Component,Performance,Prototype,Patient Robot,"In this paper, we present a system of patient robot developed with the aim at improving abilities of nursing student's medical treatment, such as injection to vein. We propose to realize variable emotion of patient robot by using chaos orbit of non-linear time-differentiation equation. To evaluate the effectiveness of the robot through actual injection training, we measure heartbeat rate of nurse student during the injection training, proving the effects of the robot's similarity to human. To make the patient robot to be self-contained for the training, we propose a 3D injector pose recognition method of patient robot to help that the robot behave autonomously along with the injection procedures of the nurse students trainings.",Yoshiro Kitagawa; Tomohito Ishikura; Wei Song; Yasushi Mae; M. Minami; Kanji Tanaka,"University of Fukui, Bunkyo3-9-1, Fukui, Japan; University of Fukui, Bunkyo3-9-1, Fukui, Japan; University of Fukui, Bunkyo3-9-1, Fukui, Japan; Osaka University, machikaneyamachou1-3, toyonaka, Japan; University of Fukui, Bunkyo3-9-1, Fukui, Japan; University of Fukui, Bunkyo3-9-1, Fukui, Japan",2009 ICCAS-SICE,,2009,,,4635,4640,,,,,Patient robot;Chaos;Variable emotion;Injector recognition,Humanoid robots;Chaos;Medical robotics;Medical services;Medical treatment;Veins;Orbital robotics;Nonlinear equations;Extraterrestrial measurements;Heart beat,biomedical education;chaos;computer based training;differentiation;emotion recognition;humanoid robots;medical computing;medical robotics;nonlinear differential equations;patient treatment;pose estimation;robot vision,human-like patient robot;chaotic emotion;injection training;nursing student;medical treatment;nonlinear time-differentiation equation;heartbeat rate;3D injector pose recognition method;robot vision,,3,4,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491469,Human-Robot Interaction Experiment Based on Markovian Emotional Model,Markovain emotional model,Y,User emotion to emotion output,Eckman Extension,7,Core ,General Interaction,Implemented and Evaluated,NAO,"We aim to perform interactive communication by movements with the emotion to increase the affinity of interpersonal to the robot by amplifying and suppressing the human emotion. In previous research, it has been found it is necessary to have not only sympathetic but also not bored emotional behavior response model to enhance interpersonal affinity. In this paper we propose a method for emotion generation using Markovian emotional model. The Markovian emotional model is capable of modeling the state transition that takes into account the emotional preference reactions and the internal state of recognized emotion. We aim to build an emotion generation model with the interaction so that the human interest is sustained. Performing the interaction experiment by a humanoid robot, we confirmed that the improved interpersonal affinity is improved by the robot with Markovian emotional model.",Y. Maeda,"College of Information Science and Engineering, Ritsumeikan University, Kusatsu, Shiga, 525-8577, Japan",2018 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE),,2018,,,1,6,,,,,Human-robot interaction;Interactive communication;Markovian emotional model;Humanoid robot,Micromechanical devices;IEC;Markov processes;Probability;Mathematical model;Humanoid robots,emotion recognition;humanoid robots;human-robot interaction,Markovian emotional model;human emotion;bored emotional behavior response model;emotional preference reactions;emotion generation model;robot interaction experiment;interpersonal affinity,,,6,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=952719,I show you how I like you - can you read it in my face? [robotics],Rule-based Computational Model,N,Human and external to emotion output ,Eckman,6,Core ,General Interaction,Implemented and Evaluated,Lego,"We report work on a LEGO robot that displays different emotional expressions in response to physical stimulation, for the purpose of social interaction with humans. This is a first step toward our longer-term goal of exploring believable emotional exchanges to achieve plausible interaction with a simple robot. Drawing inspiration from theories of human basic emotions, we implemented several prototypical expressions in the robot's caricatured face and conducted experiments to assess the recognizability of these expressions.",L. Canamero; J. Fredslund,"Dept. of Comput. Sci., Hertfordshire Univ., Hatfield, UK; NA","IEEE Transactions on Systems, Man, and Cybernetics - Part A: Systems and Humans",,2001,31,5,454,459,,,,,,Human robot interaction;Robot sensing systems;Displays;Computer science;Emotion recognition;Prototypes;Face recognition;Psychology;Robot programming;User centered design,robots;man-machine systems;psychology;cooperative systems;robot programming;user centred design;user interfaces,LEGO robot;emotional expressions;physical stimulation;human robot interaction;facial expression;cooperative systems;psychology;robot programming;user centered design;user interfaces,,57,26,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=531978,Imitation of animal behavior with use of a model of consciousness-behavior relation for a small robot,Factor table ,N,Non-emotion stimuli to internal process,Custom Single (Pleasant,1,Component,Performance,Prototype,Digital,"This paper proposes an approach to designing behavior and its subjective world of a small robot to behave like an animal. This approach employs a hierarchical model of the relation between consciousness and behavior. The basic idea of this model is that a consciousness appears on a level in the hierarchical structure when an action on an immediately lower level is inhibited for internal or external causes, and that the appearing consciousness drives a chosen higher action. The computer simulation on a Mac shows the behavior of an artificial animal from reflex actions to catching of food. Its instantaneous consciousness that appears due to inhibited behavior is visualized with the behavior on the screen with use of colors according to emotions of the animal.",T. Kitamura; Y. Otsuka; T. Nakao,"Dept. of Mech. Syst. Eng., Kyushu Inst. of Technol., Fukuoka, Japan; Dept. of Mech. Syst. Eng., Kyushu Inst. of Technol., Fukuoka, Japan; Dept. of Mech. Syst. Eng., Kyushu Inst. of Technol., Fukuoka, Japan",Proceedings 4th IEEE International Workshop on Robot and Human Communication,,1995,,,313,317,,,,,,Animal behavior;Humans;Robots;Animal structures;Phylogeny;Biological system modeling;Mechanical systems;Systems engineering and theory;Visualization;Color,robots;behavioural sciences;hierarchical systems;digital simulation,animal behavior imitation;consciousness-behavior relation;small robot;hierarchical structure;inhibition;computer simulation;instantaneous consciousness,,7,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8256522,Implement human-robot interaction via robot's emotion model,Factor table (update by human),Y,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital,"Nowadays, many robots are in service for the people, such as pepper, Paro, HSR and so on. The robots are not only as partners but also provide services to daily life. To be a good partner, a robot needs to have a better model of feedback, such that it can interact more naturally. Moreover, in order to design a robot that can interact just like human, we need to design the emotion model for the robot. In our research, first our system extracts face and computes the feature from the facial image. Then our system uses SVM to classify the facial expression into different emotion states. At the same time, the robot also updates its own emotion states. Then the robot's emotion will change to interact with human according to the facial expression recognized. Therefore, the robot can show different feedback actions that expressing the emotion of robot with some funny postures.",W. Shih; K. Naruse; S. Wu,"Computer and Information System, The University of Aizu, Aizuwakamatsu, Japan; Division of Information System, The University of Aizu, Aizuwakamatsu, Japan; Computer Science and Information Engineering, Chaoyang University of Technology, Taichung, Taiwan, R.O.C.",2017 IEEE 8th International Conference on Awareness Science and Technology (iCAST),,2017,,,580,585,,,,,Human-robot interaction;emotion model;robot emotion,Robots;Support vector machines;Human-robot interaction;Feature extraction;Kernel;Face;Computational modeling,emotion recognition;face recognition;feature extraction;human-robot interaction;image classification;support vector machines,SVM;human-robot interaction implementation;feature computation;face extraction;emotion states;facial expression classification;robot emotion model;facial image,,2,18,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6630793,Impression survey of the emotion expression humanoid robot with mental model based dynamic emotions,Factor table,N,Non-emotion stimuli to internal process and emotion ,Custom Discrete,4,Core,General interaction,Prototype,KOBIAN-R,"This paper describes the implementation in a walking humanoid robot of a mental model, allowing the dynamical change of the emotional state of the robot based on external stimuli; the emotional state affects the robot decisions and behavior, and it is expressed with both facial and whole-body patterns. The mental model is applied to KOBIAN-R, a 65-DoFs whole body humanoid robot designed for human-robot interaction and emotion expression. To evaluate the importance of the proposed system in the framework of human-robot interaction and communication, we conducted a survey by showing videos of the robot behaviors to a group of 30 subjects. The results show that the integration of dynamical emotion expression and locomotion makes the humanoid robot more appealing to humans, as it is perceived as more ‚Äúfavorable‚Äù and ‚Äúuseful‚Äù, and less ‚Äúrobot-like"".",T. Kishi; T. Kojima; N. Endo; M. Destephe; T. Otani; L. Jamone; P. Kryczka; G. Trovato; K. Hashimoto; S. Cosentino; A. Takanishi,"Graduate School of Science and Engineering, Waseda University, #41-304, 17 Kikui-cho, Shinjuku-ku, Tokyo 162-0044, JAPAN; Graduate School of Science and Engineering, Waseda University, Japan; Graduate School of Science and Engineering, Waseda University, Japan; Graduate School of Science and Engineering, Waseda University, Japan; Graduate School of Science and Engineering, Waseda University, Japan; Graduate School of Science and Engineering, Waseda University, Japan; Graduate School of Science and Engineering, Waseda University, Japan; Graduate School of Science and Engineering, Waseda University, Japan; Faculty of Science and Engineering, Waseda University, Japan; Graduate School of Science and Engineering, Waseda University, Japan; Department of Modern Mechanical Engineering, Waseda University, Japan",2013 IEEE International Conference on Robotics and Automation,,2013,,,1663,1668,,,,,,Robot sensing systems;Legged locomotion;Cognitive science;Videos;Humanoid robots,artificial intelligence;emotion recognition;humanoid robots;human-robot interaction;legged locomotion,emotion expression humanoid robot;mental model-based dynamic emotions;walking humanoid robot;dynamical change;emotional state change;external stimuli;robot decisions;robot behavior;facial patterns;whole-body patterns;KOBIAN-R;65-DoF whole body humanoid robot;human-robot interaction;human-robot communication;dynamical emotion expression;dynamical locomotion,,9,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6033408,Innovative embodiment of job interview in emotionally aware communication robot,Fuzzy Rule Base,N,User Emotion to Internal Process and emotion output,Binary,2,Component,General interaction,Prototype,Matilda,"Emotions form an important component of human behavior and decision making. This paper reports on the embodiment of emotions and other human attributes like gestures, speech and motion in a communication robot for conducting a job interview and measuring emotional and cultural fitness of a candidate for a sales job. The contributions include enhanced information quality for managerial decision making, customization of follow up face to face interviews, and enhancement of social interaction between people and communication robot in interview situations.",R. Khosla; M. Chu; K. G. Yamada; K. Kuneida; S. Oga,"Research Centre for Computers, Communication and Social Innovation La Trobe University, Victoria - 3086, Australia; Research Centre for Computers, Communication and Social Innovation La Trobe University, Victoria - 3086, Australia; C & C Innovation Research Labs, NEC Corporation, Nara, Japan; C & C Innovation Research Labs, NEC Corporation, Nara, Japan; C & C Innovation Research Labs, NEC Corporation, Nara, Japan",The 2011 International Joint Conference on Neural Networks,,2011,,,1546,1552,,,,,Communication Robot;Job Interview;Social Interaction;Cultural and Emotion Fitness,Interviews;Face;Robots;Marketing and sales;Cultural differences;Speech recognition;Humans,recruitment;service robots,job interview;innovative embodiment;emotionally aware communication robot;human behavior component;decision making component;gesture attribute;speech attribute;motion attribute;sales job;managerial decision making;face-to-face interview;social interaction,,1,30,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4399132,Integration of emotional reactions on human facial expressions into the robot head MEXI,Rule-based Computational Model,Y,Human and external to emotion output,Custom Discrete,4,Component,General interaction,Prototype,Mexi,Emotion recognition and adequate reactions are a crucial part of human communication and hence should also be considered for interactions between humans and robots. In this paper we present the robot head MEXI which is able to recognize emotions of its human counterpart from a video sequence using a fuzzy rule based approach. It reacts on these perceptions in an emotional way. Therefor MEXI maintains an internal state made up of (artificial) emotions and drives. This internal state is used to evaluate its perceptions and action alternatives and controls its behavior on the basis of this evaluation. This is a major difference between MEXI and usual goal based agents that rely on a world model to control and plan their actions. For MEXI the behavior based programming paradigm originally developed by Arkin for robot navigation was extended to support a multidimensional control architecture based on emotions and drives.,N. Esau; L. Kleinjohann; B. Kleinjohann,"University of Paderborn, C-LAB, D-33102, Germany; University of Paderborn, C-LAB, D-33102, Germany; University of Paderborn, C-LAB, D-33102, Germany",2007 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2007,,,534,541,,,,,,Emotion recognition;Intelligent robots;Magnetic heads;Computer architecture;Humanoid robots;Human robot interaction;Speech analysis;Robot sensing systems;USA Councils,emotion recognition;face recognition;fuzzy control;man-machine systems,emotional reactions integration;human facial expressions;robot head MEXI;emotion recognition;human communication;fuzzy rule based approach;internal state;Arkin;multidimensional control architecture;machine with emotionally extended intelligence,,5,22,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=727828,Intelligent agent system for human-robot interaction through artificial emotion,Self-organizing map,N,User Emotion to emotion output,Custom Discrete,4,Component,General Interaction,Prototype,Small Robot,"The purpose of our work is to realize an agent for intelligent interaction between humans and robots, embedding a computational model of artificial emotions with learning and self-adaptation features. The gesture of a human can cause the robot to change its ""emotional state"", which is exhibited by means of integrated visual media, environmental lights, music, and changes in robot's style of movement and behavior. We adopt our emotional agent architecture for developing the agent. The system is a kind of ""emotional activator"", which plays the role of stimulating the human creativity. In our environment, humans do not need to wear any special on-body sensor. We use the small robot on wheels, equipped with on-board ultrasound sensors. Furthermore, We develop a camera-based sensor system to increase its input capabilities.",K. Suzuki; A. Camurri; P. Ferrentino; S. Hashimoto,"Musical Inf. Lab., Genova Univ, Italy; NA; NA; NA","SMC'98 Conference Proceedings. 1998 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.98CH36218)",,1998,2,,1055,1060 vol.2,,,,,,Intelligent agent;Intelligent robots;Robot sensing systems;Computational and artificial intelligence;Human robot interaction;Embedded computing;Computational modeling;Computer architecture;Wearable sensors;Mobile robots,robots;software agents;man-machine systems;interactive systems;computer vision,intelligent agent system;human-robot interaction;artificial emotion;self-adaptation;learning;emotional agent;camera-based sensor system;ultrasound sensors,,18,17,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8588149,Intelligent Execution of Behaviors in a NAO Robot Exposed to Audiovisual Stimulus,Factor table,N,User Emotion to emotion output,Custom Discrete,8,Component,General Interaction,Prototype,Nao,"Emotions and their intimate relationship with how humans interact with each other are currently studied as an alternative to stimulate what is called as Human-Robot Interaction (HRI). Different strategies that use emotions in robots as a central element have been developed to fulfil this goal, which has allowed the improvement of the interaction quality between a robot and a human. In this paper, different models and APIs are discussed and integrated for the processing of visual and audio stimulus in order to deliver the evoked emotions to a deterministic system and finally get the intelligent execution of behaviors in a NAO robot. The tests carried out with different case studies validated that the system responds according to the characteristics of each audiovisual stimulus and this does not have a bias towards a particular case.",S. S. D√≠az; J. M. M. Shaik; J. C. G. Santofimio; C. G. Quintero M.,"Department of Electrical and Electronics Engineering, Universidad del Norte, Barranquilla, Colombia; Department of Electrical and Electronics Engineering, Universidad del Norte, Barranquilla, Colombia; Department of Electrical and Electronics Engineering, Universidad del Norte, Barranquilla, Colombia; Department of Electrical and Electronics Engineering, Universidad del Norte, Barranquilla, Colombia",2018 IEEE 2nd Colombian Conference on Robotics and Automation (CCRA),,2018,,,1,6,,,,,NAO;stimulus;emotion;behaviors,Visualization;Robot sensing systems;Google;Libraries;Dictionaries;Natural languages,humanoid robots;human-robot interaction,audiovisual stimulus;intimate relationship;central element;interaction quality;visual stimulus;audio stimulus;evoked emotions;deterministic system;NAO robot;human-robot interaction,,,12,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6483986,Interactions and systems for augmenting a live dance performance,Markovain emotional model,Y,User Emotion to emotion output,Eckman,6,Component,General Interaction,Prototype,Digital,"The context of this work is to develop, adapt and integrate augmented reality related tools to enhance the emotion involved in cultural performances. Part of the work was dedicated to augmenting a stage in a live performance, with dance as an application case. In this paper, we present a milestone of this work, an augmented dance show that brings together several tools and technologies that were developed over the project's lifetime. This is the result of mixing an artistic process with scientific research and development. This augmented show brings to stage issues from the research fields of Human-Machine Interaction (HMI) and Augmented Reality (AR). Virtual elements are added on stage (visual and audio) and the dancer is able to interact with them in real-time, using different interaction techniques. The originality of this work is threefold. Firstly, we propose a set of movement-based interaction techniques that can be used independently on stage or in another context. In this set, some techniques are direct, while others go through a high level of abstraction. Namely, we performed movement-based emotion recognition on the dancer, and used the recognized emotions to generate emotional music pieces and emotional poses for a humanoid robot. Secondly, those interaction techniques rely on various interconnected systems that can be reassembled. We hence propose an integrated, interactive system for augmenting a live performance, a context where system failure is not tolerated. The final system can be adapted following the artist's preferences. Finally, those systems were validated through an on field experiment - the show itself - after which we gathered and analyzed the feedback from both the audience and the choreographer.",A. Clay; N. Couture; L. Nigay; J. de la Rivi√®re; J. Martin; M. Courgeon; M. Desainte-Catherine; E. Orvain; V. Girondel; G. Domengero,"ESTIA, USA; ESTIA, USA; LIG, France; IMMERSION, France; LIMSI CNRS, France; LIMSI CNRS, France; LaBRI, USA; IMMERSION, France; GIPSA-LAB, France; Malandain Ballet Biarritz, France","2012 IEEE International Symposium on Mixed and Augmented Reality - Arts, Media, and Humanities (ISMAR-AMH)",,2012,,,29,38,,,,,Augmented reality;augmented dance;emotion recognition;interaction for performing arts,Emotion recognition;Augmented reality;Robots;Real-time systems;Software;Context;Tracking,augmented reality;emotion recognition;humanities;humanoid robots;human-robot interaction,live dance performance augmentation;augmented reality related tools;emotion enhancement;cultural performances;augmented dance show;artistic process;scientific research and development;human-machine interaction;HMI;augmented reality;AR;virtual elements;movement-based interaction techniques;movement-based emotion recognition;emotional music pieces;emotional poses;humanoid robot;choreographer feedback analysis;audience feedback analysis,,8,40,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8685798,Interactions With an Empathetic Agent: Regulating Emotions and Improving Engagement in Autism,Factor table,N,User Emotion to emotion output,Custom Discrete,13,Component,General Interaction,Prototype,Romo,"Based on years of research establishing the utility of socially assistive robots (SARs) for autism spectrum disorder (ASD) intervention, such robots have now become popular tools, widely used in special education schools, autism care centers, and clinical settings. Most previous studies have explored the roles of SARs as instructors, learning aides, and social-skills trainers, focusing on the learning, language, and social impairments associated with ASD. This article addresses aspects of empathy and emotion regulation (ER) impairments, which are important underlying factors for many atypicalities manifested in ASD. We discuss the design of our robot's emotional capabilities, its emotion-based action library, and the algorithm it uses to regulate a user?s emotions. In addition, we describe a user study that evaluates the ER capabilities of an emotionally expressive empathetic agent as well as its capability to prime higher social engagement in a user.",H. Javed; C. H. Park,"Biomedical Engineering, George Washington University, Washington, D.C., United States; Biomedical Engineering, George Washington University, Washington, D.C., United States",IEEE Robotics & Automation Magazine,,2019,26,2,40,48,,,,National Institutes of Health; ,,Autism;Robot sensing systems;Image color analysis;Automation;Graphical user interfaces,behavioural sciences computing;emotion recognition;human-robot interaction;medical computing;medical disorders;multi-agent systems,emotion-based action library;prime higher social engagement;socially assistive robots;autism spectrum disorder intervention;ASD intervention;emotion regulation;engagement improvement;empathetic agent,,,20,,,,,IEEE,IEEE Magazines,,
,Interactive facial robot system on a smart device: enhanced touch screen input recognition and robot's reactive facial expression,Rule-based Computational Model,N,Non-emotion stimuli to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8571998,Interactive Reinforcement Learning based Assistive Robot for the Emotional Support of Children,Reinforcement Learning,N,User Emotion to Internal Process,Custom Discrete,8,Core,General Interaction,Prototype,RoBoHon,"In this work, we challenge the Interactive Reinforcement Learning paradigm by implementing an interactive action-planning module developed with the goal of exploring the feasibility of using a robot to socially engage with children and improve their mood. Facial features of the child are captured and processed, determining their emotional reaction to a behavior performed by the robot. Then, these emotions are classified as affective states in a multi-dimensional model. Leveraging the expertise of a human trainer, the action-planning module interactively learns those actions that are the most appropriate to perform when the child subject is in a specific affective state. To validate the usefulness of the proposed methodology, we evaluated the impact of the robot on elementary school aged children. Our findings show that using this methodology, the robot is able not only to learn in real time from the human trainer through interactions, but also that performing these social actions a robot can improve the mood of children.",E. Gamborino; L. Fu,"NTU Center for Artificial Intelligence & Advanced Robotics, National Taiwan University, Taipei, Taiwan; NTU Center for Artificial Intelligence & Advanced Robotics, National Taiwan University, Taipei, Taiwan","2018 18th International Conference on Control, Automation and Systems (ICCAS)",,2018,,,708,713,,,,,Human-Robot Interaction;Socially Assistive Robot;Interactive Reinforcement Learning,Robots;Mood;Pediatrics;Hospitals;Tools,assisted living;interactive systems;learning (artificial intelligence);robots,social actions;assistive robot;emotional support;interactive action-planning module;facial features;emotional reaction;affective states;multidimensional model;human trainer;child subject;specific affective state;elementary school aged children;interactive reinforcement learning paradigm,,,20,,,,,IEEE,IEEE Conferences,,
,Investigating emotional interaction with a robotic dog,Rule-based Computational Model,N,User Emotion to Internal Process,Custom Discrete,5,Core,General Interaction,Prototype,AIBO,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023699,Knowledge Creation Model for Emotion Based Response Generation for AI,BLSTM,N,User Emotion to emotion output,Eckman,6,Component,General interaction,Prototype,Digital,"The traditional view on the nature of rationality has proposed that emotions and reasons do not influence decision making. Hence, socially assistive robot (SAR) and chatbots are designed to act rationally and do not take emotions into account throughout the reasoning process. Therefore, the current conversation systems frequently use the user‚Äôs linguistic message in response generation. Such systems take into account factual and behavior related conversations, where these systems are unable to grasp the dynamic situations such as the user‚Äôs emotional state when generating a response. Studies by psychologists have provided contrary to popular belief where memories, both semantic, or learned knowledge, and episodic, or personal experiences, play an important role in an individual‚Äôs decision making. In this paper, authors present a system to support new findings which can enhance response generation regarding conversation flow while considering the actual emotional state of the user by analyzing the user‚Äôs current emotional state and emotional memories.",U. K. Premasundera; M. C. Farook,"Informatics Institute of Technology,Department of Computer Science,Colombo - 06,Sri Lanka; Informatics Institute of Technology,Department of Computer Science,Colombo - 06,Sri Lanka",2019 19th International Conference on Advances in ICT for Emerging Regions (ICTer),,2019,250,,1,7,,,,,Cognitive Human-Robot Interaction;Deep Learning in Robotics and Automation;Social Human-Robot Interaction,Robots;Compounds;Decision making;Associative memory;Task analysis;Mood,,,,,46,,,,,IEEE,IEEE Conferences,,
,Learning behavior-selection by emotions and cognition in a multi-goal robot task,Rule-based Computational Model,N,Non-emotion stimuli to internal process,Custom Single,1,Component,Performance,Implemented and Evaluated,Khepera,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8489158,Learning Empathy-Driven Emotion Expressions using Affective Modulations,Factor table,Y,User Emotion to emotion output,Custom Discrete,4,Component,General Interaction,Prototype,Nico,"Human-Robot Interaction (HRI) studies, particularly the ones designed around social robots, use emotions as important building blocks for interaction design. In order to provide a natural interaction experience, these social robots need to recognise the emotions expressed by the users across various modalities of communication and use them to estimate an internal affective model of the interaction. These internal emotions act as motivation for learning to respond to the user in different situations, using the physical capabilities of the robot. This paper proposes a deep hybrid neural model for multi-modal affect recognition, analysis and behaviour modelling in social robots. The model uses growing self-organising network models to encode intrinsic affective states for the robot. These intrinsic states are used to train a reinforcement learning model to learn facial expression representations on the Neuro-Inspired Companion (NICO) robot, enabling the robot to express empathy towards the users.",N. Churamani; P. Barros; E. Strahl; S. Wermter,"Department of Informatics University of Hamburg, Knowledge Technology, Hamburg, Germany; Department of Informatics University of Hamburg, Knowledge Technology, Hamburg, Germany; Department of Informatics University of Hamburg, Knowledge Technology, Hamburg, Germany; Department of Informatics University of Hamburg, Knowledge Technology, Hamburg, Germany",2018 International Joint Conference on Neural Networks (IJCNN),,2018,,,1,8,,,,,,Mood;Adaptation models;Neurons;Robot sensing systems;Convolution;Emotion recognition,emotion recognition;face recognition;humanoid robots;human-robot interaction;learning (artificial intelligence);neurocontrollers;self-organising feature maps,natural interaction experience;social robots;internal affective model;internal emotions;deep hybrid neural model;self-organising network models;intrinsic affective states;reinforcement learning model;facial expression representations;empathy-driven emotion expressions;affective modulations;interaction design;human-robot interaction;neuro-inspired companion robot;emotion recognition;multimodal affect recognition;NICO robot,,2,37,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4937914,Location-dependent emotional memory for natural communication of partner robots,Rule-based Computational Model,Y,Non-emotion stimuli to internal process,Custom Discrete,4,Core,Performance,Prototype,MOBImac,"This paper deals with an emotional model based on location-dependent emotional memory and location-dependent physical memory for partner robots to realize natural communication with people. First we discuss the functions of emotion in social interaction, and we propose an emotional model. Furthermore, the episode memory is related with the change of feelings. Therefore, we propose a map building method based on the emotional model. Next, we propose a behavior control method based on emotional model. Finally, we show several experimental results of the proposed method, and discuss the availability of the emotional model based on location-dependent memory.",N. Kubota; S. Wakisaka,"Department of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, 191-0065, Japan; Department of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, 191-0065, Japan",2009 IEEE Workshop on Robotic Intelligence in Informationally Structured Space,,2009,,,107,113,,,,,,Humans;Orbital robotics;Psychology;Communication system control;Mathematical model;Biological system modeling;Sociology;Humanoid robots;Neurophysiology,emotion recognition;human-robot interaction,location-dependent emotional memory;natural communication;location-dependent physical memory;partner robots;social interaction;behavior control method,,2,30,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8619648,Markov Decision Process for Emotional Behavior of Socially Assistive Robot,Markovain emotional model,Y,User Emotion to emotion output,Custom Discrete,3,Core,General Interaction,Prototype,Digital,"This paper presents a Markov decision process based model for a socially assistive robot. Problem addressed by the model is one to one correspondence of a robot with a human where robot has to convince the human about completing certain tasks. In this regard, emotions of the human and those of the robot are incorporated in the model. Furthermore, emotion transition probabilities and probabilities of robot being able to successfully convince the human are also incorporated. The resulting model however involves large state space. Computational complexity involved in calculation of optimal decision policy from the proposed model is discussed. Consequently, a computational complexity reduction technique is proposed that uses decomposition of the tasks to be performed into sub groups. An online learning framework is also proposed to account for un-modeled parameters in the problem. Behavior of decision making optimal policy obtained from the proposed model has been demonstrated with the help of a simulation based case study.",A. Nasir,"University of Central Punjab, Lahore, Punjab, 54782, Pakistan",2018 IEEE Conference on Decision and Control (CDC),,2018,,,1198,1203,,,,,,Robots;Task analysis;Markov processes;Cost function;Computational modeling;Mathematical model;Bayes methods,computational complexity;decision making;decision theory;human-robot interaction;learning (artificial intelligence);Markov processes;probability;service robots,Markov decision process;emotional behavior;socially assistive robot;emotion transition probabilities;optimal decision policy;computational complexity reduction technique;un-modeled parameters;online learning,,,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736762,Memristive Circuit Design of Emotional Generation and Evolution Based on Skin-Like Sensory Processor,Rule-based Biology Model,Y,Non-emotion stimuli to emotion output,Custom Discrete,4,Core,General Interaction,Prototype,Digital,"Sensory processor in human skin is used for processing and transmitting sensations to the brain, which leads to body actions and emotional responses. In this paper, a memristive circuit of emotional generation and evolution based on skin-like sensory processor is proposed. The circuit includes: first, memristive skin-like sensory processor module; second, emotional generation and evolution module; and third, emotional expression module. The first module consists of four single-memristor skin-like sensory processors, which correspond to process sensations of pain, cold, warm, and tactile. It will automatically return to its initial state if sensory signals disappear. But if sensory signals are much strong, it will not automatically return to initial state unless applied ‚Äúrestoring signal‚Äù just like a surgical operation. The second module realizes a conversion mechanism from sensations to emotions using memristor as emotional synapse. Given signals from skin-like sensory processor, the memristance will decrease, which means the extent of emotion will increase, such as more happy. This is the emotional generation. The extent of emotion will be changed if the same sensation is applied to skin-like sensory processor repeatedly, which is the emotional evolution. The third module can show the generated emotions visually. The simulation results in PSPICE show that the proposed circuit can generate and evolve emotions like human beings after processing sensory signals from skin. The proposed circuit can be applied in a perceptual robot platform to realize the conversion from sensations to emotions, enabling the robot to have the ability to sense and process information.",Z. Wang; Q. Hong; X. Wang,"School of Artificial Intelligence and Automation, and the Key Laboratory of Image Processing and Intelligent Control of Education Ministry of China, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, and the Key Laboratory of Image Processing and Intelligent Control of Education Ministry of China, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, and the Key Laboratory of Image Processing and Intelligent Control of Education Ministry of China, Huazhong University of Science and Technology, Wuhan, China",IEEE Transactions on Biomedical Circuits and Systems,,2019,13,4,631,644,,,,National Natural Science Foundation of China; National Key R&D Program of China; ,Circuit simulation;emotional generation and evolution;memristor;skin-like sensory processor,Memristors;Robot sensing systems;Skin;Mathematical model;Integrated circuit modeling;Voltage control;Synapses,bio-inspired materials;biomimetics;human computer interaction;man-machine systems;memristors;sensors;skin,memristive circuit design;emotional generation;sensory processor;emotional responses;emotional expression module;single-memristor skin-like sensory processors;sensation;sensory signals;emotional synapse;emotional evolution;generated emotions;memristive skin-like sensory processor module,,,51,Traditional,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9015303,Midoriko Chatbot: LSTM-Based Emotional 3D Avatar,LSTM,N,User Emotion to emotion output,Custom Discrete,4,Core,General Interaction,Prototype,Digital,"In this work, we developed a new model of chat robot with facial expression interaction. Different from the voice assistant that only interacts with text and voice, we let the chat robot interact with the user with a specific role play. A text-sentiment-analysis network is added to this system to recognize the emotion of the response sentences. Moreover, we created a 3D-constructed anime character ‚ÄúMidoriko‚Äù to have the image of the chat robot more vivid. Our goal is to provide better experience to users. The technical parts of this work is based on neural network techniques.",Y. Wan; C. Chiu; K. Liang; P. Chang,"National Central University,Department of Communication Engineering,Taoyuan City,Taiwan; National Central University,Department of Communication Engineering,Taoyuan City,Taiwan; National Central University,Department of Communication Engineering,Taoyuan City,Taiwan; National Central University,Department of Communication Engineering,Taoyuan City,Taiwan",2019 IEEE 8th Global Conference on Consumer Electronics (GCCE),,2019,,,937,940,,,,,Neural Network;Avatar;Chatbot;Unity;LSTM;Companionship;3D module,Three-dimensional displays;Neural networks;Servers;Animation;Artificial intelligence;Robots;Task analysis,,,,,6,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5282573,Mobile Robot Navigation Modulated by Artificial Emotions,Probability table,N,Non-emotion stimuli to internal process,Eckman (no disgust),5,Core,Performance,Prototype,Digital,"For artificial intelligence research to progress beyond the highly specialized task-dependent implementations achievable today, researchers may need to incorporate aspects of biological behavior that have not traditionally been associated with intelligence. Affective processes such as emotions may be crucial to the generalized intelligence possessed by humans and animals. A number of robots and autonomous agents have been created that can emulate human emotions, but the majority of this research focuses on the social domain. In contrast, we have developed a hybrid reactive/deliberative architecture that incorporates artificial emotions to improve the general adaptive performance of a mobile robot for a navigation task. Emotions are active on multiple architectural levels, modulating the robot's decisions and actions to suit the context of its situation. Reactive emotions interact with the robot's control system, altering its parameters in response to appraisals from short-term sensor data. Deliberative emotions are learned associations that bias path planning in response to eliciting objects or events. Quantitative results are presented that demonstrate situations in which each artificial emotion can be beneficial to performance.",C. P. Lee-Johnson; D. A. Carnegie,"Victoria University of Wellington, Wellington, New Zealand; Victoria University of Wellington, Wellington, New Zealand","IEEE Transactions on Systems, Man, and Cybernetics, Part B (Cybernetics)",,2010,40,2,469,480,,,,,Adaptive control;affect;emotion;mobile robot motion-planning,Mobile robots;Navigation;Artificial intelligence;Intelligent robots;Humans;Animals;Autonomous agents;Robot sensing systems;Robot control;Appraisal,mobile robots;path planning,mobile robot navigation;artificial emotion;artificial intelligence;task dependent implementation;robots agent;autonomous agent;human emotions emulation;hybrid reactive architecture;robot control system;short term sensor data;path planning;hybrid deliberative architecture;reactive emotion;deliberative emotion,"Adaptation, Psychological;Artificial Intelligence;Emotions;Humans;Models, Biological;Robotics",28,30,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=647004,"Model of knowledge, emotion and awareness",Fuzzy Rule Base,N,Human and external to internal process,Binary,2,Core,Performance,Prototype,Digital,"The purpose of this research is to develop a cause and effect model of knowledge, emotion, and awareness using fuzzy cognitive maps (FCMs) for systems providing physical assistance to handicapped people, and to use the model with an agent. The agent is a mobile robot whose recognition capabilities and behavior represents a knowledge. The recognition is the estimation of a person's intentions and emotions using sensor information. The behavior is the forward and the backward displacement of the agent. The emotions of the agent are represented by the status ""like"" or ""dislike"", depending on the situation when the agent likes or dislikes the person. Finally, the awareness is the behavioral intention of the agent. The agent approaches the person or goes away from him based on the model. Experiments show the effectiveness of this model.",T. Hashimoto; T. Yamaguchi,"Dept. of Inf. Sci., Utsunomiya Univ., Japan; NA",Proceedings 6th IEEE International Workshop on Robot and Human Communication. RO-MAN'97 SENDAI,,1997,,,326,331,,,,,,Equations;Mobile robots;Knowledge engineering;Fuzzy cognitive maps;Intelligent sensors;Emotion recognition;Intelligent agent;Computer graphics;Charge coupled devices;Robot vision systems,mobile robots;fuzzy systems;cognitive systems;software agents;knowledge based systems;handicapped aids,knowledge model;emotion model;awareness model;fuzzy cognitive maps;handicapped aids;mobile robot;behavioral intention;human intentions,,8,2,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8959855,Model of Multi-turn Dialogue in Emotional Chatbot,SeqGAN,N,User Emotion to emotion output,Custom Discrete,8,Component,General Interaction,Prototype,Digital,"The intent recognition and natural language understanding of multi-turn dialogue is key for the commercialization of chatbots. Chatbots are mainly used for the processing of specific tasks, and can introduce products to customers or solve related problems, thus saving human resources. Text sentiment recognition enables a chatbot to know the user's emotional state and select the best response, which is important in medical care. In this study, we combined the multi-turn dialogue model and sentiment recognition model to develop a chatbot, that is designed for used in daily conversations rather than for specific tasks. Thus, the chatbot has the ability to provide the robot's emotions as feedback while talking with a user. Moreover, it can exhibit different emotional reactions based on the content of the user's conversation.",C. Kao; C. Chen; Y. Tsai,"Institute of Medical Science and Technology National Sun Yat-sen University,Kaohsiung,Taiwan; Institute of Medical Science and Technology National Sun Yat-sen University,Kaohsiung,Taiwan; National Sun Yat-sen University,Department of Mechanical and Electro-Mechanical Engineering,Kaohsiung,Taiwan",2019 International Conference on Technologies and Applications of ArtiÔ¨Åcial Intelligence (TAAI),,2019,,,1,5,,,,,Chatbot;Multi-turn;Emotional category;Seq2Seq;SeqGAN,,natural language interfaces;natural language processing;software agents;text analysis,natural language understanding;text sentiment recognition;emotional state;multiturn dialogue model;sentiment recognition model;emotional reactions;emotional chatbot;intent recognition,,,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4107866,Modeling Affect in Socially Interactive Robots,Rule-based Computational Model,Y,User Emotion to emotion output,Eckman (no surprise),5,Core,General interaction,Prototype,Digital,"Humans use expressions of emotion in a very social manner, to convey messages such as ""I'm happy to see you"" or ""I want to be comforted,"" and people's long-term relationships depend heavily on shared emotional experiences. We believe that for robots to interact naturally with humans in social situations they should also be able to express emotions in both short-term and long-term relationships. To this end, we have developed an affective model for social robots. This generative model attempts to create natural, human-like affect and includes distinctions between immediate emotional responses, the overall mood of the robot, and long-term attitudes toward each visitor to the robot. This paper presents the general affect model as well as particular details of our implementation of the model on one robot, the Roboceptionist",R. Gockley; R. Simmons; J. Forlizzi,"Robotics Institute, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA, rachelg@cs.cmu.edu; Robotics Institute, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA, reids@cs.cmu.edu; Human Computer Interaction Institute and the Design Department, Carnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213, USA, forlizzi@cs.cmu.edu",ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,,2006,,,558,563,,,,,,Human robot interaction;Orbital robotics;Mood;Humanoid robots;Displays;Medical services;Cultural differences;Global communication;Senior citizens,emotion recognition;humanoid robots;interactive systems;man-machine systems,socially interactive robots;human emotion;Roboceptionist,,23,32,,,,,IEEE,IEEE Conferences,,
,Modeling and Simulating Empathic Behavior in Social Assistive Robots,Rule-based Computational Model,N,User Emotion to emotion output,Circumplex,NA,Core,General Interaction,Prototype,NAO,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1545342,Modeling of the emotional model with friendship for familiarity of robot,Rule-based Computational Model,Y,Human and external to emotion output ,Eckman (no disgust),5,Component,General Interaction,Prototype,Digital,"This paper deals with the emotional model of the software-robot. The software-robot requires several capabilities such as sensing, perceiving, acting, communicating, surviving and so on. There are already many studies about the emotional model like KISMET, AIBO. Though many emotional models are implemented, their human response architectures are invariant as time passes. Conventional emotional models make a robot like and obey a human during robot operation. This is natural for robots which are used in industrial, service and military areas but for pet robots this property lets robot look like real robots not real pets. Actually, a robot's emotional model is studied to implement robot intelligence more easily but emotion expression has to be exaggerated in a pet robot to make it interesting to humans. Pet robots must show dynamical emotion variations. The emotional model with the modified friendship is studied in this paper to overcome the conventional emotional model's limits to apply to pet robots. Friendship is distinguished as positive, negative and static schemes and an emotional model with the modified friendship is implemented and simulated on a software-robot.",Tae-Yong Choi; Joon-Yong Lee; Jun-ho Shin; Ju-Jang Lee,"Dept. of Electr. Eng. & Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea; Dept. of Electr. Eng. & Comput. Sci., Korea Adv. Inst. of Sci. & Technol., Daejeon, South Korea; NA; NA",2005 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2005,,,1235,1240,,,,,Human-robot interaction;friendship;artificial emotion,Positron emission tomography;Humans;Service robots;Robot sensing systems;Intelligent robots;Humanoid robots;Dogs;Mechatronics;Educational institutions;Defense industry,intelligent robots,emotional model;software-robot;robot operation;robot intelligence;pet robot;dynamical emotion variation;human-robot interaction;artificial emotion,,,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1241604,Mood and task coordination of home robots,Factor table,N,Non-emotion stimuli to internal process,Binary,2,Core,Performance,Prototype,Digital,"Many entertainment and healing robots have been developed. These robots have synthetic emotions so that they select behavior based on their current emotional state. On the contrary conventional robots which have designed to perform repetitive factor or office jobs do not have such emotions. Usually human operators assign tasks in explicit manner using keyboard or voice commands. In this paper we propose a coordination mechanism between robot mood (an activated emotion) and its task. On one hand, referring to the emotion-task history of the mechanism, the robot selects a task depending on its current mood if there is no explicit task command from the user. On the other hand, when it performs a task, a particular emotion gets boosted based on the same emotion-task history so that this emotion is more likely to be activated by external stimuli.",Myung-Jin Jung; F. Arai; Y. Hasegawa; T. Fukuda,"Human Comput. Interaction Lab., Samsung Adv. Inst. of Technol., Kyunggido, South Korea; NA; NA; NA",2003 IEEE International Conference on Robotics and Automation (Cat. No.03CH37422),,2003,1,,250,255 vol.1,,,,,,Mood;Robot kinematics;Intelligent robots;History;Robot sensing systems;Systems engineering and theory;Human robot interaction;Production facilities;Intelligent sensors;Intelligent agent,emotion recognition;artificial intelligence;intelligent robots;task analysis,mood and task coordination;home robots;coordination mechanism;robot mood;activated emotion;robot task;emotion-task history;external stimuli;entertainment robot;healing robot,,7,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5346563,Mood-transition-based emotion generation model for the robot's personality,Factor table,N,User Emotion to emotion output,Circumplex,NA,Core,General Interaction,Prototype,ifBot,"Recently, as the relationship between robot and human has become closer, humans demand that robots pose familiar human-like characteristics. For a robot to live and communicate with people, it requires its own personality or individuality. Changing the mood transition of robots can change the perceptions people have of their characteristics. We propose an emotion generation model that represents a robot's internal state. This model can assess the robot's individuality through mood transitions. We report experiments of emotional conversation with a robot that had this model installed. The experimental results showed that personality could be effectively expressed by changing robot's mood transitions. We also report significant results of evaluations of psychological impact.",C. Itoh; S. Kato; H. Itoh,"Dept. of Computer Science and Engineering, Nagoya Institute of Technology, Gokiso-cho Showa-ku Nagoya 466-8555 Japan; Dept. of Computer Science and Engineering, Nagoya Institute of Technology, Gokiso-cho Showa-ku Nagoya 466-8555 Japan; Dept. of Computer Science and Engineering, Nagoya Institute of Technology, Gokiso-cho Showa-ku Nagoya 466-8555 Japan","2009 IEEE International Conference on Systems, Man and Cybernetics",,2009,,,2878,2883,,,,,Sensitivity communication robot;Emotion generation model;Personality;Mood,Mood;Humans;Humanoid robots;Robot sensing systems;Service robots;Mobile robots;Psychology;Authentication;Cybernetics;USA Councils,emotion recognition;face recognition;humanoid robots;human-robot interaction;robot vision,robot mood-transition-based emotion generation model;robot personality;human-robot interaction;robot human-like characteristics;robot internal state;emotional conversation;psychological impact;Ifbot sensitivity communication robot;humanoid robot;mental model;human facial expression recognition,,7,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4650941,Motives as intrinsic activation for human-robot interaction,Factor table,N,Non-emotion stimuli to internal process and emotion,PAD,NA,Component,General Interaction,Implemented and Evaluated,ROMAN,"For humanoid robots that should assist humans in their daily life the capability of an adequate interaction with human operators is a key feature. A key factor for human like interaction is the usage of non-verbal communication. Therefore robots must be able to have some kind of emotions. These emotions mainly depends on the achievement of the goals of the interaction. Psychologists point out that motives generate these kind of goals to humans. Because of this, this paper presents a motive model for the emotion-based architecture of the humanoid robot ROMAN. For the implementation of these motives a behavior-based approach is used. Furthermore some experiments concerning the functionality of the motives of interaction are presented and discussed.",J. Hirth; K. Berns,"Robotics Research Lab, Departement of Computer Science, University of Kaiserslautern, Gottlieb-Daimler-Stra√üe, 67663, Germany; Robotics Research Lab, Departement of Computer Science, University of Kaiserslautern, Gottlieb-Daimler-Stra√üe, 67663, Germany",2008 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2008,,,773,778,,,,,,Robots;Humans;Robot sensing systems;Computer architecture;Psychology;Humanoid robots;Neck,emotion recognition;humanoid robots;human-robot interaction;mobile robots;service robots,human-robot interaction;humanoid robot;nonverbal communication;Psychologist;emotion-based architecture;intrinsic activation,,2,20,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4694442,Multi-dimensional emotional engine with personality using intelligent service robot for children,Factor table,N,Human and external to emotion output and internal process,Eckman,6,Core,General Interaction,Prototype,iRobiQ,"This paper introduces a multi-dimensional emotional engine which is influenced by personality of robot. It is a novel approach to design an emotional model by comparison with conventional emotional model which used three-dimensional emotional space. It calculates most emotional elements and memorizes them for the next step of calculation of emotion. This means that robot does not respond to external stimuli directly. We have designed a personality based emotional model. It consists of five elements; reactive dynamics, internal dynamics, emotional dynamics, behavior dynamics, and personality. Personality is the most important element for making different emotions and behaviors of various kinds of robots. It is related to most calculations in the emotional model. If personality is changed, the emotional model makes different emotions and behaviors, although external stimuli and internal dynamics remain unchanged. We have used the intelligent service robot dasiaiRobi Qpsila which is used for children. We have tested the performance of the proposed emotional engine.",Ho Seok Ahn; Young Min Baek; Jin Hee Na; Jin Young Choi,"School of Electrical Engineering and Computer Science, PIRC, ASRI, Seoul National University, Korea; School of Electrical Engineering and Computer Science, PIRC, ASRI, Seoul National University, Korea; School of Electrical Engineering and Computer Science, PIRC, ASRI, Seoul National University, Korea; School of Electrical Engineering and Computer Science, PIRC, ASRI, Seoul National University, Korea","2008 International Conference on Control, Automation and Systems",,2008,,,2020,2025,,,,,Emotional Engine;Personality;Intelligent Service Robot;Multi-Dimensional Emotional Engine,Engines;Intelligent robots;Service robots;Computer science;Orbital robotics;History;Humans;Automatic control;Control systems;Robotics and automation,human-robot interaction;intelligent robots;service robots,multi-dimensional emotional engine;intelligent service robot;children;robot personality;reactive dynamics;internal dynamics;emotional dynamics;behavior dynamics;'iRobi Q',,5,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=509305,Multi-variable virtual impedance control of a robot considering human emotions,Factor table,N,User Emotion to Internal Process,Custom Discrete,4,Core,General interaction,Prototype,Digital,"When robots conduct several tasks transmitting forces to humans, robots must be controlled taking human emotions into consideration. In this paper, a multivariable impedance control of a robot considering human emotions especially when a human contacts with or lean on the robot is proposed. First, human characteristics of changing his/her softness in decreasing the movement of an object which contacts with human hand with certain force are analyzed experimentally. It is expected that the human characteristics can be expressed by the multivariable impedance models. Second, we try to realize a multivariable impedance control of a robot favorable for human emotions based on the approximated human characteristics using rating-scale method.",M. S. Ben-Lamine; S. Shibata; K. Tanaka; A. Shimizu,"Dept. of Mech. Eng., Ehime Univ., Matsuyama, Japan; Dept. of Mech. Eng., Ehime Univ., Matsuyama, Japan; Dept. of Mech. Eng., Ehime Univ., Matsuyama, Japan; Dept. of Mech. Eng., Ehime Univ., Matsuyama, Japan",Proceedings of 4th IEEE International Workshop on Advanced Motion Control - AMC '96 - MIE,,1996,2,,535,540 vol.2,,,,,,Impedance;Robot control;Humans;Robotics and automation;Control systems;Intelligent robots;Mechanical engineering;Force control;Automatic control;Home automation,robots;human factors;man-machine systems;multivariable control systems,multivariable virtual impedance control;robot;human emotions;rating-scale method,,,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7353789,Multimodal adapted robot behavior synthesis within a narrative human-robot interaction,Factor table (one to one),N,User Emotion to emotion output,Eckman (no surprise),5,Component,General Interaction,Implemented and Evaluated,ALICE,"In human-human interaction, three modalities of communication (i.e., verbal, nonverbal, and paraverbal) are naturally coordinated so as to enhance the meaning of the conveyed message. In this paper, we try to create a similar coordination between these modalities of communication in order to make the robot behave as naturally as possible. The proposed system uses a group of videos in order to elicit specific target emotions in a human user, upon which interactive narratives will start (i.e., interactive discussions between the participant and the robot around each video's content). During each interaction experiment, the humanoid expressive ALICE robot engages and generates an adapted multimodal behavior to the emotional content of the projected video using speech, head-arm metaphoric gestures, and/or facial expressions. The interactive speech of the robot is synthesized using Mary-TTS (text to speech toolkit), which is used - in parallel - to generate adapted head-arm gestures [1]. This synthesized multimodal robot behavior is evaluated by the interacting human at the end of each emotion-eliciting experiment. The obtained results validate the positive effect of the generated robot behavior multimodality on interaction.",A. Aly; A. Tapus,"Robotics and Computer Vision lab. in ENSTA-ParisTech, 828 Boulevard des Mar√©chaux, 91120 Palaiseau, France; Robotics and Computer Vision lab. in ENSTA-ParisTech, 828 Boulevard des Mar√©chaux, 91120 Palaiseau, France",2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),,2015,,,2986,2993,,,,,,Speech;Robot kinematics;Synchronization;Engines;Three-dimensional displays;Generators,emotion recognition;humanoid robots;human-robot interaction;interactive systems;speech synthesis,robot behavior synthesis;human-robot interaction;emotion-eliciting experiment;humanoid expressive ALICE robot;interactive robot speech synthesis;text to speech toolkit;Mary-TTS;head-arm gesture generation,,5,42,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7821710,Multimodal architecture for emotion in robots using deep learning,CNN,N,User Emotion to emotion output,Eckman,6,Core,General interaction,Prototype,Digital,"These days, some robots have emotional state (expression and recognition) to make Human-Robot Interaction (HRI) and Robot-Robot Interaction (RRI) better. In this article we analyze what it means for a robot to have emotion and distinguishing emotional state for communication from an emotional state as a mechanism for the organization of its behavior with humans and robots by convolutional neural network (CNN). We discuss these relations and explain why it can be more effective by CNN for having better emotion in the robots. Here, we present a multimodal system for Emotions in Robots by CNN.",M. Ghayoumi; A. K. Bansal,"Artificial Intelligent Lab, Computer Science Department, Kent State University, Kent, Ohio, USA; Artificial Intelligent Lab, Computer Science Department, Kent State University, Kent, Ohio, USA",2016 Future Technologies Conference (FTC),,2016,,,901,907,,,,,multimodal systems;deep learning;emotion recognition;emotion expression;robot;convolutional neural network,Robots;Emotion recognition;Biological neural networks;Machine learning;Computer architecture;Visualization;Computer science,convolution;emotion recognition;human-robot interaction;learning (artificial intelligence);neurocontrollers,multimodal architecture;deep learning;robot emotional state;human-robot interaction;HRI;robot-robot interaction;RRI;behavior organization;convolutional neural network;CNN;multimodal system;emotion recognition;emotion expression,,6,45,,,,,IEEE,IEEE Conferences,,
,My robot is happy today: how older people with mild cognitive impairments understand assistive robots' affective output,Rule-based Computational Model,N,Non-emotion stimuli to emotion output,Custom Discrete,6,Component,General Interaction,Implemented and Evaluated,RAMCIP,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4209402,Natural Emotion Expression of a Robot Based on Reinforcer Intensity and Contingency,Rule-based Biology Model,N,Non-emotion stimuli to emotion output ,Custom Discrete,8,Core,General Interaction,Prototype,iCat,"An emotional robot is regarded as being able to express its diverse emotions in response to internal or external events. This paper presents a robot affective system that is able to express life-like emotions. In order to do that, the overall architecture of our affective system is based on neuroscience from which we obtained the natural emotional processing routines. Based on that architecture, we apply the reinforcer effects expecting that those would lead the affective system to be more similar to real-life's emotion expression. The robot affective system has responsibility for gathering environmental information and evaluating which environmental stimuli are rewarding or punishing. The emotion processing involves with appraisal of the external and internal stimuli, such as homeostasis, and generates the affective states of the robot. Therefore, emotions are associated with the presentation, omission, and termination of the expected rewards or punishers (reinforcers). The experimental results show that our affective system can express several emotions simultaneously as well as the emotions decrease, increase, or changes to another emotion seamlessly as time passes.",S. Lee; G. Park; J. Kim,"Intelligent Robot Research Division, Electronics and Telecommunications Research Institute, 161 Gajeong-dong, Yuseong-gu, Daejeon, 305-700, KOREA. e-mail: the_silee@etri.re.kr; Intelligent Robot Research Division, Electronics and Telecommunications Research Institute, 161 Gajeong-dong, Yuseong-gu, Daejeon, 305-700, KOREA. e-mail: pgy64257@etri.re.kr; Intelligent Robot Research Division, Electronics and Telecommunications Research Institute, 161 Gajeong-dong, Yuseong-gu, Daejeon, 305-700, KOREA. e-mail: jjkim@etri.re.kr",Proceedings 2007 IEEE International Conference on Robotics and Automation,,2007,,,2144,2149,,,,,,Humans;Orbital robotics;Cognitive robotics;Neuroscience;Intelligent robots;Cognitive science;Robotics and automation;Humanoid robots;Appraisal;Decision making,intelligent robots,natural emotion expression;reinforcer intensity;reinforcer contingency;emotional robot;robot affective system,,1,12,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6252498,Neural approach for personalised emotional model in human-robot interaction,Neural network,N,User Emotion to emotion output,Custom Discrete,3,Core,General interaction,Prototype,Nao,"Robotic technology is widely spreading into our everyday lives so the social interaction between robots and humans is becoming more important. We believe that the quality of human-robot interaction will determine the effectiveness of the collaboration and in general, the acceptance of robots in the society. With this motivation we propose a more intuitive way of interacting with robotic companions by recognizing human emotions and, on the other side, a methodology to construct a comprehensible way of expressing internal states of machines for human users. The novelty of our model consists in personalization of the emotional expressions for each of the users. The system consists of two parts: learning emotional expressions of humans using ARTMAP neural network and implementation of the personalised emotional model to a humanoid robot. This paper shows the first results based on experiments realized on the humanoid platform Nao. We achieved a personalised emotional behaviour especially useful in the area of social robotics.",M. Vircikova; M. Pala; P. Smolar; P. Sincak,"Center for Intelligent Technologies, Dpt. of Cybernetics and AI, Technical University of Kosice, Slovakia; Center for Intelligent Technologies, Dpt. of Cybernetics and AI, Technical University of Kosice, Slovakia; Center for Intelligent Technologies, Dpt. of Cybernetics and AI, Technical University of Kosice, Slovakia; Center for Intelligent Technologies, Dpt. of Cybernetics and AI, Technical University of Kosice, Slovakia",The 2012 International Joint Conference on Neural Networks (IJCNN),,2012,,,1,8,,,,,Computational models of emotions;fuzzy systems;human-robot interaction;MF-ARTMAP;Plutchik's psychoevolutionary theory of emotions,Humans;Emotion recognition;Neural networks;Vectors;Robot sensing systems;Humanoid robots,emotion recognition;humanoid robots;human-robot interaction;learning (artificial intelligence);neural nets,neural approach;personalised emotional model;human-robot interaction;robotic technology;social interaction;collaboration effectiveness;robot acceptance;human emotion recognition;machine internal state expression;human emotional expression learning;humanoid robot;humanoid platform Nao;personalised emotional behaviour;social robotics,,2,19,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4058781,Neurocognitive Affective System for an Emotive Robot,Rule-based Biology Model,N,Non-emotion stimuli to emotion output ,Custom Discrete,8,Core,General Interaction,Prototype,iCat,"For a service robot to be more human friendly, it is required to have various emotional interactions with human. Inspired from both neuroscience and cognitive science, this paper proposes a dynamic robot affective system that can have various emotional states at the same time and express those combined emotions just like humans do. The system comprises three modules: an appraisal module, an emotion-generation module, and an emotional expression module. The appraisal module has responsibility for gathering environmental information and evaluating whether external stimuli are rewarding or punishing. Based on the appraisal results and the homeostasis, the emotion-generation module generates affective states of the robot. The emotional expression module, then, combines and expresses emotional behaviors in accordance with the current affective states (e.g., producing facial expressions). As a result, the robot affective system can generate various emotions simultaneously and produces various emotional expressions continuously, just like human's sequential or parallel execution of emotional behaviors",G. Park; S. Lee; W. Kwon; J. Kim,"Intelligent Robot Research Division, Electronics and Telecommunications Research Institute, Daejeon, Korea; Computer Software Engineer Division, University of Science and Technology, Daejeon, Korea. Email: pgy64257@etri.re.kr; Intelligent Robot Research Division, Electronics and Telecommunications Research Institute, Daejeon, Korea; Computer Software Engineer Division, University of Science and Technology, Daejeon, Korea. Email: the_silee@etri.re.kr, pgy64257@etri.re.kr; Intelligent Robot Research Division, Electronics and Telecommunications Research Institute, Daejeon, Korea. Email: wykwon@etri.re.kr, pgy64257@etri.re.kr; Intelligent Robot Research Division, Electronics and Telecommunications Research Institute, Daejeon, Korea. Email: jjkim@etri.re.kr, pgy64257@etri.re.kr",2006 IEEE/RSJ International Conference on Intelligent Robots and Systems,,2006,,,2595,2600,,,,,emotion generation;affective computing;robot affective system;neuroscience;cognitive theory,Humans;Cognitive robotics;Appraisal;Neuroscience;Intelligent robots;Cognitive science;Humanoid robots;Orbital robotics;Service robots;Decoding,cognitive systems;robot dynamics;service robots,neurocognitive affective system;emotive robot;service robot;emotional interactions;neuroscience;cognitive science;dynamic robot affective system;appraisal module;emotion-generation module;emotional expression module;facial expressions;emotional expressions;sequential emotional behavior execution;parallel emotional behavior execution,,6,12,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8371114,Non-verbal communication-based emotion incitation robot,Factor table,N,User Emotion to emotion output,Custom Single,1,Core,General Interaction,Prototype,Custom Robot,"This paper introduces a robot system by which emotions are incited based on non-verbal communication, i.e., a series of motion such as eye movement. The designed and developed robot system comprises mainly three parts of an eyeball robot, an eyeball robot controller, and an emotion recognizer one based on image processing technique. The system configuration is described paying attention to ""emotion"" as a keyword to communicate between the robot and the human. The proposed system implements non-verbal communication by humorous eye movements from the robot to the human and emotion expression recognition by image processing from the human to the robot, respectively. In this paper, the authors focus on smile as a target of the emotion recognizer. We implemented some smile incitation experiments and their results were discussed.",S. Shimizu; K. Shimada; R. Murakami,"Department of Design Engineering, Shibaura Institute of Technology, 3-9-14 Shibaura, Minato-ku, Tokyo, 108-8548, Japan; Department of Design Engineering, Shibaura Institute of Technology, 3-9-14 Shibaura, Minato-ku, Tokyo, 108-8548, Japan; Department of Design Engineering, Shibaura Institute of Technology, 3-9-14 Shibaura, Minato-ku, Tokyo, 108-8548, Japan",2018 IEEE 15th International Workshop on Advanced Motion Control (AMC),,2018,,,338,341,,,,,emotion incitation robot;eye movement;non-verbal communication;emotion recognizer;image processeing,Robots;Emotion recognition;Image recognition,emotion recognition;eye;face recognition;man-machine systems;robot vision;robots,nonverbal communication;emotion incitation robot;eye movement;designed developed robot system;eyeball robot controller;emotion recognizer;image processing technique;system configuration;humorous eye movements;emotion expression recognition;smile incitation experiments,,,6,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5738883,Novel emotion dynamic express for robot,Rule-based Biology Model,N,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital,This paper proposes the novel emotion dynamic equation for emotion implementation like human's emotion. Almost general method use artificial approach such as neutral networks to classify emotion by using speech and face image data for human's emotion recognition. But high-dimension and large size of this data cause low-speed learning in robot system. The main idea of the proposed dynamic equation method is to dynamically express emotion by multi-agent function.,D. Kim; P. Baranyi,"Dept. of Instrumentation and Control Eng., Hanbat National University, Daejeon City, Korea; Head of Cognitive Informatics research group involved in the System and Control Laboratory, Computer and Automation Research Institute of the Hungarian Academy of Sciences (MTA SZTAKI)",2011 IEEE 9th International Symposium on Applied Machine Intelligence and Informatics (SAMI),,2011,,,243,245,,,,,,Robot sensing systems;Humans;Dynamics;Face;Equations,emotion recognition;human-robot interaction;learning (artificial intelligence);multi-agent systems;neural nets,emotion dynamic express;emotion dynamic equation;neutral networks;emotion classification;speech data;face image data;human emotion recognition;robot system;low speed learning;multiagent function,,3,7,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6343809,Personal identity module using psychoevolutionary emotion theory for social robots,Factor table,N,Human and external to emotion output ,Custom Discrete,8,Component,General Interaction,Prototype,Digital,"Robots that interacts socially in human being environment should be able to understand and act over it using clues from humans; it includes all types of expression: facial, non-facial, verbal and nonverbal affective expressions. These behaviors need a model capable to compute external and internal information to construct autonomous robots. In this paper, we are proposing a basis for modeling some reflexes inherent to human beings that are responsible by personal identity of each individual. The proposed model is constituted by two reflex modules and an emotion module that are based on psychoevolutionary theory. Then, this model has been inserted in our social architecture as an improvement of old motivational module and evaluated in a simulator. The advantage of the proposed approach from others is the possibility of representing the emotion as an internal function which varies over the time with different types of interaction. The experimental results show that this module is capable to emulate adequately human beings basic reflex in a robot during a simple interaction with a caregiver.",R. R. d. Silva; M. de Jesus Dutra dos Reis; R. A. F. Romero,"Department of Computer Science, ICMC, University of Sao Paulo, Sao Carlos, Brazil; Center for Education and Human Sciences, Federal University of Sao Carlos, Sao Paulo, Brazil; Department of Computer Science, ICMC, University of Sao Paulo, Sao Carlos, Brazil",2012 IEEE RO-MAN: The 21st IEEE International Symposium on Robot and Human Interactive Communication,,2012,,,551,558,,,,,,Humans;Mood;Service robots;Face;Organizations,emotion recognition;evolutionary computation;human-robot interaction;psychology,personal identity module;psychoevolutionary emotion theory;social robots;human-robot social interaction;nonfacial expression;verbal expression;nonverbal affective expression;external information;internal information;autonomous robot;human being;reflex module;emotion module;psychoevolutionary theory;social architecture;emotion representation;caregiver,,,24,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7942662,Personalized robot emotion representation through retrieval of memories,Rule-based - Computational Model (Cellular Automata),Y,User Emotion to emotion output,Cicurmplex,NA,Core,General Interaction,Prototype,Digital,We present a robot emotion representation model by investigating the role of human-inspired social effects and memory retrieval process. Social referencing and social sharing are modeled as human guides to share knowledge and direct or influence robot emotion generation. The robot's acquired knowledge is consolidated into a developmental memory architecture and used for future retrieval. This model enables robots interacting with their environment to learn from humans and form a human-like emotion generation process which helps to facilitate personalized human-robot interaction.,Thi Le Quyen Dang; Sungmoon Jeong; Nak Young Chong,"School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan","2017 3rd International Conference on Control, Automation and Robotics (ICCAR)",,2017,,,65,70,,,,,human-robot interaction;robot emotion;developmental architecture;social sharing;social referencing,Robots;Visualization,human-robot interaction,personalized robot emotion representation;human-inspired social effects;memory retrieval process;social referencing;social sharing;knowledge sharing;robot emotion generation;developmental memory architecture;human-like emotion generation;personalized human-robot interaction,,,28,,,,,IEEE,IEEE Conferences,,
,Pet Robot Emotional Interaction for Urban Autism,Probability table - user generated,Y,Human and external to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital - TOM,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6309474,Playing Tangram with a Humanoid Robot,Factor table,N,Non-emotion stimuli to internal process,Cicurmplex,NA,Component,General Interaction,Prototype,ROMAN,"An open question in the area of social robot interaction is how to design test scenarios that on one hand provide the required complexity and on the other hand are still describable. The tabletop game Tangram has been selected as a test scenario for human-robot interaction. This paper describes how the required skills, to enable the humanoid robot ROMAN to play the game, have been ralized. Experimental results demonstrate the functioning of the system and show how emotion influences robot's motivation.",J. Hirth; N. Schmitz; K. Berns,"Robotics Research Lab, Dept. of Computer Science, University of Kaiserslautern, Germany; Robotics Research Lab, Dept. of Computer Science, University of Kaiserslautern, Germany; Robotics Research Lab, Dept. of Computer Science, University of Kaiserslautern, Germany",ROBOTIK 2012; 7th German Conference on Robotics,,2012,,,1,6,,,,,,Games;Humans;Face;Detectors;Robot sensing systems;Tiles,,,,,,,,,,VDE,VDE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314899,Promoting Interactions Between Humans and Robots Using Robotic Emotional Behavior,Markovain emotional model,Y,Human and external to emotion output ,Custom Discrete,3,Core,General Interaction,Implemented and Evaluated,Brian,"The objective of a socially assistive robot is to create a close and effective interaction with a human user for the purpose of giving assistance. In particular, the social interaction, guidance, and support that a socially assistive robot can provide a person can be very beneficial to patient-centered care. However, there are a number of research issues that need to be addressed in order to design such robots. This paper focuses on developing effective emotion-based assistive behavior for a socially assistive robot intended for natural human-robot interaction (HRI) scenarios with explicit social and assistive task functionalities. In particular, in this paper, a unique emotional behavior module is presented and implemented in a learning-based control architecture for assistive HRI. The module is utilized to determine the appropriate emotions of the robot to display, as motivated by the well-being of the person, during assistive task-driven interactions in order to elicit suitable actions from users to accomplish a given person-centered assistive task. A novel online updating technique is used in order to allow the emotional model to adapt to new people and scenarios. Experiments presented show the effectiveness of utilizing robotic emotional assistive behavior during HRI scenarios.",M. Ficocelli; J. Terao; G. Nejat,"Department of Mechanical and Industrial Engineering, Autonomous Systems and Biomechatronics Laboratory, University of Toronto, Toronto, ON, Canada; Department of Mechanical Engineering, Autonomous Systems Laboratory, SUNY at Stony Brook, Stony Brook, NY, USA; Department of Mechanical and Industrial Engineering, Autonomous Systems and Biomechatronics Laboratory, University of Toronto, Toronto, ON, Canada",IEEE Transactions on Cybernetics,,2016,46,12,2911,2923,,,,Natural Sciences and Engineering Research Council of Canada; National Science Foundation (U.S.); ,Emotion model;human‚Äìrobot-interaction (HRI);social intelligence;socially assistive robots,Markov processes;Robot sensing systems;Adaptation models;Medical services;Computational modeling;Mathematical model,human-robot interaction;learning (artificial intelligence),socially assistive robot;robotic emotional behavior;patient-centered care;emotion-based assistive behavior;natural human-robot interaction;assistive HRI;novel online updating technique;learning-based control architecture,"Cybernetics;Emotions;Humans;Interpersonal Relations;Models, Psychological;Robotics;Self-Help Devices",19,55,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=973205,Proposal of emotion model in robot-assisted-activity,Fuzzy Rule Base,N,Non-emotion stimuli to internal process,Custom Single,1,Core,Performance,Prototype,Digital,Propose robot-assisted-activity and describes an experimental emotion model having mood congruency effects on the robot. The robot chooses sensor information and its own behavior according to its emotions.,T. Hashimoto,"Dept. of Urban Econ., Nasu Univ., Kuroiso, Japan","2000 26th Annual Conference of the IEEE Industrial Electronics Society. IECON 2000. 2000 IEEE International Conference on Industrial Electronics, Control and Instrumentation. 21st Century Technologies",,2000,1,,527,529 vol.1,,,,,,Proposals;Robots;Helium;Mood;Knowledge engineering;Legged locomotion;Character recognition;Aging;Stomach;Animals,mobile robots;handicapped aids,emotion model;robot-assisted-activity;aged population;sensor information;behavior;hierarchical knowledge;physical assistance;handicapped people;emotional oriented interface;fuzzy cognitive maps;mood congruency effects,,,5,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4215942,Quantum Mechanical Model of Emotional Robot Behaviors,Rule-based - Computational Model (Cellular Automata),N,Non-emotion stimuli to emotion output,Custom Discrete,6,Core,General Interaction,Prototype,Cynthea,"In this paper the emotional model of the humanoid Cynthea (cybernetic networked humanoid emotional agent) robot is presented. The model is detailed at two levels: the cognitive level is described by the CRL language, and the emotional level manipulates the language in a data independent way. An emotional mapping is introduced and is used to alter the language words using local energy-based rules. The robot is described as a set of functional agents, each acting on behalf of its own emotional function generating the whole robot emotional state. The cognitive level is applied to describe situations such as dialogues, interactions and behaviors specified in the CRL language. The emotional level is used as a mechanism to introduce behavioral changes in the robot's command execution. The interaction of these levels evolves in alterations to the desired behavior. To allow global effects on the language level with lower level behavioral variations we provide a model of robot-specific emotions based on quantum cellular automata.",M. Lukac; M. Perkowski,"Portland State University, USA; Portland State University, USA",37th International Symposium on Multiple-Valued Logic (ISMVL'07),,2007,,,19,19,,,,,,Quantum mechanics;Cognitive robotics;Biological system modeling;Humanoid robots;Robot sensing systems;Robotics and automation;Magnetic heads;Human robot interaction;Speech recognition;Cybernetics,cellular automata;cognitive systems;cybernetics;humanoid robots,quantum mechanical model;emotional robot behaviors;Cynthea;cybernetic networked humanoid emotional agent robot;cognitive level;CRL language;emotional mapping;energy-based rules;quantum cellular automata;robot-specific emotions,,6,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1612755,Real-time emotional architecture for robotic agents,Rule-based - Computational Model,N,Non-emotion stimuli to internal process,Binary,2,Component,Performance,Prototype,Digital,The interest of the creation of robots with emotions has been growing for the last years mainly in the topic of human-robot interaction. This paper focuses in the emotion as a mechanism for the organisation of the robot behaviour. An emotional robot should be adapted in real-time to the conditions of the environment based on its physical (actuators) and on its mental (processes) capabilities. A real-time emotional agent (RTEA) architecture where the attention of the mental processes (thoughts) is guided by an emotional system is presented. The attention system not only selects the behaviour but it adjusts its intensity as well. The flexibility to adjust the functional objectives to the mental capacity makes RTEA useful in those applications where the agent has to perform several simultaneous tasks,C. Dominguez; H. Hassan; A. Crespo,"Departamento de Informatica de Sistemas y Computadores, Univ. Politecnica de Valencia, Spain; Departamento de Informatica de Sistemas y Computadores, Univ. Politecnica de Valencia, Spain; Departamento de Informatica de Sistemas y Computadores, Univ. Politecnica de Valencia, Spain",2005 IEEE Conference on Emerging Technologies and Factory Automation,,2005,2,,7 pp.,803,,,,,,Biological system modeling;Biological control systems;Human robot interaction;Real time systems;Organisms;Robot control;Actuators;Time factors;Energy resources;Biological systems,emotion recognition;human computer interaction;robots;software agents,real-time emotional agent architecture;robotic agent;human-robot interaction;robot behaviour;emotional robotic system,,1,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=568870,Real-time facial interaction between human and 3D face robot agent,Neural network,N,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Face Robot,"We attempt to introduce a 3D realistic human-like animate face robot to human-robot communication modality. The face robot can recognize human facial expressions as well as produce realistic facial expressions in real time. For the animate face robot to communicate interactively, we propose a new concept of ""active human interface"", and we investigate the performance of real-time recognition of facial expressions by neutral network (NN) and the expression ability of facial messages on the face robot. We found that the NN recognition of facial expressions and face robots performance in generating facial expressions are of almost the same level as that in humans. We integrate these two component technologies for the face to produce facial expression in reaction to the recognition result of human facial expression in real time. This implies a high technological potential for the animate face robot to undertakes interactive communication with human when an artificial emotion being implemented.",F. Hara; H. Kobayashi,"Dept. of Mech. Eng., Sci. Univ. of Tokyo, Japan; NA",Proceedings 5th IEEE International Workshop on Robot and Human Communication. RO-MAN'96 TSUKUBA,,1996,,,401,409,,,,,,Human robot interaction;Facial animation;Man machine systems;Face recognition;Neural networks;Mechanical engineering;Communication channels;Speech;Magnetic heads;Conferences,user interfaces;interactive systems;feedforward neural nets;robots;computer vision;face recognition,real-time system;facial interaction;3D face robot agent;animate face robot;human-robot communication;human facial expressions;active human interface;neutral network;artificial emotion;facial reaction;computer vision,,3,17,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4376565,Research on Virtual Emotional Human System,Markovain emotional model,Y,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital,"Virtual emotional human system (VEHS) can be widely applied in game role and computer interface performance enhancement. Artificial emotion, as a branch of AI, is aimed at endowing robot with various emotions such as sorrow and happiness. So it becomes a more and more attractive research field than before and will be an advanced stage for AI. The research frame of (VEHS) is represented in this paper. And the emotional model, method and realization technology are also investigated. The model was set up combined six dimension emotional space with hidden Markov chains, which can be trained by the verbal and nonverbal information from a multiple databases. Furthermore a rudiment of VEHS was formed based on this model and evolved later from the communication with outside gradually. A simulation has been developed and the results are encouraging. It is expected to be applied into the interface between human and machine in the future.",Li Peng; X. Wang; S. Zhu; X. Gu,"College of Communication and Control Engineering, Southern Yangtze University, Wuxi, P.R.China, 214122. Pengli@sytu.edu.cn; College of Communication and Control Engineering, Southern Yangtze University, Wuxi, P.R.China, 214122; College of Communication and Control Engineering, Southern Yangtze University, Wuxi, P.R.China, 214122; School of Information Engineering, Hebei polytechnical University, Tangshan 063009",2007 IEEE International Conference on Control and Automation,,2007,,,1268,1272,,,,,artificial emotion;emotional model with hidden Marko;virtual emotional human system (VEHS),Humans;Hidden Markov models;Artificial intelligence;Computer interfaces;Automatic control;Cognitive science;Machine intelligence;Space technology;Application software;Communication system control,artificial intelligence;hidden Markov models,virtual emotional human system;computer interface perfermance enhancemnet;artificial emotion;realization technology;hidden Markov chains,,,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8843206,Respect Your Emotion: Human-Multi-Robot Teaming based on Regret Decision Model,Rule-based - Computational Model,Y,Non-emotion stimuli to internal process,Custom Single (Regret),1,Component,General Interaction,Implemented and Evaluated,Digital,"Often, when modeling human decision-making behaviors in the context of human-robot teaming, the emotion aspect of human is ignored. Nevertheless, the influence of emotion, in some cases, is not only undeniable but beneficial. This work studies the human-like characteristics brought by regret emotion in one-human-multirobot teaming for the application of domain search. In such applications, the task management load is outsourced to the robots to reduce the human's workload, freeing the human to do more important work. The regret decision model is first used by each robot for deciding whether to request human service, then is extended for optimally queuing the requests from multiple robots. For the movement of the robots in the domain search, we designed a path planning algorithm based on dynamic programming for each robot. The simulation shows that the human-like characteristics, namely, risk-seeking and risk-aversion, indeed bring some appealing effects for balancing the workload and performance in the human-multi-robot team.",L. Jiang; Y. Wang,"Mechanical Engineering Department, Clemson University, Clemson, SC, 29634, USA; Mechanical Engineering Department, Clemson University, Clemson, SC, 29634, USA",2019 IEEE 15th International Conference on Automation Science and Engineering (CASE),,2019,,,936,941,,,,,,Robot kinematics;Robot sensing systems;Decision making;Task analysis;Intelligent agents,decision making;dynamic programming;human-robot interaction;mobile robots;motion control;multi-robot systems;path planning,one-human-multirobot teaming;domain search;regret decision model;human service;multiple robots;human-robot teaming;regret emotion;human decision-making behaviors;human-multirobot teaming;human-like characteristics;task management load;robot movement;path planning algorithm;dynamic programming;risk-seeking;risk-aversion;workload balancing,,,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6974092,Reward shaping for reinforcement learning by emotion expressions,Reinforcement Learning,N,Non-emotion stimuli to internal process,Binary,2,Core,Performance,Prototype,Digital,"In this paper, a non-expert learning system was proposed to guide the robots learn their behaviors by humans' emotional expressions. The proposed system used interval fuzzy type-2 algorithm to recognize the human's facial expressions, which were captured by a web camera. Furthermore, emotion value (E-value), generated based on non-expert human's facial expressions, was applied to the reinforcement learning to train robots. Two kinds of problems were experimented. One was the human being know the exact solution to train robots and could clearly observe good or bad choice robots had been made. The other one was human being did not know the exact solution but robots could still learn from human's experience. The experiment results show that no matter the learning environment could be clearly observed by human being or not, robots could learn from human's facial expressions by the proposed learning system.",K. S. Hwang; J. L. Ling; Y. Chen; W. Wang,"Department of Electrical Engineering, National Sun Yat-sen University, Kaoshiung, Taiwan; Department of Information Management, Shih Hsin University, Taipei 11678, Taiwan; Department of Electrical Engineering, National Chung Cheng University, Chiayi, Taiwan; Precision Machinery Research & Development Center, Taiwan","2014 IEEE International Conference on Systems, Man, and Cybernetics (SMC)",,2014,,,1288,1293,,,,,emotion expression;fuzzy theory;intelligent robots;reinforcement learning,Robots;Learning (artificial intelligence);Mouth;Face recognition;Erbium;Learning systems;Shape,emotion recognition;face recognition;fuzzy set theory;human-robot interaction;image sensors;learning (artificial intelligence);robot vision,reward shaping;reinforcement learning;emotion expressions;nonexpert learning system;robot guidance;interval fuzzy type-2 algorithm;human facial expression recognition;web camera;emotion value;robot training,,,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7743957,RNN with Russell's circumplex model for emotion estimation and emotional gesture generation,RNN,N,User emotion to emotion output,Cicurmplex,NA,Core,General Interaction,Prototype,Digital,"Interactive Emotion Communication (IEC) has been proposed[1] and studied so far. IEC consists of three processes, recognition of human emotion, generation of robot emotion, and expression of robot emotion. Conventional studies designed those processes by hand one by one. This report proposes a comprehensive system that learns human emotion recognition and robot emotion expression both. The proposed system is a recurrent neural network introducing Russell's circumplex model explicitly and learns human emotion and corresponding motion pattern simultaneously. We show the validity of the proposed method through experiments.",T. Tsujimoto; Y. Takahashi; S. Takeuchi; Y. Maeda,"University of Fukui, Bunkyo 3-9-1, Fukui, Fukui, 910-8507, Japan; University of Fukui, Bunkyo 3-9-1, Fukui, Fukui, 910-8507, Japan; University of Fukui, Bunkyo 3-9-1, Fukui, Fukui, 910-8507, Japan; Institute of Technologists, 333 Maeya, Gyoda-city, Saitama 361-0038, Japan",2016 IEEE Congress on Evolutionary Computation (CEC),,2016,,,1427,1431,,,,,,Robots;Emotion recognition;Neurons;Recurrent neural networks;Context;IEC;Estimation,emotion recognition;image motion analysis;recurrent neural nets;robot vision,emotional gesture generation;emotion estimation;Russell's circumplex model;interactive emotion communication;IEC;human emotion recognition;robot emotion expression;recurrent neural network,,3,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7090383,ROBEE: A homeostatic-based social behavior controller for robots in Human-Robot Interaction experiments,Rule-based - Computational Model,,Human and external to emotion output ,Cicurmplex,NA,Component,General Interaction,Prototype,Nao,"This paper presents the development and implementation of Robee, a novel social behavior controller for robots with a focus on Human-Robot Interaction (HRI) studies. Using the homeostatic drive theory, Robee selects the behaviors in order to maintain the needs, mainly psychological and social, within an acceptable range. We propose a hybrid concept for the decision making process, which combines the hierarchical approach and Parallel-rooted, Ordered, Slip-stack Hierarchical (POSH) architecture. Emotions are mapped in a two-dimensional space consisting of valence and arousal. A joint attention HRI experiment with children and NAO robot has been conducted showing the usage of the controller. Robee is expected to be implemented in more robotic platforms.",H. Cao; P. G. Esteban; A. De Beir; R. Simut; G. Van de Perre; D. Lefeber; B. Vanderborght,"Vrije Universiteit Brussel, Robotics & Multibody Mechanics Research Group, Pleinlaan 2, 1050 Brussels, Belgium; Vrije Universiteit Brussel, Robotics & Multibody Mechanics Research Group, Pleinlaan 2, 1050 Brussels, Belgium; Vrije Universiteit Brussel, Robotics & Multibody Mechanics Research Group, Pleinlaan 2, 1050 Brussels, Belgium; Vrije Universiteit Brussel, Department of Clinical and Life Span Psychology Group, Pleinlaan 2, 1050 Brussels, Belgium; Vrije Universiteit Brussel, Robotics & Multibody Mechanics Research Group, Pleinlaan 2, 1050 Brussels, Belgium; Vrije Universiteit Brussel, Robotics & Multibody Mechanics Research Group, Pleinlaan 2, 1050 Brussels, Belgium; Vrije Universiteit Brussel, Robotics & Multibody Mechanics Research Group, Pleinlaan 2, 1050 Brussels, Belgium",2014 IEEE International Conference on Robotics and Biomimetics (ROBIO 2014),,2014,,,516,521,,,,,,Psychology;Joints;Robot sensing systems;Service robots;Aerospace electronics;Decision making,decision making;human-robot interaction;social aspects of automation,NAO robot;children;parallel-rooted ordered slip-stack hierarchical architecture;decision making process;homeostatic drive theory;Robee;human-robot interaction;homeostatic-based social behavior controller,,2,30,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6595215,Robot emotions generated and modulated by visual features of the environment,Reinforcement Learning,N,Non-emotion stimuli to internal process,Discrete Custom,7,Core,General Interaction,Prototype,DARwIn-OP,"Emotions are generated and modulated by many factors in the ever-changing surrounding environment. A new and challenging task is to emulate emotional responses on a robot that are caused by visual stimuli, such that the robot's responses mirror that of the human user. This paper presents the initial stage of an affective system that has been trained on-line using reinforcement learning to generate and modulate emotions. The inputs of the system comprise a subset of emotionally relevant visual features extracted from the environment: colours, fractal dimension, and facial pareidolia. These inputs are mapped onto an output that expresses the associated emotion in terms of language. Pilot experiments demonstrate how a humanoid robot tries to learn through interaction with a human companion to express emotions associated with different environmental scenes in a (near) human-like manner.",A. S. W. Wong; S. Nicklin; K. Hong; S. K. Chalup; P. Walla,"Newcastle Robotics Laboratory, School of Electrical Engineering and Computer Science, The University of Newcastle, Australia; Newcastle Robotics Laboratory, School of Electrical Engineering and Computer Science, The University of Newcastle, Australia; Newcastle Robotics Laboratory, School of Electrical Engineering and Computer Science, The University of Newcastle, Australia; Newcastle Robotics Laboratory, School of Electrical Engineering and Computer Science, The University of Newcastle, Australia; School of Psychology, Centre for Translational Neuroscience and Mental Health Research, The University of Newcastle, Australia",2013 IEEE Symposium on Computational Intelligence for Creativity and Affective Computing (CICAC),,2013,,,9,16,,,,,,Robots;Fractals;Image color analysis;Feature extraction;Visualization;Image edge detection;Detectors,emotion recognition;feature extraction;humanoid robots;human-robot interaction;learning (artificial intelligence),robot emotion;visual features;visual stimuli;reinforcement learning;feature color;fractal dimension;facial pareidolia;humanoid robot;environmental scene;human-like manner,,,43,,,,,IEEE,IEEE Conferences,,
,Robot Enabled Service Personalisation Based On Emotion Feedback,Fuzzy Rule Base,N,User Emotion to Internal Process,Binary,2,Core,General Interaction,Prototype,Digital,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4407000,Robot feeling formation based on image features,Rule-based - Computational Model,N,Non-emotion stimuli to internal process and emotion,Binary,2,Core,Performance,Prototype,Plat-F1,"Feeling and emotion are important to human being during his/her learning process, also valuable to be adopted into intelligent machines. This research presents a system which forms and expresses feelings of a robot. The vision information of robot is used and the environment features are categorized by a hierarchical SOM (Self-Organization Map). The proposed SOM here combines a feature map, an action map and a feeling map together, and the action policy of robot is modified by reinforcement learning rule, feeling degree is complicated by a dequantization algorithm. The experiments through computer simulation and an autonomous robot in the real environment showed robot's feelings formation process and its emotional actions.",Takashi Kuremoto; Tomoe Hano; Kunikazu Kobayashi; Masanao Obayashi,"Division of Electrical and Information Engineering, Graduate School of Yamaguchi University, Ube, Japan; Division of Electrical and Information Engineering, Graduate School of Yamaguchi University, Ube, Japan; Division of Electrical and Information Engineering, Graduate School of Yamaguchi University, Ube, Japan; Division of Electrical and Information Engineering, Graduate School of Yamaguchi University, Ube, Japan","2007 International Conference on Control, Automation and Systems",,2007,,,758,761,,,,,autonomous robot;emotional intelligence;feeling formation;image processing,Intelligent robots;Cognitive robotics;Learning systems;Computational intelligence;Orbital robotics;Robotics and automation;Humans;Robot vision systems;Psychology;Robot sensing systems,image classification;learning (artificial intelligence);mobile robots;robot vision;self-organising feature maps,intelligent machine;robot vision;hierarchical SOM;self-organization map;reinforcement learning rule;dequantization algorithm;image feature;autonomous robot feeling formation;robot emotional action;image classification,,3,8,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6470500,Robot Partner Development Using Emotional Model Based on Sensor Network,Rule-based - Computational Model,N,Non-emotion stimuli to emotion output ,Discrete Custom,4,Core,General Interaction,Prototype,iPhonoid,"This paper discusses the development of robot partner that can perform not only static conversation, but also can perform emotion expression by facial expression, gesture, and word expression using emotional model based on sensor network, therefore it can interact naturally with a person. Generally, the robot has sensors equipped inside it, however to express emotion the equipped sensors are not enough to grasp the necessary input information about the surrounding environmental situation. Therefore we propose a sensor network applied to the robot partner for estimating the environment states as input data, after that the acquired data is processed using emotional model to gain the desired emotional expression. In this paper, first we explain the concept of informationally structured space, robot partner that we are developing, and sensor network. Next, we explain the development of emotional model that consists of data acquisition from sensor network as an input and the model output such as face, gesture, and word expression. Finally, we conduct several experiments based on the proposed method, and discuss the ability of emotional model to develop robot partner that can perform emotional expression.",D. Tang; B. Yusuf; J. Botzheim; N. Kubota; I. A. Sulistijono,"Dept. of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, 191-0065, Japan; Dept. of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, 191-0065, Japan; Dept. of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, 191-0065, Japan; Dept. of System Design, Tokyo Metropolitan University, 6-6 Asahigaoka, Hino, 191-0065, Japan; Mechatronics Engineering Division, Department of Mechanical and Energy Engineering, Electronic Engineering Polytechnic Institute of Surabaya (EEPIS), Jalan Raya ITS Sukolilo, 60111, Indonesia","2012 IEEE Conference on Control, Systems & Industrial Informatics",,2012,,,196,201,,,,,intelligent robot;human robot interaction;emotional model;sensor network,Robot sensing systems;Image resolution;Internet,data acquisition;distributed sensors;emotion recognition;human-robot interaction;intelligent robots;state estimation,robot partner development;sensor network;static conversation;emotion expression;facial expression;gesture;word expression;emotional model;state estimation;data acquisition;human robot interaction;intelligent robot,,5,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=894574,Robot personalization based on the mental dynamics,Rule-based - Computational Model,N,Non-emotion stimuli to emotion output,Eckman Extension,12,Core ,General Interaction,Prototype,WE-3RIV,"The authors have been developing anthropomorphic head robots in order to develop a new head mechanisms and functions for a humanoid robot having the ability to communicate naturally with a human by expressing human like emotion. We developed the anthropomorphic head-eye robot ""WE-3RIV"" (Waseda Eye No.3 Refined IV) which has four sensations and facially expresses emotions in 2000. We have recently added the olfactory sensation and the facial color expression function to its previous model, WE-3RIII, and we improved and rebuilt its artificial psychological model that consists of a 3D mental space having pleasantness, activation and certainty axes. When the robot senses the stimulus, a mental vector moves in the mental space based upon a set of differential equations in the mathematical formulation. We named it ""equations of emotion. "" We also introduced the robot personality, which consists of the sensing personality and the expression personality. WE-3RIV was realized to express the mental state affected by various stimuli based on the equations of emotion and the robot personality.",H. Miwa; T. Umetsu; A. Takanishi; H. Takanobu,"Graduate Sch. of Sci. & Eng., Waseda Univ., Tokyo, Japan; NA; NA; NA",Proceedings. 2000 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2000) (Cat. No.00CH37113),,2000,1,,8,14 vol.1,,,,,,Robot kinematics;Humans;Humanoid robots;Robot sensing systems;Service robots;Orbital robotics;Anthropomorphism;Olfactory;Psychology;Manufacturing industries,robots;image sensors;tactile sensors;gas sensors;differential equations;motion control,robot personalization;mental dynamics;anthropomorphic head robots;humanoid robot;WE-3RIV;olfactory sensation;facial color expression function;artificial psychological model;3D mental space;stimulus;mental vector;equations of emotion;robot personality;sensing personality;expression personality,,5,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6628437,Robot recommender system using affection-based episode ontology for personalization,Rule-based - Computational Model,N,Human and external to emotion output and internal process,Custom Discrete,6,Core,General Interaction,Prototype,Engkey,"This paper proposes a robot recommender system, which uses a hybrid filtering method based on n-gram affective event model. Nowadays there are strong tendency to utilize a robot for educational services, which can provide educational contents to enhances individual student's motivation. However, the current service robots can be more holistic systems to offer personalized robotic services to satisfy every individuals by reflecting their preferences. Here, robotic service can be another field to meet personal need. Hybrid approaches of personalization technology that combine collaborative filtering approaches and content-based approaches are proposed over the last decade. Especially, n-gram based approaches are proposed to utilize sequential information from very large data sets. This paper suggests an extends affective event model and its n-gram model combining fact semantic knowledge, event episodic knowledge and emotion. To show the validity of the proposed approach, we applied the scenario of English learning. The experiment results shows that an educational service robot recommend two students as different content types, even though they miss same question.",G. H. Lim; S. W. Hong; I. Lee; I. H. Suh; M. Beetz,"Intelligent Autonomous Systems, Technische Universit√§t M√ºnchen, Munich, Germany; Department of Computer Science and Engineering, Hanyang University, Seoul, Korea; Department of Computer Science and Engineering, Hanyang University, Seoul, Korea; Department of Computer Science and Engineering, Hanyang University, Seoul, Korea; Institute for Artificial Intelligence, University of Bremen, Germany",2013 IEEE RO-MAN,,2013,,,155,160,,,,,,Ontologies;Semantics;Recommender systems;Collaboration;Games;Service robots,collaborative filtering;educational robots;recommender systems;service robots,educational service robot;semantic knowledge;event episodic knowledge;English learning;content-based approach;collaborative filtering approach;personalized robotic services;educational contents;educational services;n-gram affective event model;hybrid filtering method;affection-based episode ontology;robot recommender system,,1,31,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8932912,Robot Social Emotional Development through Memory Retrieval*,Rule-based - Computational Model,Y,Human and external to emotion output and internal process,Circumplex,NA,Core,General Interaction,Prototype,Pepper,"Robot emotion representation is gaining increasing attention to facilitate long-term human-robot interaction (HRI) in recent years. In particular, human-like robot emotion elicited through HRI is of great use in creating trust between humans and robots. In attempting to represent robot emotions that lead to gaining social acceptance, psychological studies of human emotion have been extensively performed. Among the various factors that affect the way people express their emotional competencies, we conjecture that two factors, social interaction and experience, can be considered important to elicit human emotions, and therefore can be used to represent robot emotions. We believe that social and developmental interaction paradigms, such as social sharing and social referencing, can shape robot emotions toward promoting social acceptance. Besides, the robot's previous experience can be a key factor contributing to robot personality formation and development. In this paper, we not only focus on the modeling of two eliciting factors affecting the formation of robot emotion but also examine the decline of memory retention over time. Specifically, the relationship between emotion and memory is investigated to design a filter for the memory consolidation process and memory forgetting mechanism. The mechanism is used to enhance robot memory performance based on emotional salience and time parameters. Experiments were performed with a humanoid robot Pepper having verbal and non-verbal interactions with 24 human subjects. Participants rate their perception of the robot in terms of human-likeness, likeability, safety, and emotional expressions through a questionnaire. The results showed that most of the participants enjoyed interacting with the robot and they wished they could have more interactions in the future. They perceived safety and responded favorably toward the robot emotional expressions.",H. Bui; T. L. Q. Dang; N. Y. Chong,"Japan Advanced Institute of Science and Technology,School of Information Science,Ishikawa,Japan,923-1292; Japan Advanced Institute of Science and Technology,School of Information Science,Ishikawa,Japan,923-1292; Japan Advanced Institute of Science and Technology,School of Information Science,Ishikawa,Japan,923-1292",2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA),,2019,,,46,51,,,,,,,emotion recognition;humanoid robots;human-robot interaction;mobile robots;psychology,robot social emotional development;robot emotion representation;human-robot interaction;social acceptance;human emotion;emotional competencies;social interaction paradigms;developmental interaction paradigms;robot personality formation;robot memory performance;humanoid robot Pepper;robot emotional expressions,,,21,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4568486,Robot with Emotion for Triggering Mixed-Initiative Interaction Planning,Factor table,N,Non-emotion stimuli to internal process and emotion,Custom Discrete,3,Core,General Interaction,Prototype,Digital,"Emotion is one of human communication' channels; and in this paper -as part of mixed-initiative-emotion is used for triggering user interaction. Three interaction-planning modes which agglutinate seven interaction-types are introduced. This work shows how the existing framework changes by adding emotion to robot. For planning, scripts are used for the implementation of the ideas presented, where emotional expressions reduces the number of interactions.",M. Acosta; D. Kang; H. Choi,"Sch. of Eng., Inf. & Commun. Univ., Daejeon; Sch. of Eng., Inf. & Commun. Univ., Daejeon; Sch. of Eng., Inf. & Commun. Univ., Daejeon",2008 IEEE 8th International Conference on Computer and Information Technology Workshops,,2008,,,98,103,,,,,,Human robot interaction;Cognitive robotics;Service robots;Orbital robotics;Communication channels;Robotics and automation;Interleaved codes;Information technology;Conferences;Technology planning,man-machine systems;planning;robots,mixed-initiative interaction planning modes;human communication channels;mixed-initiative-emotion;triggering user interaction;robot emotion,,,22,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680043,Robot's behavior expressions according to the sentence types and emotions with modification by personality,Factor table,N,Non-emotion stimuli to emotion output,Custom Discrete,14,Core,General Interaction,Prototype,Silbot,"Expression has become one of important parts in human-robot interaction as an intuitive communication channel between humans and robots. However it is very difficult to construct robot's behaviors one by one. Developers consider how to make various motions of the robot easily. Therefore we propose an useful behavior expression method according to the sentence types and emotions. In this paper, robots express behaviors using motion sets of multi-modalities described as a combination of sentence types and emotions. In order to gather the data of multi-modal motion sets, we used video analysis of the actress for human modalities and did user-test for non-human modalities. We developed a behavior edit-toolkit to make and modify robot's behaviors easily. And also we proposed stereotyped actions according to the robot's personality for diversifying behavior expressions. Defined 25 behaviors based on the sentence types and emotions are applied to Silbot, a test-bed robot in CIR of Korea, and used for the English education.",Jong-Chan Park; Hyunsoo Song; Seongyong Koo; Young-Min Kim; Dong-Soo Kwon,"Department of Mechanical Engineering and Human-Robot Interaction Research Center, KAIST(Korea Advanced Institute of Science and Technology), Daejeon 305-701, Republic of Korea; M.E. and HRI Research Center, KAIST, Daejeon, Republic of Korea; M.E. and HRI Research Center, KAIST, Daejeon, Republic of Korea; M.E. and HRI Research Center, KAIST, Daejeon, Republic of Korea; M.E. and HRI Research Center, KAIST, Daejeon, Republic of Korea",2010 IEEE Workshop on Advanced Robotics and its Social Impacts,,2010,,,105,110,,,,,,Humans;Software;Mobile robots;Synchronization;Wheels;Context,behavioural sciences;human-robot interaction;motion estimation;robot programming,human robot interaction;intuitive communication channel;robot behavior;behavior expression method;multimodal motion;video analysis;behavior edit toolkit;Korea;CIR;Silbot;English education;sentence types;emotions;robot personality,,,13,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5723386,"Robot's emotion generation model for transition and diversity using energy, entropy, and homeostasis concepts",Rule-based - Computational Model,N,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital,"Abstract-This study is for describing a robot's emotion generation and transition by introducing concepts of energy, entropy, and homeostasis. Robot has been deeply involved to the human society, and required social roles to interact with people personally, socially, and universally. So a lot of researchers have been studied how a robot can generate their own emotions. Among several approaches to explain the emotional structure, the dimensional approach based on factors of pleasure and arousal is used due to the merit of the interpolation between emotions in an emotional space. Specifically, Circumplex model is used which has also two factors: pleasure and arousal, and this model indicates how emotions are distributed in the two-dimensional plane. Two kinds of energy states: mental energy and physical energy are introduced by the definition of psychological energy from psychodynamics. Then these two energy states are matched to pleasure and arousal respectively. First, the mental energy is updated by the result of Prospect theory which measures the value of gain and loss as pleasure factor. And the physical energy is updated by the result of the hedonic scaling which measures the levels of arousal from pleasure, and by the intensity of stimuli. Then each energy state is fed by entropy and homeostasis. The feedback loop by entropy is to satisfy the 2nd law of thermodynamics, and the feedback loop by homeostasis is to satisfy the property of a living system. The energy states generated by stimuli and fed by entropy and homeostasis take a position in the plane of Circumplex model. And distances between the current position and other emotions are computed to get a level of each emotion, proportional to the inverse of the distance. Finally, for the experimental result, only Ekman's six basic emotions were expressed by the face simulator, FRESi to which LDAEM is applied.",W. H. Lee; J. W. Park; W. H. Kim; J. C. Kim; M. J. Chung,"Department of Electrical Engineering, KAIST, Daejeon 305-701, Rep. of Korea; Department of Electrical Engineering, KAIST, Daejeon 305-701, Rep. of Korea; Department of Electrical Engineering, KAIST, Daejeon 305-701, Rep. of Korea; Department of Electrical Engineering, KAIST, Daejeon 305-701, Rep. of Korea; Department of Electrical Engineering, KAIST, Daejeon 305-701, Rep. of Korea",2010 IEEE International Conference on Robotics and Biomimetics,,2010,,,555,560,,,,,,Energy states;Entropy;Robots;Biological system modeling;Mathematical model;Loss measurement;Humans,entropy;feedback;human-robot interaction,robot emotion generation model;homeostasis concepts;energy concepts;entropy concepts;circumplex model;psychodynamics;prospect theory;feedback loop;FRESi;LDAEM,,1,19,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5326128,Robot's individual emotion generation model and action coloring according to the robot's personality,Factor table,N,Non-emotion stimuli to emotion output ,Custom Discrete,5,Core,General Interaction,Prototype,Kamero,"In order to achieve a believable interaction between humans and robots, synthesizing the reasonable and natural emotion is important. Furthermore, improving the adjustability of parameters' values in the model is essential for the designer of a robot. In this paper we developed a hybrid emotion generation architecture and defined the generalized context inputs of emotion generation model for convenient use by a robot designer. We also developed the personality model based on the Big-Five personality factors to generate the various emotions and action colorings. The personality model affected not only the intensity of the generated emotion, mood state, and emotion decay, but also the action selection of the robot. So, for each circumstance, the robot can show the distinct emotional state and modified actions, which we call action colorings. The developed emotion generation system is integrated into a robot which responds to the user's calling, and manages the schedule of the human.",J. Park; H. Kim; Y. Kim; D. Kwon,"Mechanical Engineering Department and Human-Robot Interaction Research Center, KAIST(Korea Advanced Institute of Science and Technology), Daejeon 305-701, Republic of Korea; M.E. and HRI Research Center, KAIST, Daejeon, Republic of Korea; M.E. and HRI Research Center, KAIST, Daejeon, Republic of Korea; M.E. and HRI Research Center, KAIST, Daejeon, Republic of Korea",RO-MAN 2009 - The 18th IEEE International Symposium on Robot and Human Interactive Communication,,2009,,,257,262,,,,,,Human robot interaction;Robot sensing systems;Context modeling;Character generation;Mood;Hybrid power systems;Intelligent robots;Nonhomogeneous media;Bayesian methods;Psychology,cognition;intelligent robots,emotion generation model;action coloring;hybrid emotion generation architecture;robot designer;big-five personality factors;emotion generation system,,9,24,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6376252,Robotic Emotional Expression Generation Based on Mood Transition and Personality Model,Rule-based - Computational Model,Y,User Emotion to emotion output,Circumplex,NA,Core,General Interaction,Implemented and Evaluated,Digital,"This paper presents a method of mood transition design of a robot for autonomous emotional interaction with humans. A 2-D emotional model is proposed to combine robot emotion, mood, and personality in order to generate emotional expressions. In this design, the robot personality is programmed by adjusting the factors of the five factor model proposed by psychologists. From Big Five personality traits, the influence factors of robot mood transition are determined. Furthermore, a method to fuse basic robotic emotional behaviors is proposed in order to manifest robotic emotional states via continuous facial expressions. An artificial face on a screen is a way to provide a robot with a humanlike appearance, which might be useful for human-robot interaction. An artificial face simulator has been implemented to show the effectiveness of the proposed methods. Questionnaire surveys have been carried out to evaluate the effectiveness of the proposed method by observing robotic responses to a user's emotional expressions. Preliminary experimental results on a robotic head show that the proposed mood state transition scheme appropriately responds to a user's emotional changes in a continuous manner.",M. Han; C. Lin; K. Song,"Department of Electrical Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical Engineering, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical Engineering, National Chiao Tung University, Hsinchu, Taiwan",IEEE Transactions on Cybernetics,,2013,43,4,1290,1303,,,,,Emotional model;facial expression generation;facial expression recognition;robotic behavior fusion;robotic emotional interactions;robotic mood state transition,Mood;Robot kinematics;Humans;Emotion recognition;Prototypes;Face,emotion recognition;human-robot interaction;intelligent robots;sensor fusion,robotic emotional expression generation;autonomous emotional interaction;2-D emotional model;robot personality;five factor model;psychologists;big five personality traits;robot mood transition design;robotic emotional behavior fusion;robotic emotional states;continuous facial expression;humanlike appearance;human-robot interaction;artificial face simulator;robotic responses;user emotional expression;mood state transition scheme,"Affect;Cybernetics;Facial Expression;Humans;Models, Biological;Personality;Robotics",39,48,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=943667,Self-consciousness and emotion for a pet robot with structured intelligence,Fuzzy Rule Base,N,Non-emotion stimuli to internal process,Custom Discrete,4,Component,Performance,Prototype,Digital,"The pet robots require several capabilities such as perceiving, acting, surviving, and communicating with human. The communication is an important aspect for the owner to establish a friendliness with the pet robot. Furthermore, an internal model independent of environmental states is also important, because the pet robot should be seen to be alive. Therefore, this paper discusses the issues of emotions and self-consciousness for a pet robot. We consider two assumptions about self-consciousness. First, the self-consciousness is activated when a temporal change of perceptual information is relatively big. Second, the self-consciousness is activated when the predicting perceptual information is different from the actual perceptual information. Furthermore, we discuss the unit of the behavior using a modular neural network for robotic systems. We conduct several computer simulations and experiments based on these assumptions.",N. Kubota; F. Kojima; T. Fukuda,"Dept. of Human & Artificial Intelligent Syst., Fukui Univ., Japan; NA; NA",Proceedings Joint 9th IFSA World Congress and 20th NAFIPS International Conference (Cat. No. 01TH8569),,2001,,,2786,2791 vol.5,,,,,,Intelligent robots;Positron emission tomography;Intelligent structures;Artificial intelligence;Neural networks;Robot sensing systems;Microcomputers;Neurodynamics;Humans;Computer simulation,robots;artificial intelligence;neural nets,pet robots;structured intelligence;perceptual information;modular neural network;emotional model;behavioral unit;self-consciousness,,12,8,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7803408,Sequential decision making based on emergent emotion for a humanoid robot,Reinforcement Learning,N,Non-emotion stimuli to internal process,Binary,2,Component,Performance,Prototype,iCub,"Certain emotions and moods can be manifestations of complex and costly neural computations that our brain wants to avoid. Instead of reaching an optimal decision based on the facts, we find it often easier and sometimes more useful to rely on hunches. In this work, we extend a previously developed model for such a mechanism where a simple neural associative memory was used to implement a visual recall system for a humanoid robot. In the model, the changes in the neural state consume (neural) energy, and to minimize the total cost and the time to recall a memory pattern, the robot should take the action that will lead to minimal neural state change. To do so, the robot needs to learn to act rationally, and for this, it has to explore and find out the cost of its actions in the long run. In this study, a humanoid robot (iCub) is used to act in this scenario. The robot is given the sole action of changing his gaze direction. By reinforcement learning (RL) the robot learns which state-action pair sequences lead to minimal energy consumption. More importantly, the reward signal for RL is not given by the environment but obtained internally, as the actual neural cost of processing an incoming visual stimuli. The results indicate that reinforcement learning with the internally generated reward signal leads to non-trivial behaviours of the robot which might be interpreted by external observers as the robot's `liking' of a specific visual pattern, which in fact emerged solely based on the neural cost minimization principle.",M. Kirtay; L. Vannucci; E. Falotico; E. Oztop; C. Laschi,"BioRobotics Institute, Scuola Superiore Sant'Anna, 56025 Pontedera (PISA), Italy; BioRobotics Institute, Scuola Superiore Sant'Anna, 56025 Pontedera (PISA), Italy; BioRobotics Institute, Scuola Superiore Sant'Anna, 56025 Pontedera (PISA), Italy; Department of Computer Science, Ozyegin University, Cekmekoy Campus, Nisantepe Mah., Orman Sk. No:13, 34794, Istanbul, Turkey; BioRobotics Institute, Scuola Superiore Sant'Anna, 56025 Pontedera (PISA), Italy",2016 IEEE-RAS 16th International Conference on Humanoid Robots (Humanoids),,2016,,,1101,1106,,,,,,Robots;Visualization;Decision making;Heuristic algorithms;Energy consumption;Biology;Cameras,affective computing;decision making;humanoid robots;learning (artificial intelligence),sequential decision making;emergent emotion;humanoid robot;neural associative memory;visual recall system;neural energy;neural state change;iCub;gaze direction;reinforcement learning;state-action pair sequences;minimal energy consumption,,1,23,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5523410,Simulating Emotion and Personality for Intelligent Agent,Markovain emotional model - HMM,Y,Non-emotion stimuli to internal process and emotion ,Single,1,Core,General Interaction,Prototype,Digital,"Synthesizing the reasonable and natural emotion is important to achieve a more effective and believable human-computer interaction. The paper presents an emotion and personality model based on HMM. The emotion process is regarded as a double random process in the model. Different personality traits of intelligent agent can be built by adjusting the parameters of the model. At the same time, as emotion engine, the model can generate corresponding emotion states to changes of stimulus under the different personality circumstances and can be applied to emotion robots or other intelligent agent.",W. Guojiang; T. Shaodong; F. Kechang,"Chengdu Univ. of Inf. Technol., Chengdu, China; Beijing New YuanMing Coll., Beijing, China; Chengdu Univ. of Inf. Technol., Chengdu, China",2010 International Conference on Intelligent Computation Technology and Automation,,2010,3,,304,308,,,,,human-computer interaction;artifical emotion;emotion and personality model,Intelligent agent;Hidden Markov models;Information technology;Random processes;Human robot interaction;Psychology;Automation;Computational modeling;Educational institutions;Engines,artificial intelligence;hidden Markov models;human computer interaction,emotion simulation;intelligent agent personality;natural emotion;human computer interaction;double random process;emotion engine,,1,8,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7009165,Spiking neural network based emotional model for robot partner,Neural network,N,User Emotion to emotion output,Custom Discrete,4,Component,General Interaction,Implemented and Evaluated,iPhonoid,"In this paper, a spiking neural network based emotional model is proposed for a smart phone based robot partner. Since smart phone has limited computational power compared to personal computers, a simple spike response model is applied for the neurons in the neural network. The network has three layers following the concept of emotion, feeling, and mood. The perceptual input stimulates the neurons in the first, emotion layer. Weights adjustment is also proposed for the interconnected neurons in the feeling layer and between the feeling and mood layer based on Hebbian learning. Experiments are presented to validate the proposed method. Based on the emotional model, the output action such as gestural and facial expressions for the robot is calculated.",J. Botzheim; N. Kubota,"Graduate School of System Design, Tokyo Metropolitan University 6-6 Asahigaoka, Hino, Tokyo, 191-0065 Japan; Graduate School of System Design, Tokyo Metropolitan University 6-6 Asahigaoka, Hino, Tokyo, 191-0065 Japan",2014 IEEE Symposium on Robotic Intelligence in Informationally Structured Space (RiiSS),,2014,,,1,6,,,,,,Neurons;Mood;Robots;Computational modeling;Biological neural networks;Smart phones,Hebbian learning;human-robot interaction;neural nets;service robots;smart phones,spiking neural network;emotional model;robot partner;smart phone;spike response model;weights adjustment;Hebbian learning;robot facial expressions;robot gestural expressions;iPhonoid,,3,24,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=506527,Spontaneous behavior of robots for cooperation. Emotionally intelligent robot system,Rule-based - Computational Model,N,Non-emotion stimuli to internal process,Custom Discrete,1,Component,Performance,Prototype,Digital,"This paper deals with spontaneous behavior for cooperation among distributed autonomous robots. Though human gives the robots evaluation functions of the relation of cooperation among them, each robot determines its behavior depending on its experience and the behaviors of other robots. The robot acquires a model of behaviors of the other robots through teaming. Inspired from biological systems, the robot has emotions which play important roles of behavior selection. Each robot feels frustration when its determination does not suit to its environment. Then, it changes its behavior to change its situation actively. The results show a potential of emotional intelligence in robotics.",T. Shibata; K. Ohkawa; K. Tanie,"Artificial Intelligence Lab., MIT, Shibata, Japan; NA; NA",Proceedings of IEEE International Conference on Robotics and Automation,,1996,3,,2426,2431 vol.3,,,,,,Intelligent robots;Robot kinematics;Humans;Laboratories;Artificial intelligence;Mechanical engineering;Tellurium;Biological system modeling;Biological systems;Production,intelligent control;robots;cooperative systems;learning (artificial intelligence),spontaneous behavior;intelligent robots;cooperation;autonomous robots;teaming;emotional intelligence,,20,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4107819,Steward Robot: Emotional Agent for Subtle Human-Robot Interaction,Rule-based - Computational Model,N,Human and external to emotion output and internal process,Custom Discrete,8,Component,General Interaction,Prototype,Steward,"In this paper, we propose a new service agent, called a steward robot, which provides inhabitants with accessible, convenient, and cost effective interfaces as an intermediate agent between the user and a smart home environment. To implement more subtle emotional reaction of the agent, we adopt a novel emotional cue, sentiment relation, and address a problem of modeling the intensity and transition of emotion words, while previous researches have mainly focused on the selection of discrete emotion words from psychological point of view. We also discuss some issues of the proposed emotional model applying a virtual scenario to our Intelligent Sweet Home",Y. Kim; H. Lee; K. Park; Z. Z. Bien,"Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, 373-1 Guseong-dong, Yuseong-gu, Daejeon, 305-701, Republic of Korea, kimym@robot.kaist.ac.kr; Department of Electrical Engineering and Computer Science, Korea Advanced Institute of Science and Technology, 373-1 Guseong-dong, Yuseong-gu, Dae-jeon, 305-701, Republic of Korea, helee@ctrsys.kaist.ac.kr; Department of Electrical Engineering and Computer Science, Korea Advanced Institute of Science and Technology, 373-1 Guseong-dong, Yuseong-gu, Dae-jeon, 305-701, Republic of Korea, akaii@robotian.net; Department of Electrical Engineering and Computer Science, Korea Advanced Institute of Science and Technology, 373-1 Guseong-dong, Yuseong-gu, Dae-jeon, 305-701, Republic of Korea, zbien@ee.kaist.ac.kr",ROMAN 2006 - The 15th IEEE International Symposium on Robot and Human Interactive Communication,,2006,,,263,268,,,,,,Human robot interaction;Intelligent robots;Psychology;Service robots;Medical robotics;Costs;Smart homes;Medical treatment;Mechanical engineering;Senior citizens,home automation;man-machine systems;mobile robots;service robots,steward robot;emotional agent;human-robot interaction;service agent;Intelligent Sweet Home;virtual scenario,,1,16,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5423242,Stochastic approach on a simplified OCC model for uncertainty and believability,Probability table - user generated,N,Non-emotion stimuli to emotion output,Eckman Extension,12,Core,General Interaction,Prototype,Digital - SimStudio,"As robots step into the human's daily lives, interaction and communication between human and robot is becoming essential. For this social interaction with humans, we propose an emotion generation model considering simplicity, believability and uncertainty. First, OCC model is simplified and then stochastic approach on emotion decision algorithm for believability and uncertainty is applied. The proposed model is implemented on a 3D robot expression simulator that can express emotions through its facial expression, gesture, led and so on. A demo of the model is provided as a result.",W. H. Kim; J. W. Park; W. H. Lee; W. H. Kim; M. J. Chung,"Robotics Program, KAIST, Daejeon, Korea; School of Electrical Engineering and Computer Science, Division of Electrical Engineering, KAIST, Daejeon, Korea; School of Electrical Engineering and Computer Science, Division of Electrical Engineering, KAIST, Daejeon, Korea; School of Electrical Engineering and Computer Science, Division of Electrical Engineering, KAIST, Daejeon, Korea; School of Electrical Engineering and Computer Science, Division of Electrical Engineering, KAIST, Daejeon, Korea",2009 IEEE International Symposium on Computational Intelligence in Robotics and Automation - (CIRA),,2009,,,66,71,,,,,Emotion Generation;OCC Model;Probability,Stochastic processes;Uncertainty;Cognitive robotics;Human robot interaction;Intelligent robots;Electronic mail;Databases;Atherosclerosis;Humanoid robots;Computational modeling,emotion recognition;human-robot interaction;intelligent robots;stochastic processes,stochastic approach;simplified OCC model;human-robot communication;emotion generation model;simplicity;believability;uncertainty;3D robot expression simulator;Ortony-Clore-Collins model;emotion decision algorithm,,,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8172371,Study of emotion rendering design for humanoid robots compiled with real-time music mood perception,Factor table,N,Non-emotion stimuli to emotion output,Custom Discrete,4,Core,General Interaction,Prototype,Kondo KHR-3HV,"This study focuses on the role of anthropomorphic robots in rendering emotion and expressive behavior, either in entertainment or communicative scenarios. An integrated system was proposed to demonstrate the emotional movements of humanoid robot inspired by the real-time music emotions. The music emotions tracking system progressively extracts the features of music and characterizes music-induced emotions in an emotion plane to trace the real-time emotion locus of music. The Thayer's model of mood is consisted of four quadrants: (i)Contentment, (ii)Depression, (iii)Anxious, (iv)Exuberance. Each emotion is quantized to three levels to express the degree of mood. A humanoid robot is used as a base robot that allows for 17 Degree-Of-Freedom (DOF) movement. The motions designs for emotional expression are based on Laban Movement Analysis (LMA) to construct a quantifiable action description system. The system is capable of describing and interpreting many varieties of human movements. Furthermore, a questionnaire survey is conducted to evaluate the results of proposed emotions rendering system judged by the participants' experience. For the comparative emotion model checklist, 53 participants had to rate their felt emotional reaction to emotions movement on all three motions levels checklists. Good agreement has been obtained between motion design expression and questionnaire survey evaluations.",S. Cheng,"Mechanical Engineering Dept., National Chiao Tung University, 1001 University Road, Hsinchu, Taiwan 300, ROC",2017 26th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),,2017,,,647,652,,,,,,Robots,control engineering computing;emotion recognition;humanoid robots;music;rendering (computer graphics),motion design expression;comparative emotion model checklist;quantifiable action description system;Laban Movement Analysis;emotional expression;real-time music emotions;entertainment;anthropomorphic robots;real-time music mood perception;humanoid robot;emotion rendering design,,,17,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7016192,Sympathy expression model for the bystander robot in group communication,Neural network,N,User Emotion to emotion output,Cicurmplex,NA,Core,General interaction,Prototype,Digital,"In this paper, we propose a sympathy expression model for a bystander robot that honors the concept of moral emotion. Therefore, we pay attention to the robot that is in a bystander position, which is unrelated to the communication between participants. We propose a sympathy expression model that lets a bystander robot learn the emotional display of others and enables cooperative expressiveness. This model allows the appropriate expressiveness affecting communication of a robot in the position of a bystander. To test it, we assume the interaction of three robots with the emotion generation model using the neural network. Further, we inspect the movement of this model by using a psychology model. As a result, we confirmed the appropriate actions of this model.",S. Iguchi; H. Takenouchi; M. Tokumaru,"Dept. Science and Engineering Graduate School of Kansai University Osaka, Japan; Faculty of Information Engineering Fukuoka Institute of Technology Fukuoka, Japan; Faculty of Engineering Science Kansai University Osaka, Japan","2014 International Conference on Humanoid, Nanotechnology, Information Technology, Communication and Control, Environment and Management (HNICEM)",,2014,,,1,6,,,,,Sympathy;moral emotion;emotion generation model;bystander robot,Ethics;Robot kinematics;Observers;Vectors;Psychology;Robot sensing systems,control engineering computing;humanoid robots;neural nets;psychology,sympathy expression model;bystander robot;group communication;emotion generation model;neural network;psychology model,,,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4421131,Task Allocation with a Cooperative Plan for an Emotionally Intelligent System of Multi-Robots,Markovian emotion model,Y,Non-emotion stimuli to internal process,Custom Discrete,4,Core,Performance,Prototype,Digital,"This paper deals with an emotion-based approach to the task allocation of multi-robots, in which one robot requests the assistance of another robot in order to complete a task. A stochastic model of emotion is adapted to achieve a method for well organization of team work. With the emotional capability, each robot can distinguish the changed environment and can react with it with adaptability and also can understand colleague robot's state. The proposed computational architecture to model emotion is based on Markov modeling theory. In our approach, emotional state plays a role in the task allocation among the robots of a team in a productive and efficient manner.",Sajal Chandra Banik; Keigo Watanabe; Kiyotaka Izumi,"Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 1 Honjomachi, 840-8502, Japan; Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 1 Honjomachi, 840-8502, Japan; Department of Advanced Systems Control Engineering, Graduate School of Science and Engineering, Saga University, 1 Honjomachi, 840-8502, Japan",SICE Annual Conference 2007,,2007,,,1004,1010,,,,,Colleague robot;Distributed job;Markov modeling theory;Multi-agent system;Task allocation;Task sharing,Intelligent systems;Multirobot systems;Intelligent robots;Humans;Robustness;Fault tolerance;Orbital robotics;Control engineering;Stochastic processes;Computer architecture,intelligent robots;Markov processes;multi-robot systems,task allocation;cooperative plan;emotionally intelligent system;multirobots;Markov modeling theory,,3,24,,,,,IEEE,IEEE Conferences,,
,The Emotion Expression Robot through the Affective Interaction: KOBIE ,Look-up table,Y,Non-emotion stimuli to emotion output,Custom Discrete,6,Core,General Interaction,Prototype,Kobie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6798757,The MEI Robot: Towards Using Motherese to Develop Multimodal Emotional Intelligence,Rule-based - Computational Model,N,User Emotion to emotion output,Eckman,4,Core,General Interaction,Implemented and Evaluated,NAO,"We introduce the first steps in a developmental robot called MEI (multimodal emotional intelligence), a robot that can understand and express emotions in voice, gesture and gait using a controller trained only on voice. Whereas it is known that humans can perceive affect in voice, movement, music and even as little as point light displays, it is not clear how humans develop this skill. Is it innate? If not, how does this emotional intelligence develop in infants? The MEI robot develops these skills through vocal input and perceptual mapping of vocal features to other modalities. We base MEI's development on the idea that motherese is used as a way to associate dynamic vocal contours to facial emotion from an early age. MEI uses these dynamic contours to both understand and express multimodal emotions using a unified model called SIRE (Speed, Intensity, irRegularity, and Extent). Offline experiments with MEI support its cross-modal generalization ability: a model trained with voice data can recognize happiness, sadness, and fear in a completely different modality-human gait. User evaluations of the MEI robot speaking, gesturing and walking show that it can reliably express multimodal happiness and sadness using only the voice-trained model as a basis.",A. Lim; H. G. Okuno,"Graduate School of Informatics, Kyoto University, Kyoto, JAPAN; Graduate School of Informatics, Kyoto University, Kyoto, JAPAN",IEEE Transactions on Autonomous Mental Development,,2014,6,2,126,138,,,,,Cross-modal recognition;emotion recognition;gait;gaussian mixture;gesture;motherese;SIRE;voice,Speech;Robots;Feature extraction;Emotion recognition;Face;Speech recognition;Psychology,emotion recognition;face recognition;gait analysis;gesture recognition;human-robot interaction;intelligent robots;path planning;social aspects of automation,MEI robot;multimodal emotional intelligence;emotions express;robot voice;robot movement;music;vocal input;perceptual mapping;vocal features;motherese;dynamic vocal contours;facial emotion;SIRE;speed-intensity-irregularity-extent;cross-modal generalization ability;MEI robot speaking;MEI robot gesturing;MEI robot walking,,14,79,,,,,IEEE,IEEE Journals,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1627462,The research of interactive system of emotional robot based on multi-agent,Fuzzy Rule Base,Y,Human and external to emotion output ,Binary,2,Core,General Interaction,Prototype,Custom Robot,"To realize the harmonious interaction between the human user and computer, this paper conceives a structure model of emotional robot based on multi-agent, and makes an extensive introduction about affective model construction, learning model, and perception agent of the emotional model. Firstly, the primary factors that attribute to the generation of robot's emotion are extracted, and then an affective model construction method based on grey system theory is introduced. Secondly, the robot's learning model based on probability is discussed. Thirdly, the concept of affective correlation in perception agent is proposed, and then a modeling method based on grey prediction for the affective correlative model is given. Finally, models are experimented on the robot platform, and the results have proved that the robot is of the ability of affective and intelligent interaction",Xueyuan Zhang; Ping Dong; Zhiliang Wang; Masatake Nagai,"Sch. of Inf. Eng., Univ. of Sci. & Technol., Beijing, China; NA; NA; NA",2006 1st International Symposium on Systems and Control in Aerospace and Astronautics,,2006,,,5 pp.,857,,,,,,Interactive systems;Robotics and automation;Intelligent robots;Robot sensing systems;Psychology;Human robot interaction;Predictive models;Computer architecture;Information science;Neuroscience,correlation methods;grey systems;intelligent robots;learning (artificial intelligence);multi-agent systems,man-machine interaction;emotional robot;perception agent;grey systems;robot learning;affective correlation;affective interaction;intelligent interaction,,,5,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6628532,The role of arousal in two-resource problem tasks for humanoid service robots,Rule-based - Computational Model,N,Non-emotion stimuli to internal process,Single (Arousal),1,Component,Performance,Prototype,iCub,A computational architecture of emotion is presented which grounds a component of an appraisal cognitive model into the homeostatic processes of a humanoid robot. The focus of the present work entails a `grounding' of the arousal component of the Pleasure Arousal Dominance emotion space into the electrical energy processes of an iCub robot. Key variables and performance criteria for robotic energy autonomous behavior in interaction with human are discussed. We show that our bio-inspired affective architecture offers viable basic cycles in exemplar ‚Äútwo-resource problem‚Äù testbed scenarios for a real iCub robot. The expression of the robot's emotional state and its role for the efficient interaction in the proposed two-resource problem task is discussed and experimental designs are presented.,K. Kiryazov; R. Lowe; C. Becker-Asano; M. Randazzo,"Interaction Lab, University of Skovde, Sweden; Interaction Lab, University of Skovde, Sweden; Research Group on the Foundations of Artificial Intelligence Institut f√ºr Informatik, Albert-Ludwigs-Universit√§t, Freiburg, Germany; iCub Facility. Istittuto Italiano di Tecnologia, Genoa, Italy",2013 IEEE RO-MAN,,2013,,,62,69,,,,,,Robot kinematics;Appraisal;Mobile robots;Robot sensing systems;Service robots;Tracking,humanoid robots;service robots,robot emotional state;exemplar two resource problem testbed;bioinspired affective architecture;robotic energy autonomous behavior;iCub robot;electrical energy processes;pleasure arousal dominance emotion space;arousal component;homeostatic processes;appraisal cognitive model;computational architecture;humanoid service robots,,6,23,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1513860,The role of episodic memory and emotion in a cognitive robot,Look-up table,N,Non-emotion stimuli to internal process and emotion,Custom Discrete,5,Component,General interaction,Prototype,Digital,The design and creation of an episodic memory system for a cognitive robot is detailed. This memory system is interfaced with a machine emotion system with the goal of producing intelligent behaviors in a cognitive humanoid robot. The design of the system is tested and analyzed through the explanation of a case in which emotion assists in the retrieval of an episode.,W. Dodd; R. Gutierrez,"Dept. of Electr. Eng. & Comput. Sci., Vanderbilt Univ., Nashville, TN, USA; Dept. of Electr. Eng. & Comput. Sci., Vanderbilt Univ., Nashville, TN, USA","ROMAN 2005. IEEE International Workshop on Robot and Human Interactive Communication, 2005.",,2005,,,692,697,,,,,,Cognitive robotics;Humans;Intelligent robots;Actuators;Machine intelligence;Humanoid robots;Cognition;Artificial intelligence;Psychology;Control systems,cognitive systems;humanoid robots;intelligent robots;cognition;artificial intelligence,episodic memory;machine emotion system;cognitive humanoid robot;intelligent behaviors,,25,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360948,The sense of smell in social robots,Fuzzy Rule Base,N,Non-emotion stimuli to emotion output,Custom Discrete,4,Component,General interaction,Prototype,Urbano,"This paper presents an approach to the integration of the sense of smell in social robots. The Intelligence Control Group of CAR (CSIC-UPM) has been working on the design of URBANO, a tour guide robot. The URBANO's software architecture is based in agents using SOAP proposal. Some agents offer cognitive services, such as the automatic generation of presentations, learning of concepts using internet and the emotional behavior. One of them is an ontology that contains the knowledge used by the robot. A new agent that implements the learning of odors and produces new stimuli has been developed. This stimuli generate changes in the emotions, therefore, it also produces changes in the behavior of the robot. The obtained results show how to add odors to the emotional model of the robot help it to increase its performance as a social robot.",D. Gal√°n; R. Gal√°n; √Å. L. Mart√≠nez; I. Moreno,"Centro de Autom√°tica y Rob√≥tica, UPM - CSIC, Madrid, Spain; Centro de Autom√°tica y Rob√≥tica, UPM - CSIC, Madrid, Spain; Centro de Autom√°tica y Rob√≥tica, UPM - CSIC, Madrid, Spain; Facultad de Ciencias y Tecnolog√≠a, Universidad Tecnol√≥gica de Panam√°, Panam√°",2012 7th IEEE Conference on Industrial Electronics and Applications (ICIEA),,2012,,,1429,1434,,,,,Cognitive systems;Social robotics;Electronic Nose;Odors Classification;Affective Computing,Electronic noses;Robot sensing systems;Chemical sensors;Humans;Chemicals,chemioception;control engineering computing;human-robot interaction;Internet;learning (artificial intelligence);software architecture,social robots;smell sense;intelligence control group;CAR;CSIC-UPM;URBANO;tour guide robot;software architecture;SOAP proposal;cognitive services;automatic presentation generation;concepts learning;Internet;emotional behavior;odors,,,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690915,The Simulation of a Robot with Emotions Implemented with Fuzzy Logic,Fuzzy Rule Base,N,User Emotion to emotion output,Eckman,6,Core,General Interaction,Prototype,Digital,"With advancements in computer technologies, robots can be designed to act in more human ways. If behaviors of human beings are better understood, a robot enabled with human emotions may someday be created. To achieve this goal, in this study, we design and simulate a robot, named Shiau_Lu, empowered with six universal human emotions, including happiness, anger, fear, sadness, disgust, and surprise. When we input a sentence to Shiau_Lu, it recognizes the sentence by invoking the Google speech recognition method on the Android system, and reacts in a proper manner by outputting a sentence to reveal its emotion. Each input sentence affects strength of the six corresponding emotional variables. After the fuzzy inference process, the most significant emotion of those six will be inferred and determined. The remaining five are called hidden emotions. Besides, the most appropriate output sentence as a response is chosen from its database. With the new state of the six emotional variables, when the robot encounters another sentence, the above processes repeat and another output sentence is then chosen and replied. Artificial intelligence and psychological theories of human behaviors are applied to the robot to simulate how emotions are influenced by the outside world. In fact, the robot may help autistic children to interact more with the world around them and relate themselves well to the outside world.",Y. Hsu; F. Leu; J. Liu; Y. Huang; W. C. Chu,"Dept. of Comput. Sci., ThungHai Univ., Taichung, Taiwan; Dept. of Comput. Sci., ThungHai Univ., Taichung, Taiwan; Dept. of Comput. Sci., ThungHai Univ., Taichung, Taiwan; Dept. of Comput. Sci., ThungHai Univ., Taichung, Taiwan; Dept. of Comput. Sci., ThungHai Univ., Taichung, Taiwan","2013 Eighth International Conference on Broadband and Wireless Computing, Communication and Applications",,2013,,,382,386,,,,,Affective Computing;Fuzzy theory;Artificial intelligence;Psychology;Cognitive science,Robots;Fuzzy logic;Databases;Artificial intelligence;Cognitive science;Mood;Control systems,Android (operating system);fuzzy logic;fuzzy reasoning;human-robot interaction;psychology;speech recognition,autistic children interaction;psychological theory;artificial intelligence;hidden emotions;fuzzy inference process;emotional variables;Android system;Google speech recognition method;sentence recognition;surprise;disgust;sadness;fear;anger;happiness;Shiau_Lu;robot design;human emotion;human being behaviors;fuzzy logic;robot emotion;robot simulation,,,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4694221,Three-layered hybrid architecture for emotional reactive system,Rule-based Computational Model,N,Human and external to emotion output,Custom Discrete,12,Core,General Interaction,Prototype,EveR - 1,"In this paper, we present the design of an emotional reactive system based on three-layered hybrid architecture. The purpose of emotional reactive system is to make robot software system that has its autonomous emotion in interaction with human. The three-layered hybrid architecture is composed of Hardware abstraction layer, Reactive Layer and Deliberative Layer and developed for autonomous mobile robots. We applied this architecture to make android EveR-2psilas emotional reactive system. With this architecture, EveR-1 could make robot emotion generated by external stimulus and play its emotional behavior in robot task execution.",Jun-Young Jung; Dong-Wook Lee; Hyun-Sub Park; Ho-Gil Lee,"Department of Intelligent Robotics, Korea University of Science and Technology, Daejeon, Korea; Division of Applied Robot Technology, Korea Institute of Industrial Technology, Ansan, Korea; Division of Applied Robot Technology, Korea Institute of Industrial Technology, Ansan, Korea; Division of Applied Robot Technology, Korea Institute of Industrial Technology, Ansan, Korea","2008 International Conference on Control, Automation and Systems",,2008,,,2728,2731,,,,,Android;Emotional Robot;Emotion System;Three-Layered Hybrid Architecture;HRI,Service robots;Intelligent robots;Computer architecture;Human robot interaction;Software systems;Robotics and automation;Hybrid intelligent systems;Electronic mail;Automatic control;Control systems,artificial intelligence;control engineering computing;humanoid robots;mobile robots,three-layered hybrid architecture;emotional reactive system;robot software system;autonomous emotion;hardware abstraction layer;deliberative Layer;autonomous mobile robots;android EveR-2;EveR-1;robot task execution,,1,10,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5217935,Towards a dynamic emotional model,Rule-based Computational Model (Multi-agent,Y,Non-emotion stimuli to internal process,Custom Discrete,3,Core,General interaction,Prototype,Digital,"Emotions in general are a complex phenomenon to comprehend. They have been known to influence decisions as also behavior. Several computational models for emotions have been attempted. In this paper we present the dynamics and working of a multi-agent emotion generating system. Three basic emotions viz. happiness, fear and anger have been used to generate a resultant internal mood for a machine or a robot whose state depends on the immediate past. We compare the results obtained with those generated by a conventional fuzzy model to highlight their significance.",W. W. Godfrey; S. B. Nair; Kim Dong Hwa,"Department of Computer Science & Engineering, Indian Institute of Technology Guwahati, India; Department of Computer Science & Engineering, Indian Institute of Technology Guwahati, India; Department of Control & Instrumentation Engineering, Hanbat National University, Daejeon, S.Korea",2009 IEEE International Symposium on Industrial Electronics,,2009,,,1932,1936,,,,,,Decision making;Robot sensing systems;Computational modeling;Human robot interaction;Appraisal;Industrial electronics;Computer science;Instruments;Mood;Uncertainty,artificial intelligence;multi-agent systems,emotions;multi-agent emotion generating system;machine resultant internal mood,,6,22,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6661717,Towards ambient intelligence in assisted living: The creation of an Intelligent Home Care,Fuzzy Rule Base,N,User Emotion to Internal Process,Custom Discrete,4,Component,Performance,Implemented and Evaluated,Digital,"As the percentage of the elderly in the world's population continues to increase, the drive for improved technological support for assisted living follows. A new global objective that aims towards enhancing the elderly quality of life appears where lot of research has been taking place in the field of ambient intelligence consideration factors which includes more comfort, improved health and security for the elderly while living in their homes longer. This paper describes steps towards that goal. Thus a new intelligent fuzzy agent have been created with an emotion aware system that transforms a living environment into a pseudo robot which within which they reside providing a non-invasive, self-learning, intelligent controlling system that constantly adapts to the requirements of an individual. The system developed aims to towards providing a level of care for those who have difficulty in their interaction with standardised living spaces and a comparison of the two different self-learning methodologies developed is discussed. The empirical results of experiments performed at the Glamorgan Intelligent Home Care (Glam i-Home Care) will be presented shown the potential of the approach in assisting the extension of independent living.",S. Mowafey; S. Gardner,"Glamorgan Intelligent Home Care, Faculty of Advanced Technology, University of South Wales, Pontypridd, United Kingdom; Glamorgan Intelligent Home Care, Faculty of Advanced Technology, University of South Wales, Pontypridd, United Kingdom",2013 Science and Information Conference,,2013,,,51,60,,,,,Fuzzy Logic Systems;Adaptive Intelligent Agents;Ambient Intelligent Environments;Intelligent Control;Home Care,Biomedical monitoring;Temperature measurement;Emotion recognition;Monitoring;Actuators;Temperature sensors,age issues;ambient intelligence;assisted living;fuzzy logic;fuzzy reasoning;human-robot interaction;intelligent robots;multi-agent systems;unsupervised learning,Glam i-Home Care;Glamorgan intelligent home care;living space environment;noninvasive system;intelligent controlling system;self learning system;pseudo robot;emotion aware system;intelligent fuzzy agent;elderly quality of life;technological support;intelligent home care;assisted living;ambient intelligence,,,27,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1374740,Towards an emotion core based on a hidden Markov model,Markovain emotional model,Y,Non-emotion stimuli to emotion output,Custom Discrete,4,Core,General interaction,Prototype,Digital,"An emotion core for autonomous robots based on a hidden Markov model is proposed. Different emotional robot characters can be designed by tuning state transition probabilities. Perception of stimuli has an impact on emotional state transitions, and, thus, affects emotion dynamics and observable expressions/actions. This work proposes the methodology of design and implementation, and shows integration into a decision and control architecture. The application potential in an emotion-based human-robot interaction is discussed.",K. Kuhnlenz; M. Buss,"Inst. of Autom. Control Eng., Technische Univ. Munchen, Germany; Inst. of Autom. Control Eng., Technische Univ. Munchen, Germany",RO-MAN 2004. 13th IEEE International Workshop on Robot and Human Interactive Communication (IEEE Catalog No.04TH8759),,2004,,,119,124,,,,,,Hidden Markov models;Decision making;Robotics and automation;Human robot interaction;Cognitive robotics;Communication system control;Biomedical signal processing;Time measurement;Automatic control;Electronic mail,mobile robots;hidden Markov models;probability;man-machine systems;emotion recognition,emotional robot characters;hidden Markov model;autonomous robots;emotion core;state transition probability;stimuli perception;emotional state transitions;emotion dynamics;human robot interaction,,3,11,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613855,Towards Transparent Robot Learning through TDRL-based Emotional Expressions,Reinforcement Learning,Y,Non-emotion stimuli to emotion output,Custom Discrete,4,Core,Performance,Model,NAO,"Robots and virtual agents need to adapt existing and learn novel behavior to function autonomously in our society. Robot learning is often in interaction with or in the vicinity of humans. As a result the learning process needs to be transparent to humans. Reinforcement Learning (RL) has been used successfully for robot task learning. However, this learning process is often not transparent to the users. This results in a lack of understanding of what the robot is trying to do and why. The lack of transparency will directly impact robot learning. The expression of emotion is used by humans and other animals to signal information about the internal state of the individual in a language-independent, and even species-independent way, also during learning and exploration. In this article we argue that simulation and subsequent expression of emotion should be used to make the learning process of robots more transparent. We propose that the TDRL Theory of Emotion gives sufficient structure on how to develop such an emotionally expressive learning robot. Finally, we argue that next to such a generic model of RL-based emotion simulation we need personalized emotion interpretation for robots to better cope with individual expressive differences of users.",J. Broekens; M. Chetouani,"MMI, TU Delft, Delft, ZH Netherlands (e-mail: joost.broekens@gmail.com); Institut des Syst√®mes Intelligents et de Robotique, University Pierre and Marie Curie, Paris, Paris France 75252 (e-mail: mohamed.chetouani@upmc.fr)",IEEE Transactions on Affective Computing,,2019,PP,99,1,1,,,,H2020 Marie Sklodowska-Curie Actions; ,Robot learning;Transparency;Emotion;Reinforcement Learning;Temporal Difference,Task analysis;Robot kinematics;Robot learning;Reinforcement learning;Computational modeling;Education,,,,2,,,,,,IEEE,IEEE Early Access Articles,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7333599,Uncovering emotional memories in robot soccer players,Rule-based Computational Model,Y,Non-emotion stimuli to internal process,PAD,NA,Core,Performance,Implemented and Evaluated,Nao,"Memory is central to the emotional experience of playing sports. The capacity to recall great achievements, triumphs and defeats inevitably influences the emotional state of athletes and people in general. Nevertheless, research on robot competitions that has been striving to mimic real-world soccer, such as the well-known RoboCup challenge, never considered the relevance of memory and emotions, nor their possible connection. This paper proposes a data mining approach to emotional memory modelling with the purpose of replicating the link between emotion and memory in a Ro-boCup scenario. A model of emotional fluctuations is also proposed based on neurological disorders to investigate their effect on the robot's ability to choose appropriate behaviours. The proposed model is evaluated using the NAO robot on a simulation environment. By utilizing emotion to assess memories stored, NAO was able to successfully choose behaviours based on the optimal outcomes achieved in the past.",C. Allan; M. S. Couceiro; P. A. Vargas,"Robotics Lab, Heriot-Watt University, Edinburgh, UK, EH14 4AS; Ingeniarius, Ltd., and the Institute of Systems and Robotics, Coimbra, Portugal, 3030-290; Robotics Lab, Heriot-Watt University, Edinburgh, UK, EH14 4AS",2015 24th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN),,2015,,,474,479,,,,,,Robot sensing systems;Artificial intelligence;Niobium;Adaptation models;Data mining;Encoding,data mining;mobile robots;multi-robot systems,robot soccer players;emotional memories;RoboCup challenge;robot competitions;data mining approach;emotional memory modelling;emotional fluctuations;NAO robot;neurological disorders,,,17,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6106313,Universal emotional behavior decision model for applying to various social robots with different specifications and purposes,Probability table,N,Human and external to emotion output ,Custom Discrete,7,Core,General Interaction,Implemented and Evaluated,SALLY,"Emotional reaction should be different from the purpose of the robot system. The method for emotional reaction is also different from the specification of the robot system. Therefore, emotional behavior decision model, which is applied to social robots regardless of specifications and purposes, is necessary. This paper introduces a universal emotional behavior decision model designed for applying to various social robots that have different specifications and purposes. Multiple emotions, a set of probability value of every emotion, are calculated independently and expressed according to the purpose of the robot system. Then, behavior, for emotional reaction according to the calculated multiple emotions, is decided regarding the specification of the robot system. The decided behavior is a combination of unit behaviors that indicates the smallest expressible behaviors in each expression parts. It is possible to express various undefined behaviors by generating unit behavior combinations according to multiple emotions. The universal emotional behavior decision model is applied to two kinds of social robot systems that have different specifications and purposes.",H. S. Ahn; J. Y. Choi; D. Lee; W. H. Shon,"Department of Applied Robot Technology, Korea Institute of Industrial Technology, Ansan, Korea; School of Electrical Engineering and Computer Science, PIRC, ASRI, Seoul National University, Korea; Department of Applied Robot Technology, Korea Institute of Industrial Technology, Ansan, Korea; Department of Applied Robot Technology, Korea Institute of Industrial Technology, Ansan, Korea","2011 11th International Conference on Control, Automation and Systems",,2011,,,1048,1053,,,,,universal emotional behavior decision model;emotional expression;social robot system;unit behavior combination;multiple emotions,Robots;Three dimensional displays;Mathematical model;Generators;Collision avoidance;Mouth,behavioural sciences;cooperative systems;multi-robot systems,universal emotional behavior decision model;social robots;emotional reaction;robot system specification;unit behavior combinations;multiple emotions;social robot systems,,,14,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4381958,Virtual KANSEI for Robots in Welfare,Rule-based Computational Model,N,User Emotion to Internal Process,Eckman (no surprise),5,Component,Welfare,Prototype,Hajime-Chane,"This paper describes a series of studies to develop various components to invest robots in welfare field (we call care-taker support robots) with human-like emotions. These components are collectively proposed as the ""Virtual KANSEI (VK),"" which is a capability to generate and express emotion like behaviors of this robot. The word 'KANSEI' is used here to mean emotions, feelings and affective behaviors. The VK consists of three parts: a KANSEI Detector, a KANSEI Generator and a KANSEI Expressive Regulator. Our care-taker support robot is expected to be able to perform smooth interaction with human in executing everyday tasks when those three functions are integrated onto it. This paper focuses on describing the concept of this VK.",Y. Miyaji; K. Tomiyama,"Aoyama Gakuin Women's Junior College, 4-4-25 Shibuya, Shibuya-ku, Tokyo 150-8366, JAPAN. Email: uta@luce.aoyama.ac.jp; Chiba Institute of Technology, 2-17-1 Tsudanuma, Narashino-shi, Chiba 275-0016, JAPAN. Email: tomiyama.ken@it-chiba.ac.jp",2007 IEEE/ICME International Conference on Complex Medical Engineering,,2007,,,1323,1326,,,,,,Humanoid robots;Human robot interaction;Detectors;Regulators;Educational institutions;Paper technology;Engines;Aging;Medical services;State estimation,health care;intelligent robots;public administration;service robots,Virtual KANSEI;welfare robots;care-taker support robots;KANSEI Detector;KANSEI Generator;KANSEI Expressive Regulator,,6,15,,,,,IEEE,IEEE Conferences,,
https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8914198,You Are Doing Great! Only One Rep Left: An Affect-Aware Social Robot for Exercising,Markovain emotional model,Y,Non-emotion stimuli to emotion output,Custom Discrete,4,Component,Exercise,Implemented and Evaluated,Pepper,"Regular exercise has immediate and long-term benefits for people of all ages. Maintaining an adequate amount of daily exercise is important to overall health and wellbeing. Our research focuses on the development of a socially assistive robot, Salt, to facilitate different upper body exercises. During the exercises, the robot is uniquely able to autonomously detect a user's affect and engagement as well as measure their heart rate to prevent overexertion. A robot emotion model using an n th order Markov Chain is used to determine the robot's appropriate emotions during interactions based on user affect and engagement, and its own emotion history. Human-robot interaction experiments were conducted to investigate perceived usefulness and acceptance. The results showed that most users were engaged and had positive valence towards the robot during the interactions. Post-experiment questionnaire results also showed they were able to detect the robot's emotions and enjoyed interacting with it.",M. Shao; S. F. D. R. Alves; O. Ismail; X. Zhang; G. Nejat; B. Benhabib,"University of Toronto,Department of Mechanical and Industrial Engineering,Toronto,Canada; University of Toronto,Department of Mechanical and Industrial Engineering,Toronto,Canada; University of Toronto,Department of Mechanical and Industrial Engineering,Toronto,Canada; University of Toronto,Department of Mechanical and Industrial Engineering,Toronto,Canada; University of Toronto,Department of Mechanical and Industrial Engineering,Toronto,Canada; University of Toronto,Department of Mechanical and Industrial Engineering,Toronto,Canada","2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)",,2019,,,3811,3817,,,,,,Robot sensing systems;Electroencephalography;Heart rate;Brain modeling;Hidden Markov models;Monitoring,emotion recognition;human-robot interaction;Markov processes,acceptance;perceived usefulness;upper body exercises;daily exercise;long-term benefits;regular exercise;affect-aware social robot;post-experiment questionnaire results;human-robot interaction experiments;emotion history;appropriate emotions;order Markov Chain;robot emotion model;heart rate;socially assistive robot,,,42,,,,,IEEE,IEEE Conferences,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,